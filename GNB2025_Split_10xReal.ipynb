{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iOMBeyVyQ-7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941fd63d-e6e7-4b73-d515-e20dd52ef532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sdv\n",
            "  Downloading sdv-1.20.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting boto3<2.0.0,>=1.28 (from sdv)\n",
            "  Downloading boto3-1.37.36-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<2.0.0,>=1.31 (from sdv)\n",
            "  Downloading botocore-1.37.36-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (3.1.1)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.67.1)\n",
            "Collecting copulas>=0.12.1 (from sdv)\n",
            "  Downloading copulas-0.12.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting ctgan>=0.11.0 (from sdv)\n",
            "  Downloading ctgan-0.11.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting deepecho>=0.7.0 (from sdv)\n",
            "  Downloading deepecho-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rdt>=1.16.0 (from sdv)\n",
            "  Downloading rdt-1.16.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sdmetrics>=0.20.1 (from sdv)\n",
            "  Downloading sdmetrics-0.20.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.3.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (6.0.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading s3transfer-0.11.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.3.0)\n",
            "Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (1.14.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ctgan>=0.11.0->sdv) (2.6.0+cu124)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.16.0->sdv) (1.6.1)\n",
            "Collecting Faker>=17 (from rdt>=1.16.0->sdv)\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.16.0->sdv) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.16.0->sdv) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->ctgan>=0.11.0->sdv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan>=0.11.0->sdv) (3.0.2)\n",
            "Downloading sdv-1.20.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.36-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.36-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading copulas-0.12.2-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctgan-0.11.0-py3-none-any.whl (24 kB)\n",
            "Downloading deepecho-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading rdt-1.16.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.3/69.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sdmetrics-0.20.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, Faker, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, rdt, nvidia-cusolver-cu12, copulas, sdmetrics, boto3, deepecho, ctgan, sdv\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Faker-37.1.0 boto3-1.37.36 botocore-1.37.36 copulas-0.12.2 ctgan-0.11.0 deepecho-0.7.0 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdt-1.16.0 s3transfer-0.11.5 sdmetrics-0.20.1 sdv-1.20.0\n"
          ]
        }
      ],
      "source": [
        "# install singular value decomposition\n",
        "!pip install sdv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h1sinr-sIkou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0421552a-777e-4b21-e4ab-c23e8fcf9a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# import tools\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from sdv.evaluation.single_table import evaluate_quality\n",
        "from google.colab import drive\n",
        "import logging\n",
        "import warnings\n",
        "drive.mount('/content/gdrive')\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, log_loss, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U2q--EUBQcy",
        "outputId": "94be8c60-8474-43c7-978a-d7909071d684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe dimensions: (134, 38)\n",
            "Processed dataframe dimensions: (118, 37)\n",
            "Number of ALS: 97\n",
            "Number of HC: 21\n",
            "--------------------------------------------------\n",
            "Index(['Sesso', 'Disease', 'Età', 'GCSF', 'IFNgamma', 'IL10', 'IL15', 'IL17A',\n",
            "       'IL1beta', 'IL2', 'IL4', 'IL6', 'IL8', 'MCP1', 'MIP1alfa', 'TNFalfa',\n",
            "       'VEGF', 'TTVlog', 'TTVcopies', 'acetic', 'Propionic', 'Butyric',\n",
            "       'isoButyric', 'isoValeric', '@MethylButyric', 'valeric', 'Hexanoic',\n",
            "       'Heptanoic', 'Nonanoic', '@EthylHexanoic', 'Octanoic', 'Decanoic',\n",
            "       'Benzoic', 'Dodecanoic', 'Tetradecanoic', 'Hexadecanoic',\n",
            "       'Octadecanoic'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# data processing\n",
        "df = pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/Database_Features_ML.xlsx')\n",
        "print(f\"Original dataframe dimensions: {df.shape}\")\n",
        "df[df.columns[4:]] = df[df.columns[4:]].apply(pd.to_numeric, errors='coerce')\n",
        "df.replace([\"#!NULL\", \"\"], np.nan, inplace=True)\n",
        "df.drop(columns=['ID Paziente'], inplace=True)\n",
        "df = df.dropna()\n",
        "print(f\"Processed dataframe dimensions: {df.shape}\")\n",
        "\n",
        "# encoding sex column\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sesso'] = label_encoder.fit_transform(df['Sesso'])\n",
        "# encoding disease column\n",
        "df['Disease'] = df['Disease'].replace({'ALS': 1, 'HEALTHY': 0})\n",
        "df_als = df[df['Disease'] == 1]\n",
        "df_hc = df[df['Disease'] == 0]\n",
        "\n",
        "print(f\"Number of ALS: {len(df_als)}\")\n",
        "print(f\"Number of HC: {len(df_hc)}\")\n",
        "print('-'*50)\n",
        "print(df.columns)\n",
        "feature_names = df.columns.tolist()  # Store feature names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NtG7rv20ENtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415d9a0c-dffb-4cf0-a5dd-88c64bdbda2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (20, 37)\n",
            "Test set shape: (22, 37)\n"
          ]
        }
      ],
      "source": [
        "# subsampling the majority class, ALS\n",
        "df_als_downsized = df_als.sample(n=21, random_state=42)\n",
        "df_downsized = pd.concat([df_als_downsized, df_hc], ignore_index=True)\n",
        "# spliting data into training 50% and testing 50%\n",
        "class_a = df_downsized[df_downsized['Disease'] == 1]\n",
        "class_b = df_downsized[df_downsized['Disease'] == 0]\n",
        "half_class_a = class_a.sample(frac=0.5, random_state=42)\n",
        "half_class_b = class_b.sample(frac=0.5, random_state=42)\n",
        "train_df = pd.concat([half_class_a, half_class_b], axis=0).reset_index(drop=True)\n",
        "test_df = pd.concat([class_a.drop(half_class_a.index), class_b.drop(half_class_b.index)], axis=0).reset_index(drop=True)\n",
        "print(\"Train set shape:\", train_df.shape)\n",
        "print(\"Test set shape:\", test_df.shape)\n",
        "\n",
        "# Save to CSV\n",
        "test_df.to_csv(\"/content/gdrive/MyDrive/ALS/real.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6MvADyQwFGqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc3363e-f7fd-4ada-f71f-7ce1dd8f1718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 37)\n"
          ]
        }
      ],
      "source": [
        "# Detect metadata and ensure 'Disease' is categorical\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(train_df)\n",
        "metadata.update_column('Disease', sdtype='categorical')\n",
        "\n",
        "# validate\n",
        "metadata.validate()\n",
        "metadata.validate_data(data=train_df)\n",
        "\n",
        "# Initialize and fit the synthesizer\n",
        "synthesizer_GC = GaussianCopulaSynthesizer(\n",
        "        metadata,  # required\n",
        "        enforce_min_max_values=True,\n",
        "        enforce_rounding=False,\n",
        "        default_distribution='gaussian_kde'\n",
        "        )\n",
        "synthesizer_GC.fit(train_df)\n",
        "\n",
        "# Generate synthetic data\n",
        "# Sample 1 (10xTrainingSet)\n",
        "synthetic_data = synthesizer_GC.sample(num_rows=10*len(train_df))\n",
        "print(synthetic_data.shape)\n",
        "# Save to CSV\n",
        "synthetic_data.to_csv(\"/content/gdrive/MyDrive/ALS/synthetic.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EB5M3wrBHRwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e557939d-1e24-426d-ffee-ebce0b0ea15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 37/37 [00:00<00:00, 468.71it/s]|\n",
            "Column Shapes Score: 80.28%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 666/666 [00:14<00:00, 47.38it/s]|\n",
            "Column Pair Trends Score: 92.76%\n",
            "\n",
            "Overall Score (Average): 86.52%\n",
            "\n",
            "<sdmetrics.reports.single_table.quality_report.QualityReport object at 0x78cd4a179890>\n"
          ]
        }
      ],
      "source": [
        "quality_report = evaluate_quality(train_df, synthetic_data, metadata)\n",
        "print(quality_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KLeeRhFqIu7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9141b9-cfaf-4d90-85dd-0365df08af01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 36)\n",
            "(200,)\n",
            "(22, 36)\n",
            "(22,)\n"
          ]
        }
      ],
      "source": [
        "# Spliting features and labels\n",
        "\n",
        "Xtrain = synthetic_data.drop(columns=['Disease']).values  # Features\n",
        "ytrain = synthetic_data['Disease'].values  # Labels\n",
        "\n",
        "# Use the test set\n",
        "Xtest = test_df.drop(columns=['Disease']).values  # Features\n",
        "ytest = test_df['Disease'].values  # Labels\n",
        "\n",
        "print(Xtrain.shape)\n",
        "print(ytrain.shape)\n",
        "print(Xtest.shape)\n",
        "print(ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras\n",
        "\n",
        "# Scale the data for improved training stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_test = scaler.transform(Xtest)\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(ytrain), y=ytrain)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Define the deep learning model\n",
        "def create_model(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', input_shape=(input_dim,)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "# Metrics containers\n",
        "val_accuracies = []\n",
        "val_log_losses = []\n",
        "val_f1_scores = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_specificities = []\n",
        "val_aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "for train_index, val_index in kf.split(X_train, ytrain):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split training data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = ytrain[train_index], ytrain[val_index]\n",
        "\n",
        "    # Create and train the model\n",
        "    model = create_model(X_train_fold.shape[1])\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, lr_scheduler],\n",
        "        class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    y_val_pred_proba = model.predict(X_val_fold)\n",
        "    y_val_pred_classes = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    val_log_loss = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    val_f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    val_precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    val_recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    val_auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    val_specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_log_losses.append(val_log_loss)\n",
        "    val_f1_scores.append(val_f1)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_specificities.append(val_specificity)\n",
        "    val_aurocs.append(val_auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Val Accuracy: {val_accuracy:.4f}, Val Log Loss: {val_log_loss:.4f}, \"\n",
        "          f\"Val F1: {val_f1:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, \"\n",
        "          f\"Val Specificity: {val_specificity:.4f}, Val AUROC: {val_auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final Cross-Validation Results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Val Accuracy: {np.mean(val_accuracies):.4f}\")\n",
        "print(f\"Average Val Log Loss: {np.mean(val_log_losses):.4f}\")\n",
        "print(f\"Average Val F1 Score: {np.mean(val_f1_scores):.4f}\")\n",
        "print(f\"Average Val Precision: {np.mean(val_precisions):.4f}\")\n",
        "print(f\"Average Val Recall: {np.mean(val_recalls):.4f}\")\n",
        "print(f\"Average Val Specificity: {np.mean(val_specificities):.4f}\")\n",
        "print(f\"Average Val AUROC: {np.mean(val_aurocs):.4f}\")\n",
        "\n",
        "# Save the modelprint()\n",
        "model.save(\"/content/gdrive/MyDrive/ALS/dl.keras\")\n",
        "\n",
        "y_test_pred_proba = model.predict(X_test)\n",
        "y_test_pred_classes = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "test_accuracy = accuracy_score(ytest, y_test_pred_classes)\n",
        "test_log_loss = log_loss(ytest, y_test_pred_proba)\n",
        "test_f1 = f1_score(ytest, y_test_pred_classes)\n",
        "test_precision = precision_score(ytest, y_test_pred_classes)\n",
        "test_recall = recall_score(ytest, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(ytest, y_test_pred_proba)\n",
        "\n",
        "cm_test = confusion_matrix(ytest, y_test_pred_classes)\n",
        "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
        "test_specificity = tn_test / (tn_test + fp_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSZ_iQz4vnWE",
        "outputId": "34dbaaa0-d78f-468d-818c-fad45f125c61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.5029 - loss: 0.9025 - val_accuracy: 0.3500 - val_loss: 0.8160 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4993 - loss: 0.8421 - val_accuracy: 0.3750 - val_loss: 0.8071 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5359 - loss: 0.7870 - val_accuracy: 0.3750 - val_loss: 0.7971 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5247 - loss: 0.8967 - val_accuracy: 0.4000 - val_loss: 0.7874 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5195 - loss: 0.7730 - val_accuracy: 0.4000 - val_loss: 0.7777 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6052 - loss: 0.7324 - val_accuracy: 0.4750 - val_loss: 0.7685 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.6205 - loss: 0.6978 - val_accuracy: 0.4750 - val_loss: 0.7590 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6287 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.7499 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.6087 - loss: 0.6726 - val_accuracy: 0.4750 - val_loss: 0.7414 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6453 - loss: 0.6318 - val_accuracy: 0.5250 - val_loss: 0.7329 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6548 - loss: 0.6358 - val_accuracy: 0.5000 - val_loss: 0.7241 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5785 - loss: 0.6419 - val_accuracy: 0.5500 - val_loss: 0.7155 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7216 - loss: 0.5870 - val_accuracy: 0.5500 - val_loss: 0.7073 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6489 - loss: 0.5840 - val_accuracy: 0.5500 - val_loss: 0.6986 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6562 - loss: 0.6673 - val_accuracy: 0.5500 - val_loss: 0.6897 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6727 - loss: 0.6140 - val_accuracy: 0.5750 - val_loss: 0.6806 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6420 - loss: 0.6059 - val_accuracy: 0.6000 - val_loss: 0.6724 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6852 - loss: 0.5769 - val_accuracy: 0.6500 - val_loss: 0.6639 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7956 - loss: 0.4673 - val_accuracy: 0.6250 - val_loss: 0.6559 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8048 - loss: 0.4843 - val_accuracy: 0.6250 - val_loss: 0.6481 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7159 - loss: 0.5481 - val_accuracy: 0.6250 - val_loss: 0.6402 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7968 - loss: 0.4343 - val_accuracy: 0.6250 - val_loss: 0.6329 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7602 - loss: 0.4469 - val_accuracy: 0.6250 - val_loss: 0.6256 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8057 - loss: 0.4621 - val_accuracy: 0.6250 - val_loss: 0.6189 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7860 - loss: 0.4658 - val_accuracy: 0.6250 - val_loss: 0.6128 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8033 - loss: 0.4101 - val_accuracy: 0.6250 - val_loss: 0.6069 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7316 - loss: 0.5257 - val_accuracy: 0.6250 - val_loss: 0.6004 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7477 - loss: 0.4565 - val_accuracy: 0.6250 - val_loss: 0.5945 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8622 - loss: 0.3972 - val_accuracy: 0.6500 - val_loss: 0.5890 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8359 - loss: 0.4142 - val_accuracy: 0.6500 - val_loss: 0.5841 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8555 - loss: 0.3994 - val_accuracy: 0.6500 - val_loss: 0.5797 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8475 - loss: 0.3864 - val_accuracy: 0.6500 - val_loss: 0.5752 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8350 - loss: 0.3874 - val_accuracy: 0.6500 - val_loss: 0.5707 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8175 - loss: 0.4029 - val_accuracy: 0.6500 - val_loss: 0.5659 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8335 - loss: 0.3709 - val_accuracy: 0.6500 - val_loss: 0.5616 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8199 - loss: 0.3651 - val_accuracy: 0.6500 - val_loss: 0.5577 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8160 - loss: 0.4049 - val_accuracy: 0.6500 - val_loss: 0.5542 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8646 - loss: 0.3741 - val_accuracy: 0.6500 - val_loss: 0.5505 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8216 - loss: 0.3886 - val_accuracy: 0.6500 - val_loss: 0.5471 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8755 - loss: 0.3892 - val_accuracy: 0.6500 - val_loss: 0.5443 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8720 - loss: 0.3384 - val_accuracy: 0.6500 - val_loss: 0.5418 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9061 - loss: 0.3077 - val_accuracy: 0.6500 - val_loss: 0.5394 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8326 - loss: 0.3729 - val_accuracy: 0.6500 - val_loss: 0.5369 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8670 - loss: 0.3288 - val_accuracy: 0.6500 - val_loss: 0.5345 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8653 - loss: 0.3227 - val_accuracy: 0.6500 - val_loss: 0.5322 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9038 - loss: 0.2998 - val_accuracy: 0.6500 - val_loss: 0.5300 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8843 - loss: 0.3419 - val_accuracy: 0.6500 - val_loss: 0.5284 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8576 - loss: 0.3411 - val_accuracy: 0.6500 - val_loss: 0.5268 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8719 - loss: 0.3268 - val_accuracy: 0.6500 - val_loss: 0.5254 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8583 - loss: 0.3558 - val_accuracy: 0.6500 - val_loss: 0.5243 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8926 - loss: 0.2837 - val_accuracy: 0.6500 - val_loss: 0.5235 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8455 - loss: 0.3331 - val_accuracy: 0.6500 - val_loss: 0.5219 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9219 - loss: 0.2696 - val_accuracy: 0.6500 - val_loss: 0.5206 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8557 - loss: 0.3249 - val_accuracy: 0.6750 - val_loss: 0.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9028 - loss: 0.2605 - val_accuracy: 0.6750 - val_loss: 0.5174 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8707 - loss: 0.3083 - val_accuracy: 0.6750 - val_loss: 0.5159 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8436 - loss: 0.3430 - val_accuracy: 0.6750 - val_loss: 0.5143 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9004 - loss: 0.2845 - val_accuracy: 0.6750 - val_loss: 0.5131 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8707 - loss: 0.2992 - val_accuracy: 0.6750 - val_loss: 0.5126 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9423 - loss: 0.2454 - val_accuracy: 0.6750 - val_loss: 0.5120 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9356 - loss: 0.2440 - val_accuracy: 0.6750 - val_loss: 0.5117 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9287 - loss: 0.2668 - val_accuracy: 0.6750 - val_loss: 0.5103 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9163 - loss: 0.2843 - val_accuracy: 0.7000 - val_loss: 0.5084 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8836 - loss: 0.2924 - val_accuracy: 0.7000 - val_loss: 0.5070 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9126 - loss: 0.2847 - val_accuracy: 0.7000 - val_loss: 0.5065 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8681 - loss: 0.3029 - val_accuracy: 0.7000 - val_loss: 0.5051 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9070 - loss: 0.2686 - val_accuracy: 0.7000 - val_loss: 0.5045 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9217 - loss: 0.2817 - val_accuracy: 0.7000 - val_loss: 0.5037 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9333 - loss: 0.2265 - val_accuracy: 0.7000 - val_loss: 0.5031 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9153 - loss: 0.2759 - val_accuracy: 0.7000 - val_loss: 0.5026 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9732 - loss: 0.2102 - val_accuracy: 0.7000 - val_loss: 0.5021 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9322 - loss: 0.2576 - val_accuracy: 0.7000 - val_loss: 0.5021 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9307 - loss: 0.2262 - val_accuracy: 0.7000 - val_loss: 0.5016 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8735 - loss: 0.2964 - val_accuracy: 0.7000 - val_loss: 0.5013 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9194 - loss: 0.2666 - val_accuracy: 0.7000 - val_loss: 0.5004 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9240 - loss: 0.2926 - val_accuracy: 0.7000 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9012 - loss: 0.3121 - val_accuracy: 0.7000 - val_loss: 0.4996 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9055 - loss: 0.2373 - val_accuracy: 0.7000 - val_loss: 0.4991 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9279 - loss: 0.2291 - val_accuracy: 0.7000 - val_loss: 0.4984 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9257 - loss: 0.2232 - val_accuracy: 0.7000 - val_loss: 0.4972 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9035 - loss: 0.2728 - val_accuracy: 0.7000 - val_loss: 0.4969 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9380 - loss: 0.2136 - val_accuracy: 0.7000 - val_loss: 0.4961 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9302 - loss: 0.2498 - val_accuracy: 0.7000 - val_loss: 0.4954 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9039 - loss: 0.2118 - val_accuracy: 0.7250 - val_loss: 0.4945 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9273 - loss: 0.2494 - val_accuracy: 0.7250 - val_loss: 0.4935 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9483 - loss: 0.2159 - val_accuracy: 0.7250 - val_loss: 0.4928 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9242 - loss: 0.2233 - val_accuracy: 0.7250 - val_loss: 0.4929 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9181 - loss: 0.2081 - val_accuracy: 0.7250 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9298 - loss: 0.2141 - val_accuracy: 0.7250 - val_loss: 0.4920 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9080 - loss: 0.2395 - val_accuracy: 0.7250 - val_loss: 0.4911 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9078 - loss: 0.2601 - val_accuracy: 0.7250 - val_loss: 0.4916 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9278 - loss: 0.2204 - val_accuracy: 0.7250 - val_loss: 0.4920 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9530 - loss: 0.1913 - val_accuracy: 0.7250 - val_loss: 0.4929 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9385 - loss: 0.2028 - val_accuracy: 0.7250 - val_loss: 0.4928 - learning_rate: 2.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8805 - loss: 0.2475 - val_accuracy: 0.7250 - val_loss: 0.4926 - learning_rate: 2.0000e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "Fold 1 - Val Accuracy: 0.7250, Val Log Loss: 0.4911, Val F1: 0.6857, Val Precision: 0.7500, Val Recall: 0.6316, Val Specificity: 0.8095, Val AUROC: 0.8421\n",
            "\n",
            "Training fold 2...\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - accuracy: 0.5451 - loss: 0.7350 - val_accuracy: 0.6750 - val_loss: 0.6333 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6168 - loss: 0.6365 - val_accuracy: 0.6750 - val_loss: 0.6261 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5940 - loss: 0.6683 - val_accuracy: 0.6750 - val_loss: 0.6194 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5969 - loss: 0.6276 - val_accuracy: 0.7250 - val_loss: 0.6126 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6389 - loss: 0.6174 - val_accuracy: 0.7250 - val_loss: 0.6061 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7283 - loss: 0.5980 - val_accuracy: 0.7500 - val_loss: 0.5997 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6742 - loss: 0.5976 - val_accuracy: 0.8000 - val_loss: 0.5933 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6763 - loss: 0.5764 - val_accuracy: 0.8250 - val_loss: 0.5868 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5644 - loss: 0.6421 - val_accuracy: 0.8250 - val_loss: 0.5802 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6610 - loss: 0.6083 - val_accuracy: 0.8250 - val_loss: 0.5734 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7474 - loss: 0.5491 - val_accuracy: 0.8250 - val_loss: 0.5668 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7056 - loss: 0.5510 - val_accuracy: 0.8250 - val_loss: 0.5606 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7332 - loss: 0.5441 - val_accuracy: 0.8250 - val_loss: 0.5545 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7069 - loss: 0.5244 - val_accuracy: 0.8250 - val_loss: 0.5488 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6901 - loss: 0.5716 - val_accuracy: 0.8250 - val_loss: 0.5430 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7510 - loss: 0.5576 - val_accuracy: 0.8250 - val_loss: 0.5372 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7342 - loss: 0.4804 - val_accuracy: 0.8250 - val_loss: 0.5316 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7256 - loss: 0.5202 - val_accuracy: 0.8250 - val_loss: 0.5258 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7064 - loss: 0.5228 - val_accuracy: 0.8500 - val_loss: 0.5201 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8086 - loss: 0.4685 - val_accuracy: 0.8500 - val_loss: 0.5144 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7995 - loss: 0.4468 - val_accuracy: 0.8500 - val_loss: 0.5085 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7819 - loss: 0.4765 - val_accuracy: 0.8500 - val_loss: 0.5028 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7226 - loss: 0.4997 - val_accuracy: 0.8250 - val_loss: 0.4971 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6795 - loss: 0.4878 - val_accuracy: 0.8250 - val_loss: 0.4915 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7881 - loss: 0.4305 - val_accuracy: 0.8250 - val_loss: 0.4863 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8372 - loss: 0.4407 - val_accuracy: 0.8250 - val_loss: 0.4814 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7954 - loss: 0.4436 - val_accuracy: 0.8250 - val_loss: 0.4770 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7745 - loss: 0.4816 - val_accuracy: 0.8250 - val_loss: 0.4725 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7843 - loss: 0.4469 - val_accuracy: 0.8250 - val_loss: 0.4680 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8553 - loss: 0.3858 - val_accuracy: 0.8250 - val_loss: 0.4635 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7867 - loss: 0.4558 - val_accuracy: 0.8250 - val_loss: 0.4592 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8158 - loss: 0.4207 - val_accuracy: 0.8250 - val_loss: 0.4551 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8320 - loss: 0.4337 - val_accuracy: 0.8250 - val_loss: 0.4511 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8427 - loss: 0.3835 - val_accuracy: 0.8250 - val_loss: 0.4470 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8329 - loss: 0.4020 - val_accuracy: 0.8250 - val_loss: 0.4435 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8126 - loss: 0.4183 - val_accuracy: 0.8250 - val_loss: 0.4397 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8197 - loss: 0.3926 - val_accuracy: 0.8250 - val_loss: 0.4359 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8253 - loss: 0.3879 - val_accuracy: 0.8250 - val_loss: 0.4322 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8543 - loss: 0.4011 - val_accuracy: 0.8250 - val_loss: 0.4287 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7847 - loss: 0.4219 - val_accuracy: 0.8250 - val_loss: 0.4253 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8813 - loss: 0.3348 - val_accuracy: 0.8000 - val_loss: 0.4221 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8377 - loss: 0.3671 - val_accuracy: 0.8000 - val_loss: 0.4190 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8899 - loss: 0.3443 - val_accuracy: 0.8000 - val_loss: 0.4158 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8585 - loss: 0.3905 - val_accuracy: 0.8000 - val_loss: 0.4126 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8385 - loss: 0.3539 - val_accuracy: 0.8000 - val_loss: 0.4096 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8761 - loss: 0.3593 - val_accuracy: 0.8000 - val_loss: 0.4069 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8997 - loss: 0.3317 - val_accuracy: 0.8000 - val_loss: 0.4039 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8609 - loss: 0.3657 - val_accuracy: 0.8000 - val_loss: 0.4013 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8694 - loss: 0.3536 - val_accuracy: 0.8000 - val_loss: 0.3984 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8608 - loss: 0.3260 - val_accuracy: 0.8000 - val_loss: 0.3958 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8568 - loss: 0.3560 - val_accuracy: 0.8000 - val_loss: 0.3931 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8168 - loss: 0.3617 - val_accuracy: 0.8000 - val_loss: 0.3906 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8606 - loss: 0.3708 - val_accuracy: 0.8000 - val_loss: 0.3883 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8760 - loss: 0.3399 - val_accuracy: 0.8000 - val_loss: 0.3862 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8786 - loss: 0.3365 - val_accuracy: 0.8000 - val_loss: 0.3840 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9006 - loss: 0.2942 - val_accuracy: 0.8000 - val_loss: 0.3817 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8576 - loss: 0.3413 - val_accuracy: 0.8000 - val_loss: 0.3793 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8142 - loss: 0.3629 - val_accuracy: 0.8000 - val_loss: 0.3771 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8796 - loss: 0.3236 - val_accuracy: 0.8000 - val_loss: 0.3750 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8687 - loss: 0.3303 - val_accuracy: 0.8000 - val_loss: 0.3729 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8935 - loss: 0.3177 - val_accuracy: 0.8000 - val_loss: 0.3705 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8885 - loss: 0.2923 - val_accuracy: 0.8000 - val_loss: 0.3683 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8750 - loss: 0.3148 - val_accuracy: 0.8000 - val_loss: 0.3663 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8011 - loss: 0.3708 - val_accuracy: 0.8000 - val_loss: 0.3651 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8826 - loss: 0.3294 - val_accuracy: 0.8000 - val_loss: 0.3638 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8830 - loss: 0.3099 - val_accuracy: 0.8000 - val_loss: 0.3622 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8831 - loss: 0.2793 - val_accuracy: 0.8000 - val_loss: 0.3608 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8786 - loss: 0.2897 - val_accuracy: 0.8000 - val_loss: 0.3593 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8728 - loss: 0.3137 - val_accuracy: 0.8250 - val_loss: 0.3578 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8793 - loss: 0.2878 - val_accuracy: 0.8250 - val_loss: 0.3565 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8631 - loss: 0.2954 - val_accuracy: 0.8250 - val_loss: 0.3551 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8937 - loss: 0.3323 - val_accuracy: 0.8250 - val_loss: 0.3538 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8870 - loss: 0.3124 - val_accuracy: 0.8250 - val_loss: 0.3525 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8615 - loss: 0.3227 - val_accuracy: 0.8250 - val_loss: 0.3513 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9040 - loss: 0.2774 - val_accuracy: 0.8250 - val_loss: 0.3502 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8414 - loss: 0.3783 - val_accuracy: 0.8250 - val_loss: 0.3490 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8705 - loss: 0.3366 - val_accuracy: 0.8250 - val_loss: 0.3483 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9480 - loss: 0.2324 - val_accuracy: 0.8250 - val_loss: 0.3472 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9148 - loss: 0.2882 - val_accuracy: 0.8250 - val_loss: 0.3464 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8672 - loss: 0.2974 - val_accuracy: 0.8250 - val_loss: 0.3454 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9117 - loss: 0.2582 - val_accuracy: 0.8250 - val_loss: 0.3445 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9230 - loss: 0.2455 - val_accuracy: 0.8250 - val_loss: 0.3436 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8944 - loss: 0.2810 - val_accuracy: 0.8250 - val_loss: 0.3427 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9325 - loss: 0.2355 - val_accuracy: 0.8250 - val_loss: 0.3420 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8878 - loss: 0.2782 - val_accuracy: 0.8250 - val_loss: 0.3415 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9248 - loss: 0.2557 - val_accuracy: 0.8250 - val_loss: 0.3406 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8934 - loss: 0.2499 - val_accuracy: 0.8250 - val_loss: 0.3396 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9432 - loss: 0.2556 - val_accuracy: 0.8250 - val_loss: 0.3390 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8853 - loss: 0.2703 - val_accuracy: 0.8250 - val_loss: 0.3386 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9009 - loss: 0.2611 - val_accuracy: 0.8250 - val_loss: 0.3382 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9198 - loss: 0.2662 - val_accuracy: 0.8250 - val_loss: 0.3374 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8779 - loss: 0.3081 - val_accuracy: 0.8250 - val_loss: 0.3367 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9087 - loss: 0.2743 - val_accuracy: 0.8250 - val_loss: 0.3360 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8945 - loss: 0.2718 - val_accuracy: 0.8250 - val_loss: 0.3354 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9416 - loss: 0.2168 - val_accuracy: 0.8250 - val_loss: 0.3344 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9084 - loss: 0.2773 - val_accuracy: 0.8250 - val_loss: 0.3336 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9170 - loss: 0.2569 - val_accuracy: 0.8250 - val_loss: 0.3332 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9266 - loss: 0.2432 - val_accuracy: 0.8250 - val_loss: 0.3331 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9149 - loss: 0.2524 - val_accuracy: 0.8250 - val_loss: 0.3329 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9372 - loss: 0.2121 - val_accuracy: 0.8250 - val_loss: 0.3325 - learning_rate: 1.0000e-04\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "Fold 2 - Val Accuracy: 0.8250, Val Log Loss: 0.3325, Val F1: 0.7742, Val Precision: 1.0000, Val Recall: 0.6316, Val Specificity: 1.0000, Val AUROC: 0.9624\n",
            "\n",
            "Training fold 3...\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.4696 - loss: 1.0485 - val_accuracy: 0.4500 - val_loss: 0.8467 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4696 - loss: 1.0666 - val_accuracy: 0.4000 - val_loss: 0.8363 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4789 - loss: 0.9457 - val_accuracy: 0.3750 - val_loss: 0.8266 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5475 - loss: 0.9938 - val_accuracy: 0.3750 - val_loss: 0.8176 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4686 - loss: 0.9681 - val_accuracy: 0.4000 - val_loss: 0.8099 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4865 - loss: 0.9229 - val_accuracy: 0.4250 - val_loss: 0.8026 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5132 - loss: 0.8882 - val_accuracy: 0.4000 - val_loss: 0.7954 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5755 - loss: 0.8236 - val_accuracy: 0.3750 - val_loss: 0.7879 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5516 - loss: 0.8265 - val_accuracy: 0.3750 - val_loss: 0.7796 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5633 - loss: 0.8043 - val_accuracy: 0.3750 - val_loss: 0.7722 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6306 - loss: 0.7186 - val_accuracy: 0.4000 - val_loss: 0.7651 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6586 - loss: 0.7068 - val_accuracy: 0.4000 - val_loss: 0.7585 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6202 - loss: 0.7463 - val_accuracy: 0.4000 - val_loss: 0.7520 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5751 - loss: 0.7189 - val_accuracy: 0.4500 - val_loss: 0.7454 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5810 - loss: 0.7217 - val_accuracy: 0.5000 - val_loss: 0.7394 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6608 - loss: 0.6039 - val_accuracy: 0.5000 - val_loss: 0.7334 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6613 - loss: 0.6070 - val_accuracy: 0.5000 - val_loss: 0.7275 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5891 - loss: 0.6360 - val_accuracy: 0.5250 - val_loss: 0.7219 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6353 - loss: 0.6347 - val_accuracy: 0.5500 - val_loss: 0.7167 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6997 - loss: 0.5778 - val_accuracy: 0.5500 - val_loss: 0.7115 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7586 - loss: 0.5068 - val_accuracy: 0.5500 - val_loss: 0.7066 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6728 - loss: 0.5933 - val_accuracy: 0.5500 - val_loss: 0.7019 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6747 - loss: 0.5869 - val_accuracy: 0.5750 - val_loss: 0.6972 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6924 - loss: 0.5075 - val_accuracy: 0.5750 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7842 - loss: 0.4824 - val_accuracy: 0.6000 - val_loss: 0.6899 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7105 - loss: 0.5654 - val_accuracy: 0.6000 - val_loss: 0.6864 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7802 - loss: 0.4748 - val_accuracy: 0.6000 - val_loss: 0.6832 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7277 - loss: 0.5599 - val_accuracy: 0.6000 - val_loss: 0.6801 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7711 - loss: 0.4694 - val_accuracy: 0.6000 - val_loss: 0.6768 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7157 - loss: 0.4828 - val_accuracy: 0.6250 - val_loss: 0.6738 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7865 - loss: 0.4647 - val_accuracy: 0.6250 - val_loss: 0.6709 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7944 - loss: 0.4504 - val_accuracy: 0.6250 - val_loss: 0.6682 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6941 - loss: 0.5286 - val_accuracy: 0.6500 - val_loss: 0.6653 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8072 - loss: 0.4491 - val_accuracy: 0.6500 - val_loss: 0.6631 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8055 - loss: 0.4380 - val_accuracy: 0.6500 - val_loss: 0.6605 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8418 - loss: 0.3614 - val_accuracy: 0.6500 - val_loss: 0.6583 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8105 - loss: 0.4207 - val_accuracy: 0.6500 - val_loss: 0.6563 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7907 - loss: 0.4247 - val_accuracy: 0.6500 - val_loss: 0.6544 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8014 - loss: 0.4048 - val_accuracy: 0.6750 - val_loss: 0.6526 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8683 - loss: 0.3732 - val_accuracy: 0.6750 - val_loss: 0.6511 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8165 - loss: 0.3993 - val_accuracy: 0.6750 - val_loss: 0.6492 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8813 - loss: 0.3571 - val_accuracy: 0.6750 - val_loss: 0.6476 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8556 - loss: 0.3273 - val_accuracy: 0.6750 - val_loss: 0.6460 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8495 - loss: 0.3552 - val_accuracy: 0.6750 - val_loss: 0.6443 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8324 - loss: 0.3571 - val_accuracy: 0.6750 - val_loss: 0.6426 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8349 - loss: 0.3736 - val_accuracy: 0.6750 - val_loss: 0.6409 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8378 - loss: 0.3718 - val_accuracy: 0.6750 - val_loss: 0.6394 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7711 - loss: 0.4252 - val_accuracy: 0.6750 - val_loss: 0.6378 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7996 - loss: 0.3866 - val_accuracy: 0.6750 - val_loss: 0.6359 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8344 - loss: 0.3513 - val_accuracy: 0.6750 - val_loss: 0.6344 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8048 - loss: 0.3798 - val_accuracy: 0.6750 - val_loss: 0.6332 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8683 - loss: 0.3363 - val_accuracy: 0.6750 - val_loss: 0.6318 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8221 - loss: 0.3335 - val_accuracy: 0.6750 - val_loss: 0.6305 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8694 - loss: 0.3485 - val_accuracy: 0.6750 - val_loss: 0.6291 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8452 - loss: 0.3451 - val_accuracy: 0.6750 - val_loss: 0.6277 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8452 - loss: 0.2947 - val_accuracy: 0.6750 - val_loss: 0.6265 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8462 - loss: 0.3211 - val_accuracy: 0.6500 - val_loss: 0.6254 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8465 - loss: 0.3467 - val_accuracy: 0.6500 - val_loss: 0.6240 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8406 - loss: 0.2935 - val_accuracy: 0.6500 - val_loss: 0.6225 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8778 - loss: 0.2991 - val_accuracy: 0.6500 - val_loss: 0.6210 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8760 - loss: 0.3204 - val_accuracy: 0.6500 - val_loss: 0.6195 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8173 - loss: 0.3587 - val_accuracy: 0.6500 - val_loss: 0.6184 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8161 - loss: 0.3481 - val_accuracy: 0.6500 - val_loss: 0.6172 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9129 - loss: 0.2523 - val_accuracy: 0.6500 - val_loss: 0.6162 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8975 - loss: 0.2841 - val_accuracy: 0.6500 - val_loss: 0.6154 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9004 - loss: 0.3107 - val_accuracy: 0.6500 - val_loss: 0.6143 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8637 - loss: 0.2934 - val_accuracy: 0.6500 - val_loss: 0.6135 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8789 - loss: 0.3057 - val_accuracy: 0.6500 - val_loss: 0.6122 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8952 - loss: 0.2710 - val_accuracy: 0.6500 - val_loss: 0.6113 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8482 - loss: 0.3451 - val_accuracy: 0.6500 - val_loss: 0.6099 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8728 - loss: 0.2793 - val_accuracy: 0.6500 - val_loss: 0.6084 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8809 - loss: 0.3088 - val_accuracy: 0.6500 - val_loss: 0.6074 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9099 - loss: 0.2516 - val_accuracy: 0.6500 - val_loss: 0.6063 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8681 - loss: 0.2618 - val_accuracy: 0.6500 - val_loss: 0.6057 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8894 - loss: 0.2569 - val_accuracy: 0.6500 - val_loss: 0.6049 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9043 - loss: 0.2360 - val_accuracy: 0.6500 - val_loss: 0.6037 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8515 - loss: 0.2732 - val_accuracy: 0.6500 - val_loss: 0.6027 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8867 - loss: 0.2643 - val_accuracy: 0.6500 - val_loss: 0.6014 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8851 - loss: 0.2731 - val_accuracy: 0.6500 - val_loss: 0.6004 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8686 - loss: 0.2770 - val_accuracy: 0.6500 - val_loss: 0.5991 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9029 - loss: 0.2597 - val_accuracy: 0.6500 - val_loss: 0.5982 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9117 - loss: 0.2591 - val_accuracy: 0.6500 - val_loss: 0.5973 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8882 - loss: 0.2608 - val_accuracy: 0.6500 - val_loss: 0.5966 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8715 - loss: 0.2811 - val_accuracy: 0.6500 - val_loss: 0.5955 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8861 - loss: 0.2447 - val_accuracy: 0.6500 - val_loss: 0.5942 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9139 - loss: 0.2561 - val_accuracy: 0.6500 - val_loss: 0.5927 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8510 - loss: 0.3008 - val_accuracy: 0.6500 - val_loss: 0.5910 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9005 - loss: 0.2638 - val_accuracy: 0.6750 - val_loss: 0.5893 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9106 - loss: 0.2190 - val_accuracy: 0.6750 - val_loss: 0.5878 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9439 - loss: 0.1804 - val_accuracy: 0.6750 - val_loss: 0.5866 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8859 - loss: 0.2522 - val_accuracy: 0.6750 - val_loss: 0.5853 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9092 - loss: 0.2379 - val_accuracy: 0.6750 - val_loss: 0.5841 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8975 - loss: 0.2483 - val_accuracy: 0.6750 - val_loss: 0.5831 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8970 - loss: 0.2433 - val_accuracy: 0.6750 - val_loss: 0.5820 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9265 - loss: 0.2375 - val_accuracy: 0.6750 - val_loss: 0.5812 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9090 - loss: 0.2477 - val_accuracy: 0.6750 - val_loss: 0.5804 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9096 - loss: 0.2226 - val_accuracy: 0.6750 - val_loss: 0.5800 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9595 - loss: 0.1875 - val_accuracy: 0.6750 - val_loss: 0.5797 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9189 - loss: 0.2491 - val_accuracy: 0.6750 - val_loss: 0.5796 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8918 - loss: 0.2500 - val_accuracy: 0.6750 - val_loss: 0.5793 - learning_rate: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78cd479bd8a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78cd479bd8a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Fold 3 - Val Accuracy: 0.6750, Val Log Loss: 0.5793, Val F1: 0.6977, Val Precision: 0.6250, Val Recall: 0.7895, Val Specificity: 0.5714, Val AUROC: 0.8471\n",
            "\n",
            "Training fold 4...\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.5240 - loss: 0.8232 - val_accuracy: 0.4500 - val_loss: 0.7191 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4611 - loss: 0.8327 - val_accuracy: 0.4750 - val_loss: 0.7078 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5520 - loss: 0.7717 - val_accuracy: 0.5000 - val_loss: 0.6963 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6571 - loss: 0.6904 - val_accuracy: 0.5250 - val_loss: 0.6851 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5033 - loss: 0.7346 - val_accuracy: 0.5250 - val_loss: 0.6731 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5546 - loss: 0.7382 - val_accuracy: 0.5500 - val_loss: 0.6614 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6844 - loss: 0.6656 - val_accuracy: 0.5500 - val_loss: 0.6501 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5697 - loss: 0.7107 - val_accuracy: 0.5500 - val_loss: 0.6394 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5977 - loss: 0.6086 - val_accuracy: 0.5750 - val_loss: 0.6294 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6959 - loss: 0.6129 - val_accuracy: 0.6250 - val_loss: 0.6191 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6557 - loss: 0.6386 - val_accuracy: 0.6500 - val_loss: 0.6092 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6546 - loss: 0.6036 - val_accuracy: 0.7000 - val_loss: 0.5997 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6253 - loss: 0.6279 - val_accuracy: 0.7000 - val_loss: 0.5903 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6787 - loss: 0.5732 - val_accuracy: 0.7250 - val_loss: 0.5808 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7228 - loss: 0.5664 - val_accuracy: 0.7500 - val_loss: 0.5723 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7609 - loss: 0.5270 - val_accuracy: 0.7750 - val_loss: 0.5637 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7062 - loss: 0.5526 - val_accuracy: 0.8000 - val_loss: 0.5553 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7343 - loss: 0.5368 - val_accuracy: 0.8000 - val_loss: 0.5471 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7202 - loss: 0.5419 - val_accuracy: 0.8000 - val_loss: 0.5394 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7515 - loss: 0.5018 - val_accuracy: 0.8250 - val_loss: 0.5321 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6891 - loss: 0.5983 - val_accuracy: 0.8250 - val_loss: 0.5251 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7925 - loss: 0.5147 - val_accuracy: 0.8250 - val_loss: 0.5180 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8160 - loss: 0.5099 - val_accuracy: 0.8250 - val_loss: 0.5113 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8091 - loss: 0.4471 - val_accuracy: 0.8250 - val_loss: 0.5047 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8022 - loss: 0.4703 - val_accuracy: 0.8250 - val_loss: 0.4988 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8111 - loss: 0.4626 - val_accuracy: 0.8250 - val_loss: 0.4926 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8035 - loss: 0.4466 - val_accuracy: 0.8250 - val_loss: 0.4871 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8339 - loss: 0.4328 - val_accuracy: 0.8250 - val_loss: 0.4814 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8247 - loss: 0.4473 - val_accuracy: 0.8500 - val_loss: 0.4756 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7846 - loss: 0.4493 - val_accuracy: 0.8500 - val_loss: 0.4698 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7868 - loss: 0.4329 - val_accuracy: 0.8750 - val_loss: 0.4642 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8023 - loss: 0.4568 - val_accuracy: 0.8750 - val_loss: 0.4587 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7358 - loss: 0.5136 - val_accuracy: 0.8750 - val_loss: 0.4530 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8292 - loss: 0.4239 - val_accuracy: 0.8750 - val_loss: 0.4477 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8271 - loss: 0.4098 - val_accuracy: 0.8750 - val_loss: 0.4428 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8373 - loss: 0.4031 - val_accuracy: 0.8750 - val_loss: 0.4379 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8359 - loss: 0.3786 - val_accuracy: 0.8750 - val_loss: 0.4328 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7835 - loss: 0.4624 - val_accuracy: 0.8750 - val_loss: 0.4276 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8549 - loss: 0.3812 - val_accuracy: 0.8750 - val_loss: 0.4224 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7688 - loss: 0.4229 - val_accuracy: 0.9000 - val_loss: 0.4173 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8372 - loss: 0.4027 - val_accuracy: 0.9000 - val_loss: 0.4128 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8201 - loss: 0.3712 - val_accuracy: 0.9250 - val_loss: 0.4088 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8475 - loss: 0.3925 - val_accuracy: 0.9250 - val_loss: 0.4049 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8308 - loss: 0.3750 - val_accuracy: 0.9250 - val_loss: 0.4014 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8059 - loss: 0.4282 - val_accuracy: 0.9250 - val_loss: 0.3980 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8892 - loss: 0.3525 - val_accuracy: 0.9250 - val_loss: 0.3946 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8247 - loss: 0.4099 - val_accuracy: 0.9250 - val_loss: 0.3917 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8574 - loss: 0.3545 - val_accuracy: 0.9250 - val_loss: 0.3887 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8626 - loss: 0.3639 - val_accuracy: 0.9250 - val_loss: 0.3857 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8701 - loss: 0.3486 - val_accuracy: 0.9250 - val_loss: 0.3825 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8303 - loss: 0.3692 - val_accuracy: 0.9250 - val_loss: 0.3791 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8668 - loss: 0.3670 - val_accuracy: 0.9250 - val_loss: 0.3759 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8569 - loss: 0.3566 - val_accuracy: 0.9500 - val_loss: 0.3724 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8353 - loss: 0.3283 - val_accuracy: 0.9500 - val_loss: 0.3691 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8485 - loss: 0.3829 - val_accuracy: 0.9500 - val_loss: 0.3660 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8759 - loss: 0.3506 - val_accuracy: 0.9500 - val_loss: 0.3630 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8580 - loss: 0.3375 - val_accuracy: 0.9500 - val_loss: 0.3597 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8821 - loss: 0.3437 - val_accuracy: 0.9500 - val_loss: 0.3568 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8201 - loss: 0.3883 - val_accuracy: 0.9500 - val_loss: 0.3538 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8628 - loss: 0.3399 - val_accuracy: 0.9500 - val_loss: 0.3509 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8870 - loss: 0.3098 - val_accuracy: 0.9500 - val_loss: 0.3482 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8793 - loss: 0.3189 - val_accuracy: 0.9500 - val_loss: 0.3457 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8743 - loss: 0.3334 - val_accuracy: 0.9500 - val_loss: 0.3432 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8615 - loss: 0.3439 - val_accuracy: 0.9250 - val_loss: 0.3410 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9139 - loss: 0.2851 - val_accuracy: 0.9250 - val_loss: 0.3390 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8760 - loss: 0.2997 - val_accuracy: 0.9250 - val_loss: 0.3370 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8727 - loss: 0.3063 - val_accuracy: 0.9250 - val_loss: 0.3352 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8187 - loss: 0.3487 - val_accuracy: 0.9250 - val_loss: 0.3331 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9008 - loss: 0.2733 - val_accuracy: 0.9250 - val_loss: 0.3310 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8589 - loss: 0.3293 - val_accuracy: 0.9250 - val_loss: 0.3292 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8813 - loss: 0.3336 - val_accuracy: 0.9250 - val_loss: 0.3273 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8778 - loss: 0.3081 - val_accuracy: 0.9250 - val_loss: 0.3253 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9303 - loss: 0.2741 - val_accuracy: 0.9250 - val_loss: 0.3233 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8850 - loss: 0.3114 - val_accuracy: 0.9250 - val_loss: 0.3212 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9174 - loss: 0.2442 - val_accuracy: 0.9250 - val_loss: 0.3192 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8444 - loss: 0.3227 - val_accuracy: 0.9250 - val_loss: 0.3173 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8807 - loss: 0.3064 - val_accuracy: 0.9250 - val_loss: 0.3154 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9063 - loss: 0.2762 - val_accuracy: 0.9250 - val_loss: 0.3137 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8275 - loss: 0.3583 - val_accuracy: 0.9250 - val_loss: 0.3118 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8602 - loss: 0.2812 - val_accuracy: 0.9250 - val_loss: 0.3102 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8818 - loss: 0.3134 - val_accuracy: 0.9250 - val_loss: 0.3083 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9260 - loss: 0.2576 - val_accuracy: 0.9250 - val_loss: 0.3065 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8575 - loss: 0.2903 - val_accuracy: 0.9250 - val_loss: 0.3048 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9125 - loss: 0.2787 - val_accuracy: 0.9250 - val_loss: 0.3033 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9077 - loss: 0.2813 - val_accuracy: 0.9250 - val_loss: 0.3016 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8953 - loss: 0.3003 - val_accuracy: 0.9250 - val_loss: 0.3006 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8691 - loss: 0.3115 - val_accuracy: 0.9250 - val_loss: 0.2996 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8955 - loss: 0.2979 - val_accuracy: 0.9250 - val_loss: 0.2985 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8861 - loss: 0.2789 - val_accuracy: 0.9250 - val_loss: 0.2974 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8696 - loss: 0.3037 - val_accuracy: 0.9250 - val_loss: 0.2960 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8364 - loss: 0.3056 - val_accuracy: 0.9250 - val_loss: 0.2950 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9161 - loss: 0.2787 - val_accuracy: 0.9250 - val_loss: 0.2937 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8805 - loss: 0.2724 - val_accuracy: 0.9250 - val_loss: 0.2926 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8918 - loss: 0.2746 - val_accuracy: 0.9250 - val_loss: 0.2913 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9388 - loss: 0.2264 - val_accuracy: 0.9250 - val_loss: 0.2904 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8852 - loss: 0.2736 - val_accuracy: 0.9250 - val_loss: 0.2901 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9081 - loss: 0.2368 - val_accuracy: 0.9250 - val_loss: 0.2892 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8826 - loss: 0.2721 - val_accuracy: 0.9250 - val_loss: 0.2880 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8867 - loss: 0.2547 - val_accuracy: 0.9250 - val_loss: 0.2866 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8720 - loss: 0.2592 - val_accuracy: 0.9250 - val_loss: 0.2854 - learning_rate: 1.0000e-04\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Fold 4 - Val Accuracy: 0.9250, Val Log Loss: 0.2854, Val F1: 0.9268, Val Precision: 0.8636, Val Recall: 1.0000, Val Specificity: 0.8571, Val AUROC: 0.9749\n",
            "\n",
            "Training fold 5...\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5939 - loss: 0.7377 - val_accuracy: 0.5000 - val_loss: 0.7956 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5213 - loss: 0.8123 - val_accuracy: 0.5000 - val_loss: 0.7847 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5507 - loss: 0.7287 - val_accuracy: 0.5000 - val_loss: 0.7735 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5818 - loss: 0.7515 - val_accuracy: 0.5000 - val_loss: 0.7629 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5689 - loss: 0.7797 - val_accuracy: 0.5250 - val_loss: 0.7514 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6067 - loss: 0.7072 - val_accuracy: 0.5250 - val_loss: 0.7400 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6319 - loss: 0.7344 - val_accuracy: 0.5500 - val_loss: 0.7287 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5918 - loss: 0.7334 - val_accuracy: 0.6000 - val_loss: 0.7170 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6014 - loss: 0.6673 - val_accuracy: 0.6250 - val_loss: 0.7053 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6050 - loss: 0.6606 - val_accuracy: 0.6250 - val_loss: 0.6936 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6772 - loss: 0.5868 - val_accuracy: 0.6250 - val_loss: 0.6821 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6561 - loss: 0.6680 - val_accuracy: 0.6250 - val_loss: 0.6710 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6597 - loss: 0.6612 - val_accuracy: 0.6250 - val_loss: 0.6598 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6938 - loss: 0.5829 - val_accuracy: 0.6250 - val_loss: 0.6491 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7154 - loss: 0.6154 - val_accuracy: 0.6250 - val_loss: 0.6391 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7442 - loss: 0.5569 - val_accuracy: 0.6750 - val_loss: 0.6292 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7239 - loss: 0.5599 - val_accuracy: 0.7250 - val_loss: 0.6195 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7374 - loss: 0.5123 - val_accuracy: 0.7250 - val_loss: 0.6099 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7012 - loss: 0.5792 - val_accuracy: 0.7250 - val_loss: 0.6002 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7308 - loss: 0.5552 - val_accuracy: 0.7250 - val_loss: 0.5901 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7441 - loss: 0.5170 - val_accuracy: 0.7500 - val_loss: 0.5804 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7446 - loss: 0.5161 - val_accuracy: 0.7500 - val_loss: 0.5706 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7595 - loss: 0.5103 - val_accuracy: 0.7500 - val_loss: 0.5615 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7679 - loss: 0.4654 - val_accuracy: 0.7750 - val_loss: 0.5527 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7596 - loss: 0.4820 - val_accuracy: 0.7750 - val_loss: 0.5438 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7725 - loss: 0.5063 - val_accuracy: 0.7750 - val_loss: 0.5357 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7687 - loss: 0.4810 - val_accuracy: 0.8000 - val_loss: 0.5282 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7800 - loss: 0.4423 - val_accuracy: 0.8000 - val_loss: 0.5209 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7632 - loss: 0.4797 - val_accuracy: 0.8250 - val_loss: 0.5138 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7425 - loss: 0.4450 - val_accuracy: 0.8250 - val_loss: 0.5070 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8442 - loss: 0.4100 - val_accuracy: 0.8250 - val_loss: 0.5000 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7753 - loss: 0.4671 - val_accuracy: 0.8250 - val_loss: 0.4934 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7996 - loss: 0.4052 - val_accuracy: 0.8250 - val_loss: 0.4868 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8635 - loss: 0.3880 - val_accuracy: 0.8250 - val_loss: 0.4804 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7615 - loss: 0.4548 - val_accuracy: 0.8500 - val_loss: 0.4742 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8421 - loss: 0.3773 - val_accuracy: 0.8500 - val_loss: 0.4682 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8234 - loss: 0.4006 - val_accuracy: 0.8750 - val_loss: 0.4624 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.4211 - val_accuracy: 0.8750 - val_loss: 0.4569 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8468 - loss: 0.4191 - val_accuracy: 0.9000 - val_loss: 0.4512 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8128 - loss: 0.4071 - val_accuracy: 0.9000 - val_loss: 0.4461 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8482 - loss: 0.3587 - val_accuracy: 0.9250 - val_loss: 0.4416 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9054 - loss: 0.3592 - val_accuracy: 0.9250 - val_loss: 0.4371 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8158 - loss: 0.3715 - val_accuracy: 0.9250 - val_loss: 0.4328 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8726 - loss: 0.3402 - val_accuracy: 0.9250 - val_loss: 0.4288 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8950 - loss: 0.3174 - val_accuracy: 0.9250 - val_loss: 0.4251 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8826 - loss: 0.3372 - val_accuracy: 0.9250 - val_loss: 0.4215 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8442 - loss: 0.3388 - val_accuracy: 0.9500 - val_loss: 0.4177 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8730 - loss: 0.3729 - val_accuracy: 0.9500 - val_loss: 0.4143 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8435 - loss: 0.3398 - val_accuracy: 0.9500 - val_loss: 0.4109 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8474 - loss: 0.3685 - val_accuracy: 0.9500 - val_loss: 0.4075 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8665 - loss: 0.3437 - val_accuracy: 0.9500 - val_loss: 0.4043 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8668 - loss: 0.3705 - val_accuracy: 0.9500 - val_loss: 0.4009 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8679 - loss: 0.3289 - val_accuracy: 0.9500 - val_loss: 0.3978 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8753 - loss: 0.2966 - val_accuracy: 0.9500 - val_loss: 0.3950 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8825 - loss: 0.3052 - val_accuracy: 0.9500 - val_loss: 0.3923 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8354 - loss: 0.3543 - val_accuracy: 0.9500 - val_loss: 0.3900 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8662 - loss: 0.3283 - val_accuracy: 0.9500 - val_loss: 0.3876 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8866 - loss: 0.3241 - val_accuracy: 0.9500 - val_loss: 0.3856 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9145 - loss: 0.3137 - val_accuracy: 0.9500 - val_loss: 0.3834 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8837 - loss: 0.3128 - val_accuracy: 0.9500 - val_loss: 0.3817 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8885 - loss: 0.3028 - val_accuracy: 0.9500 - val_loss: 0.3801 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9171 - loss: 0.2725 - val_accuracy: 0.9250 - val_loss: 0.3788 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8783 - loss: 0.2936 - val_accuracy: 0.9250 - val_loss: 0.3772 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8852 - loss: 0.3283 - val_accuracy: 0.9250 - val_loss: 0.3755 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8418 - loss: 0.3350 - val_accuracy: 0.9250 - val_loss: 0.3739 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8543 - loss: 0.3114 - val_accuracy: 0.9250 - val_loss: 0.3722 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9293 - loss: 0.2579 - val_accuracy: 0.9250 - val_loss: 0.3704 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9067 - loss: 0.2555 - val_accuracy: 0.9250 - val_loss: 0.3689 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8947 - loss: 0.2735 - val_accuracy: 0.9250 - val_loss: 0.3673 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9049 - loss: 0.2669 - val_accuracy: 0.9250 - val_loss: 0.3656 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9172 - loss: 0.2733 - val_accuracy: 0.9250 - val_loss: 0.3640 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9263 - loss: 0.2880 - val_accuracy: 0.9250 - val_loss: 0.3625 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9359 - loss: 0.2555 - val_accuracy: 0.9250 - val_loss: 0.3612 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9088 - loss: 0.2884 - val_accuracy: 0.9250 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8983 - loss: 0.2447 - val_accuracy: 0.9250 - val_loss: 0.3587 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9218 - loss: 0.2552 - val_accuracy: 0.9250 - val_loss: 0.3577 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8914 - loss: 0.3059 - val_accuracy: 0.9250 - val_loss: 0.3567 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8923 - loss: 0.2685 - val_accuracy: 0.9250 - val_loss: 0.3560 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9220 - loss: 0.2707 - val_accuracy: 0.9250 - val_loss: 0.3549 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9370 - loss: 0.2532 - val_accuracy: 0.9250 - val_loss: 0.3539 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8964 - loss: 0.2656 - val_accuracy: 0.9250 - val_loss: 0.3529 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9126 - loss: 0.2503 - val_accuracy: 0.9250 - val_loss: 0.3517 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8977 - loss: 0.2559 - val_accuracy: 0.9250 - val_loss: 0.3507 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9293 - loss: 0.2269 - val_accuracy: 0.9250 - val_loss: 0.3498 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9164 - loss: 0.2428 - val_accuracy: 0.9250 - val_loss: 0.3488 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8470 - loss: 0.3054 - val_accuracy: 0.9250 - val_loss: 0.3480 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9095 - loss: 0.2529 - val_accuracy: 0.9250 - val_loss: 0.3476 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8995 - loss: 0.2324 - val_accuracy: 0.9250 - val_loss: 0.3473 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9170 - loss: 0.2193 - val_accuracy: 0.9250 - val_loss: 0.3467 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9075 - loss: 0.2399 - val_accuracy: 0.9250 - val_loss: 0.3460 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9117 - loss: 0.2322 - val_accuracy: 0.9250 - val_loss: 0.3455 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9428 - loss: 0.2080 - val_accuracy: 0.9250 - val_loss: 0.3445 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8868 - loss: 0.2407 - val_accuracy: 0.9250 - val_loss: 0.3435 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9280 - loss: 0.2407 - val_accuracy: 0.9250 - val_loss: 0.3428 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9185 - loss: 0.2473 - val_accuracy: 0.9250 - val_loss: 0.3419 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8820 - loss: 0.2988 - val_accuracy: 0.9250 - val_loss: 0.3416 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9062 - loss: 0.2600 - val_accuracy: 0.9250 - val_loss: 0.3415 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9213 - loss: 0.2149 - val_accuracy: 0.9250 - val_loss: 0.3413 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9244 - loss: 0.2109 - val_accuracy: 0.9250 - val_loss: 0.3413 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9625 - loss: 0.1932 - val_accuracy: 0.9250 - val_loss: 0.3412 - learning_rate: 1.0000e-04\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "Fold 5 - Val Accuracy: 0.9250, Val Log Loss: 0.3412, Val F1: 0.9189, Val Precision: 0.8947, Val Recall: 0.9444, Val Specificity: 0.9091, Val AUROC: 0.9293\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Val Accuracy: 0.8150\n",
            "Average Val Log Loss: 0.4059\n",
            "Average Val F1 Score: 0.8007\n",
            "Average Val Precision: 0.8267\n",
            "Average Val Recall: 0.7994\n",
            "Average Val Specificity: 0.8294\n",
            "Average Val AUROC: 0.9112\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Test Accuracy: 1.0000\n",
            "Test Log Loss: 0.1518\n",
            "Test F1 Score: 1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 1.0000\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoostClassifier\n",
        "\n",
        "# Scale the data for improved stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_test = scaler.transform(Xtest)\n",
        "\n",
        "# Define the AdaBoost model\n",
        "model = AdaBoostClassifier(n_estimators=25, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "# Metrics containers\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "specificities = []\n",
        "aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "for train_index, val_index in kf.split(X_train, ytrain):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split training data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = ytrain[train_index], ytrain[val_index]\n",
        "\n",
        "    # Train the AdaBoost classifier\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "    y_val_pred_classes = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    log_loss_value = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    accuracies.append(accuracy)\n",
        "    log_losses.append(log_loss_value)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    specificities.append(specificity)\n",
        "    aurocs.append(auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Log Loss: {log_loss_value:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, AUROC: {auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final aggregated cross-validation results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average Specificity: {np.mean(specificities):.4f}\")\n",
        "print(f\"Average AUROC: {np.mean(aurocs):.4f}\")\n",
        "\n",
        "# Final evaluation on the test set\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "model.fit(X_train, ytrain)  # Train the model on the full training data\n",
        "\n",
        "# Save the trained AdaBoost model before testing\n",
        "joblib.dump({\"model\": model, \"feature_names\": feature_names}, \"/content/gdrive/MyDrive/ALS/adaboost.pkl\")\n",
        "\n",
        "\n",
        "# Test set predictions\n",
        "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred_classes = model.predict(X_test)\n",
        "\n",
        "# Calculate test set metrics\n",
        "test_accuracy = accuracy_score(ytest, y_test_pred_classes)\n",
        "test_log_loss = log_loss(ytest, y_test_pred_proba)\n",
        "test_f1 = f1_score(ytest, y_test_pred_classes)\n",
        "test_precision = precision_score(ytest, y_test_pred_classes)\n",
        "test_recall = recall_score(ytest, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(ytest, y_test_pred_proba)\n",
        "\n",
        "# Specificity calculation\n",
        "cm_test = confusion_matrix(ytest, y_test_pred_classes)\n",
        "tn, fp, fn, tp = cm_test.ravel()\n",
        "test_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print test results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDSHwu6Qvwlj",
        "outputId": "bb5d9517-2185-43ac-88e1-d84e93eeadca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "Fold 1 - Accuracy: 0.7250, Log Loss: 0.5203, F1: 0.6857, Precision: 0.7500, Recall: 0.6316, Specificity: 0.8095, AUROC: 0.8070\n",
            "\n",
            "Training fold 2...\n",
            "Fold 2 - Accuracy: 0.8500, Log Loss: 0.3686, F1: 0.8235, Precision: 0.9333, Recall: 0.7368, Specificity: 0.9524, AUROC: 0.9749\n",
            "\n",
            "Training fold 3...\n",
            "Fold 3 - Accuracy: 0.7750, Log Loss: 0.5226, F1: 0.8000, Precision: 0.6923, Recall: 0.9474, Specificity: 0.6190, AUROC: 0.8471\n",
            "\n",
            "Training fold 4...\n",
            "Fold 4 - Accuracy: 0.8750, Log Loss: 0.3740, F1: 0.8718, Precision: 0.8500, Recall: 0.8947, Specificity: 0.8571, AUROC: 0.9549\n",
            "\n",
            "Training fold 5...\n",
            "Fold 5 - Accuracy: 0.8750, Log Loss: 0.3996, F1: 0.8780, Precision: 0.7826, Recall: 1.0000, Specificity: 0.7727, AUROC: 0.9482\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8200\n",
            "Average Log Loss: 0.4370\n",
            "Average F1 Score: 0.8118\n",
            "Average Precision: 0.8016\n",
            "Average Recall: 0.8421\n",
            "Average Specificity: 0.8022\n",
            "Average AUROC: 0.9064\n",
            "\n",
            "Final Test Evaluation...\n",
            "Test Accuracy: 1.0000\n",
            "Test Log Loss: 0.2446\n",
            "Test F1 Score: 1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 1.0000\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LGBMClassifier\n",
        "\n",
        "# Scale the data for improved stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_test = scaler.transform(Xtest)\n",
        "\n",
        "# Define model parameters\n",
        "model = LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics containers\n",
        "cv_accuracies = []\n",
        "cv_log_losses = []\n",
        "cv_f1_scores = []\n",
        "cv_precisions = []\n",
        "cv_recalls = []\n",
        "cv_specificities = []\n",
        "cv_aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "fold = 1\n",
        "for train_index, val_index in kf.split(X_train, ytrain):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = ytrain[train_index], ytrain[val_index]\n",
        "\n",
        "    # Scale the data within the fold\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold = scaler.transform(X_val_fold)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "    y_val_pred_classes = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    log_loss_value = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    cv_accuracies.append(accuracy)\n",
        "    cv_log_losses.append(log_loss_value)\n",
        "    cv_f1_scores.append(f1)\n",
        "    cv_precisions.append(precision)\n",
        "    cv_recalls.append(recall)\n",
        "    cv_specificities.append(specificity)\n",
        "    cv_aurocs.append(auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Log Loss: {log_loss_value:.4f}, F1: {f1:.4f}, \"\n",
        "          f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, AUROC: {auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final Cross-Validation Results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(cv_accuracies):.4f}\")\n",
        "print(f\"Average Log Loss: {np.mean(cv_log_losses):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(cv_f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(cv_precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(cv_recalls):.4f}\")\n",
        "print(f\"Average Specificity: {np.mean(cv_specificities):.4f}\")\n",
        "print(f\"Average AUROC: {np.mean(cv_aurocs):.4f}\")\n",
        "\n",
        "# Final Test Evaluation\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "\n",
        "# Train model on the entire training set\n",
        "model.fit(X_train, ytrain)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump({\"model\": model, \"feature_names\": df}, \"/content/gdrive/MyDrive/ALS/lgbm.pkl\")\n",
        "\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred_classes = model.predict(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(ytest, y_test_pred_classes)\n",
        "test_log_loss = log_loss(ytest, y_test_pred_proba)\n",
        "test_f1 = f1_score(ytest, y_test_pred_classes)\n",
        "test_precision = precision_score(ytest, y_test_pred_classes)\n",
        "test_recall = recall_score(ytest, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(ytest, y_test_pred_proba)\n",
        "\n",
        "cm_test = confusion_matrix(ytest, y_test_pred_classes)\n",
        "tn, fp, fn, tp = cm_test.ravel()\n",
        "test_specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzF8aROdg1lx",
        "outputId": "43730c77-05fc-4a86-d818-60d926a71cdb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "[LightGBM] [Info] Number of positive: 75, number of negative: 85\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1488\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468750 -> initscore=-0.125163\n",
            "[LightGBM] [Info] Start training from score -0.125163\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 1 - Accuracy: 0.6750, Log Loss: 0.9599, F1: 0.6061, Precision: 0.7143, Recall: 0.5263, Specificity: 0.8095, AUROC: 0.8145\n",
            "\n",
            "Training fold 2...\n",
            "[LightGBM] [Info] Number of positive: 75, number of negative: 85\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1475\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468750 -> initscore=-0.125163\n",
            "[LightGBM] [Info] Start training from score -0.125163\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 2 - Accuracy: 0.8750, Log Loss: 0.2632, F1: 0.8485, Precision: 1.0000, Recall: 0.7368, Specificity: 1.0000, AUROC: 1.0000\n",
            "\n",
            "Training fold 3...\n",
            "[LightGBM] [Info] Number of positive: 75, number of negative: 85\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1488\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468750 -> initscore=-0.125163\n",
            "[LightGBM] [Info] Start training from score -0.125163\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 3 - Accuracy: 0.8000, Log Loss: 0.6152, F1: 0.7895, Precision: 0.7895, Recall: 0.7895, Specificity: 0.8095, AUROC: 0.8947\n",
            "\n",
            "Training fold 4...\n",
            "[LightGBM] [Info] Number of positive: 75, number of negative: 85\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1486\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468750 -> initscore=-0.125163\n",
            "[LightGBM] [Info] Start training from score -0.125163\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 4 - Accuracy: 0.9000, Log Loss: 0.2451, F1: 0.8947, Precision: 0.8947, Recall: 0.8947, Specificity: 0.9048, AUROC: 0.9749\n",
            "\n",
            "Training fold 5...\n",
            "[LightGBM] [Info] Number of positive: 76, number of negative: 84\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1495\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.475000 -> initscore=-0.100083\n",
            "[LightGBM] [Info] Start training from score -0.100083\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 5 - Accuracy: 0.8500, Log Loss: 0.5227, F1: 0.8500, Precision: 0.7727, Recall: 0.9444, Specificity: 0.7727, AUROC: 0.9091\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8200\n",
            "Average Log Loss: 0.5212\n",
            "Average F1 Score: 0.7978\n",
            "Average Precision: 0.8342\n",
            "Average Recall: 0.7784\n",
            "Average Specificity: 0.8593\n",
            "Average AUROC: 0.9187\n",
            "\n",
            "Final Test Evaluation...\n",
            "[LightGBM] [Info] Number of positive: 94, number of negative: 106\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1826\n",
            "[LightGBM] [Info] Number of data points in the train set: 200, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.470000 -> initscore=-0.120144\n",
            "[LightGBM] [Info] Start training from score -0.120144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Test Accuracy: 1.0000\n",
            "Test Log Loss: 0.0921\n",
            "Test F1 Score: 1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 1.0000\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 1.0000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}