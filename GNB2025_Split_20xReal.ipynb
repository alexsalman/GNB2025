{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iOMBeyVyQ-7Q"
      },
      "outputs": [],
      "source": [
        "# !pip install sdv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h1sinr-sIkou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198589a9-3c67-4d49-bce8-deb8f04751fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from sdv.evaluation.single_table import evaluate_quality, run_diagnostic, get_column_plot\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import warnings\n",
        "# from pycaret.classification import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/content/gdrive')\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sdv.evaluation.single_table import get_column_plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U2q--EUBQcy",
        "outputId": "69ea248e-1a1e-4816-e78c-5ba4a0750f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(134, 38)\n",
            "(134, 38)\n",
            "(118, 35)\n",
            "Number of ALS: 97 (N.B. after dropping!)\n",
            "Number of HC: 21\n",
            "--------------------------------------------------\n",
            "DF dimensions: (118, 35)\n",
            "Index(['Disease', 'GCSF', 'IFNgamma', 'IL10', 'IL15', 'IL17A', 'IL1beta',\n",
            "       'IL2', 'IL4', 'IL6', 'IL8', 'MCP1', 'MIP1alfa', 'TNFalfa', 'VEGF',\n",
            "       'TTVlog', 'TTVcopies', 'acetic', 'Propionic', 'Butyric', 'isoButyric',\n",
            "       'isoValeric', '@MethylButyric', 'valeric', 'Hexanoic', 'Heptanoic',\n",
            "       'Nonanoic', '@EthylHexanoic', 'Octanoic', 'Decanoic', 'Benzoic',\n",
            "       'Dodecanoic', 'Tetradecanoic', 'Hexadecanoic', 'Octadecanoic'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Data cleaning: convert from 5th column to be float, replacing non number values with Nan, then drop. Then I convert disease in numeric format and round values to 2.\n",
        "\n",
        "df = pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/Database_Features_ML.xlsx')\n",
        "print(df.shape)\n",
        "df[df.columns[4:]] = df[df.columns[4:]].apply(pd.to_numeric, errors='coerce')\n",
        "print(df.shape)\n",
        "df.replace([\"#!NULL\", \"\"], np.nan, inplace=True)\n",
        "df.drop(columns=['ID Paziente', 'Età', 'Sesso'], inplace=True)\n",
        "df = df.dropna()\n",
        "print(df.shape)\n",
        "df['Disease'] = df['Disease'].replace({'ALS': 1, 'HEALTHY': 0})\n",
        "df = df.round(2)\n",
        "\n",
        "df_als = df[df['Disease'] == 1]\n",
        "df_hc = df[df['Disease'] == 0]\n",
        "\n",
        "print(f\"Number of ALS: {len(df_als)} (N.B. after dropping!)\")\n",
        "print(f\"Number of HC: {len(df_hc)}\")\n",
        "print('-'*50)\n",
        "print(f\"DF dimensions: {df.shape}\")\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NtG7rv20ENtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52aaabef-8826-48fc-ce67-abdc72e4539c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42, 35)\n"
          ]
        }
      ],
      "source": [
        "df_als_downsized = df_als.sample(n=21, random_state=42)\n",
        "df_downsized_for_synthesis = pd.concat([df_als_downsized, df_hc], ignore_index=True)\n",
        "print(df_downsized_for_synthesis.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6MvADyQwFGqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae17bd2e-87c1-4674-9015-67b98643dee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(840, 35)\n"
          ]
        }
      ],
      "source": [
        "# Detect metadata and ensure 'Disease' is categorical\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(df_downsized_for_synthesis)\n",
        "metadata.update_column('Disease', sdtype='categorical')\n",
        "\n",
        "# validate\n",
        "metadata.validate()\n",
        "metadata.validate_data(data=df_downsized_for_synthesis)\n",
        "\n",
        "# Initialize and fit the synthesizer\n",
        "synthesizer_GC = GaussianCopulaSynthesizer(\n",
        "        metadata,  # required\n",
        "        enforce_min_max_values=True,\n",
        "        enforce_rounding=False,\n",
        "        default_distribution='gaussian_kde'\n",
        "        )\n",
        "synthesizer_GC.fit(df_downsized_for_synthesis)\n",
        "\n",
        "# Generate synthetic data\n",
        "# Sample 1\n",
        "# synthetic_data = synthesizer_GC.sample(num_rows=420)\n",
        "# Sample 2\n",
        "synthetic_data = synthesizer_GC.sample(num_rows=840)\n",
        "print(synthetic_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EB5M3wrBHRwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2624eb17-33d1-469c-da21-1314bdfde839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 35/35 [00:00<00:00, 482.91it/s]|\n",
            "Column Shapes Score: 80.19%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 595/595 [00:06<00:00, 95.70it/s]| \n",
            "Column Pair Trends Score: 95.53%\n",
            "\n",
            "Overall Score (Average): 87.86%\n",
            "\n",
            "<sdmetrics.reports.single_table.quality_report.QualityReport object at 0x7d9d05c09ed0>\n"
          ]
        }
      ],
      "source": [
        "quality_report = evaluate_quality(df_downsized_for_synthesis, synthetic_data, metadata)\n",
        "print(quality_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KLeeRhFqIu7Y"
      },
      "outputs": [],
      "source": [
        "# Combine real and synthetic data for training\n",
        "# training_data = pd.concat([df_downsized_for_synthesis, synthetic_data], ignore_index=True)\n",
        "training_data = synthetic_data\n",
        "\n",
        "# training_data = synthetic_data\n",
        "X_train = training_data.drop(columns=['Disease']).values  # Features\n",
        "y_train = training_data['Disease'].values  # Target\n",
        "\n",
        "# Use all real data as the test set\n",
        "X_test = df.drop(columns=['Disease']).values  # Features\n",
        "y_test = df['Disease'].values  # Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8MqNwWBnJHYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad21835a-3a8b-4c0e-bb47-1094b29492ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(840, 34)\n",
            "(840,)\n",
            "(118, 34)\n",
            "(118,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, log_loss, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "\n",
        "# Scale the data for improved training stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Define the deep learning model\n",
        "def create_model(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', input_shape=(input_dim,)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.2),\n",
        "        # tf.keras.layers.Dense(32, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.1),\n",
        "        # tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "# Metrics containers\n",
        "val_accuracies = []\n",
        "val_log_losses = []\n",
        "val_f1_scores = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_specificities = []\n",
        "val_aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "for train_index, val_index in kf.split(X_train, y_train):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split training data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Create and train the model\n",
        "    model = create_model(X_train_fold.shape[1])\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, lr_scheduler],\n",
        "        class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    y_val_pred_proba = model.predict(X_val_fold)\n",
        "    y_val_pred_classes = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    val_log_loss = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    val_f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    val_precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    val_recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    val_auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    val_specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_log_losses.append(val_log_loss)\n",
        "    val_f1_scores.append(val_f1)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_specificities.append(val_specificity)\n",
        "    val_aurocs.append(val_auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Val Accuracy: {val_accuracy:.4f}, Val Log Loss: {val_log_loss:.4f}, \"\n",
        "          f\"Val F1: {val_f1:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, \"\n",
        "          f\"Val Specificity: {val_specificity:.4f}, Val AUROC: {val_auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final Cross-Validation Results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Val Accuracy: {np.mean(val_accuracies):.4f}\")\n",
        "print(f\"Average Val Log Loss: {np.mean(val_log_losses):.4f}\")\n",
        "print(f\"Average Val F1 Score: {np.mean(val_f1_scores):.4f}\")\n",
        "print(f\"Average Val Precision: {np.mean(val_precisions):.4f}\")\n",
        "print(f\"Average Val Recall: {np.mean(val_recalls):.4f}\")\n",
        "print(f\"Average Val Specificity: {np.mean(val_specificities):.4f}\")\n",
        "print(f\"Average Val AUROC: {np.mean(val_aurocs):.4f}\")\n",
        "\n",
        "# Final Test Evaluation\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "y_test_pred_proba = model.predict(X_test)\n",
        "y_test_pred_classes = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
        "test_log_loss = log_loss(y_test, y_test_pred_proba)\n",
        "test_f1 = f1_score(y_test, y_test_pred_classes)\n",
        "test_precision = precision_score(y_test, y_test_pred_classes)\n",
        "test_recall = recall_score(y_test, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "cm_test = confusion_matrix(y_test, y_test_pred_classes)\n",
        "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
        "test_specificity = tn_test / (tn_test + fp_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSZ_iQz4vnWE",
        "outputId": "5da7ce1a-2bce-4294-e841-1fb4790099e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4335 - loss: 1.0721 - val_accuracy: 0.4762 - val_loss: 0.8440 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4732 - loss: 0.9843 - val_accuracy: 0.5238 - val_loss: 0.7776 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4815 - loss: 0.8841 - val_accuracy: 0.5833 - val_loss: 0.7194 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5352 - loss: 0.8006 - val_accuracy: 0.6071 - val_loss: 0.6668 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5618 - loss: 0.7319 - val_accuracy: 0.6667 - val_loss: 0.6219 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6231 - loss: 0.6501 - val_accuracy: 0.7262 - val_loss: 0.5823 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6322 - loss: 0.6474 - val_accuracy: 0.7738 - val_loss: 0.5457 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6518 - loss: 0.6235 - val_accuracy: 0.7976 - val_loss: 0.5137 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5373 - val_accuracy: 0.7976 - val_loss: 0.4866 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7445 - loss: 0.5306 - val_accuracy: 0.7738 - val_loss: 0.4622 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7515 - loss: 0.5089 - val_accuracy: 0.8333 - val_loss: 0.4426 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.5003 - val_accuracy: 0.8333 - val_loss: 0.4245 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.4668 - val_accuracy: 0.8333 - val_loss: 0.4083 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7816 - loss: 0.4628 - val_accuracy: 0.8333 - val_loss: 0.3964 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 0.4213 - val_accuracy: 0.8333 - val_loss: 0.3848 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.4066 - val_accuracy: 0.8333 - val_loss: 0.3746 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7923 - loss: 0.4391 - val_accuracy: 0.8452 - val_loss: 0.3667 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.4357 - val_accuracy: 0.8333 - val_loss: 0.3596 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4365 - val_accuracy: 0.8571 - val_loss: 0.3538 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8324 - loss: 0.3811 - val_accuracy: 0.8452 - val_loss: 0.3488 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.3805 - val_accuracy: 0.8452 - val_loss: 0.3440 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8185 - loss: 0.3969 - val_accuracy: 0.8452 - val_loss: 0.3400 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.3863 - val_accuracy: 0.8452 - val_loss: 0.3362 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8288 - loss: 0.3819 - val_accuracy: 0.8452 - val_loss: 0.3334 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.3784 - val_accuracy: 0.8571 - val_loss: 0.3298 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.3777 - val_accuracy: 0.8690 - val_loss: 0.3273 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8383 - loss: 0.3585 - val_accuracy: 0.8690 - val_loss: 0.3257 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3777 - val_accuracy: 0.8571 - val_loss: 0.3231 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3391 - val_accuracy: 0.8571 - val_loss: 0.3206 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3442 - val_accuracy: 0.8571 - val_loss: 0.3182 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3713 - val_accuracy: 0.8571 - val_loss: 0.3173 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8502 - loss: 0.3521 - val_accuracy: 0.8571 - val_loss: 0.3158 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.3481 - val_accuracy: 0.8571 - val_loss: 0.3144 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3218 - val_accuracy: 0.8571 - val_loss: 0.3121 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3281 - val_accuracy: 0.8571 - val_loss: 0.3104 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.3453 - val_accuracy: 0.8571 - val_loss: 0.3100 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3259 - val_accuracy: 0.8571 - val_loss: 0.3098 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3373 - val_accuracy: 0.8571 - val_loss: 0.3095 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8620 - loss: 0.3119 - val_accuracy: 0.8571 - val_loss: 0.3077 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 0.3260 - val_accuracy: 0.8571 - val_loss: 0.3066 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2848 - val_accuracy: 0.8571 - val_loss: 0.3059 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.2998 - val_accuracy: 0.8571 - val_loss: 0.3056 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.3380 - val_accuracy: 0.8571 - val_loss: 0.3052 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3041 - val_accuracy: 0.8571 - val_loss: 0.3036 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.2975 - val_accuracy: 0.8571 - val_loss: 0.3023 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3377 - val_accuracy: 0.8571 - val_loss: 0.3019 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2877 - val_accuracy: 0.8571 - val_loss: 0.3022 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 0.3064 - val_accuracy: 0.8571 - val_loss: 0.3013 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3142 - val_accuracy: 0.8571 - val_loss: 0.3012 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3107 - val_accuracy: 0.8571 - val_loss: 0.2999 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3119 - val_accuracy: 0.8571 - val_loss: 0.2985 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8602 - loss: 0.3248 - val_accuracy: 0.8571 - val_loss: 0.2983 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8771 - loss: 0.2757 - val_accuracy: 0.8571 - val_loss: 0.2982 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8942 - loss: 0.2725 - val_accuracy: 0.8571 - val_loss: 0.2987 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.2808 - val_accuracy: 0.8571 - val_loss: 0.2978 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2658 - val_accuracy: 0.8571 - val_loss: 0.2968 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3068 - val_accuracy: 0.8571 - val_loss: 0.2974 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.2628 - val_accuracy: 0.8690 - val_loss: 0.2971 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8710 - loss: 0.2823 - val_accuracy: 0.8571 - val_loss: 0.2963 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.2948 - val_accuracy: 0.8571 - val_loss: 0.2966 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2701 - val_accuracy: 0.8690 - val_loss: 0.2968 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.2992 - val_accuracy: 0.8571 - val_loss: 0.2969 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2686 - val_accuracy: 0.8571 - val_loss: 0.2968 - learning_rate: 2.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.2751 - val_accuracy: 0.8571 - val_loss: 0.2966 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Fold 1 - Val Accuracy: 0.8571, Val Log Loss: 0.2963, Val F1: 0.8333, Val Precision: 0.9375, Val Recall: 0.7500, Val Specificity: 0.9545, Val AUROC: 0.9511\n",
            "\n",
            "Training fold 2...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5607 - loss: 0.8320 - val_accuracy: 0.5714 - val_loss: 0.7095 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: 0.7417 - val_accuracy: 0.6071 - val_loss: 0.6734 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6668 - loss: 0.6619 - val_accuracy: 0.6786 - val_loss: 0.6411 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6769 - loss: 0.6149 - val_accuracy: 0.6667 - val_loss: 0.6130 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.5687 - val_accuracy: 0.6905 - val_loss: 0.5919 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.5302 - val_accuracy: 0.7024 - val_loss: 0.5711 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.5100 - val_accuracy: 0.7381 - val_loss: 0.5519 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.4911 - val_accuracy: 0.7381 - val_loss: 0.5359 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4502 - val_accuracy: 0.7500 - val_loss: 0.5197 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.4323 - val_accuracy: 0.7500 - val_loss: 0.5055 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.4644 - val_accuracy: 0.7500 - val_loss: 0.4922 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4271 - val_accuracy: 0.7500 - val_loss: 0.4812 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.4548 - val_accuracy: 0.7619 - val_loss: 0.4692 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4497 - val_accuracy: 0.7619 - val_loss: 0.4595 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8319 - loss: 0.3873 - val_accuracy: 0.7738 - val_loss: 0.4483 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.4262 - val_accuracy: 0.7738 - val_loss: 0.4383 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7842 - loss: 0.4545 - val_accuracy: 0.7738 - val_loss: 0.4282 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4528 - val_accuracy: 0.7738 - val_loss: 0.4196 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4020 - val_accuracy: 0.7738 - val_loss: 0.4116 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4109 - val_accuracy: 0.7857 - val_loss: 0.4040 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.4218 - val_accuracy: 0.8095 - val_loss: 0.3987 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.3993 - val_accuracy: 0.8214 - val_loss: 0.3917 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.3642 - val_accuracy: 0.8214 - val_loss: 0.3856 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8464 - loss: 0.3610 - val_accuracy: 0.8214 - val_loss: 0.3805 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8168 - loss: 0.4094 - val_accuracy: 0.8214 - val_loss: 0.3746 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.3746 - val_accuracy: 0.8214 - val_loss: 0.3714 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.3617 - val_accuracy: 0.8214 - val_loss: 0.3663 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3579 - val_accuracy: 0.8214 - val_loss: 0.3628 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8697 - loss: 0.3262 - val_accuracy: 0.8214 - val_loss: 0.3594 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.3446 - val_accuracy: 0.8452 - val_loss: 0.3539 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.3476 - val_accuracy: 0.8571 - val_loss: 0.3506 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8290 - loss: 0.3508 - val_accuracy: 0.8690 - val_loss: 0.3443 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8472 - loss: 0.3455 - val_accuracy: 0.8810 - val_loss: 0.3406 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.3580 - val_accuracy: 0.8810 - val_loss: 0.3376 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.3606 - val_accuracy: 0.8929 - val_loss: 0.3334 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8178 - loss: 0.3915 - val_accuracy: 0.8929 - val_loss: 0.3299 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8474 - loss: 0.3520 - val_accuracy: 0.8929 - val_loss: 0.3261 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8630 - loss: 0.3353 - val_accuracy: 0.8929 - val_loss: 0.3230 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.3198 - val_accuracy: 0.8929 - val_loss: 0.3207 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.3085 - val_accuracy: 0.8929 - val_loss: 0.3177 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.3299 - val_accuracy: 0.9048 - val_loss: 0.3151 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.2970 - val_accuracy: 0.9048 - val_loss: 0.3113 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.3069 - val_accuracy: 0.9167 - val_loss: 0.3079 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2933 - val_accuracy: 0.9167 - val_loss: 0.3060 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.3429 - val_accuracy: 0.9167 - val_loss: 0.3029 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8421 - loss: 0.3315 - val_accuracy: 0.9167 - val_loss: 0.2992 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.2941 - val_accuracy: 0.9167 - val_loss: 0.2972 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3106 - val_accuracy: 0.9167 - val_loss: 0.2966 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.3142 - val_accuracy: 0.9167 - val_loss: 0.2938 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.3191 - val_accuracy: 0.9167 - val_loss: 0.2925 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2787 - val_accuracy: 0.9167 - val_loss: 0.2898 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3090 - val_accuracy: 0.9167 - val_loss: 0.2871 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.3267 - val_accuracy: 0.9167 - val_loss: 0.2837 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3281 - val_accuracy: 0.9167 - val_loss: 0.2805 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3059 - val_accuracy: 0.9167 - val_loss: 0.2782 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.2585 - val_accuracy: 0.9167 - val_loss: 0.2773 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.2786 - val_accuracy: 0.9167 - val_loss: 0.2770 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.2756 - val_accuracy: 0.9167 - val_loss: 0.2765 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.2660 - val_accuracy: 0.9167 - val_loss: 0.2746 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.2726 - val_accuracy: 0.9167 - val_loss: 0.2736 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.2686 - val_accuracy: 0.9167 - val_loss: 0.2737 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3089 - val_accuracy: 0.9167 - val_loss: 0.2716 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2508 - val_accuracy: 0.9167 - val_loss: 0.2708 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8627 - loss: 0.2934 - val_accuracy: 0.9167 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.2451 - val_accuracy: 0.9167 - val_loss: 0.2659 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.2652 - val_accuracy: 0.9167 - val_loss: 0.2638 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2481 - val_accuracy: 0.9167 - val_loss: 0.2611 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8659 - loss: 0.2886 - val_accuracy: 0.9167 - val_loss: 0.2607 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.2986 - val_accuracy: 0.9286 - val_loss: 0.2593 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.2545 - val_accuracy: 0.9286 - val_loss: 0.2577 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.2740 - val_accuracy: 0.9167 - val_loss: 0.2561 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2588 - val_accuracy: 0.9286 - val_loss: 0.2546 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.2847 - val_accuracy: 0.9286 - val_loss: 0.2539 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.2844 - val_accuracy: 0.9286 - val_loss: 0.2522 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2722 - val_accuracy: 0.9167 - val_loss: 0.2515 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.2825 - val_accuracy: 0.9167 - val_loss: 0.2524 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8876 - loss: 0.2470 - val_accuracy: 0.9167 - val_loss: 0.2503 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8664 - loss: 0.2783 - val_accuracy: 0.9167 - val_loss: 0.2499 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 0.2309 - val_accuracy: 0.9167 - val_loss: 0.2493 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.2621 - val_accuracy: 0.9167 - val_loss: 0.2478 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2568 - val_accuracy: 0.9167 - val_loss: 0.2463 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.2678 - val_accuracy: 0.9167 - val_loss: 0.2447 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2314 - val_accuracy: 0.9286 - val_loss: 0.2440 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2454 - val_accuracy: 0.9286 - val_loss: 0.2439 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.2521 - val_accuracy: 0.9286 - val_loss: 0.2432 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.2299 - val_accuracy: 0.9286 - val_loss: 0.2418 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8845 - loss: 0.2720 - val_accuracy: 0.9286 - val_loss: 0.2403 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2319 - val_accuracy: 0.9286 - val_loss: 0.2404 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2452 - val_accuracy: 0.9286 - val_loss: 0.2398 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.2375 - val_accuracy: 0.9286 - val_loss: 0.2402 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.2464 - val_accuracy: 0.9286 - val_loss: 0.2403 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.2637 - val_accuracy: 0.9286 - val_loss: 0.2372 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.2557 - val_accuracy: 0.9286 - val_loss: 0.2364 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2495 - val_accuracy: 0.9286 - val_loss: 0.2361 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2379 - val_accuracy: 0.9286 - val_loss: 0.2342 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2475 - val_accuracy: 0.9286 - val_loss: 0.2340 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2199 - val_accuracy: 0.9286 - val_loss: 0.2339 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.2125 - val_accuracy: 0.9286 - val_loss: 0.2337 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.2594 - val_accuracy: 0.9286 - val_loss: 0.2344 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.2652 - val_accuracy: 0.9286 - val_loss: 0.2356 - learning_rate: 1.0000e-04\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Fold 2 - Val Accuracy: 0.9286, Val Log Loss: 0.2337, Val F1: 0.9231, Val Precision: 0.9474, Val Recall: 0.9000, Val Specificity: 0.9545, Val AUROC: 0.9670\n",
            "\n",
            "Training fold 3...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5428 - loss: 0.7849 - val_accuracy: 0.6429 - val_loss: 0.6294 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6307 - loss: 0.6753 - val_accuracy: 0.7143 - val_loss: 0.5928 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6633 - loss: 0.6143 - val_accuracy: 0.7143 - val_loss: 0.5629 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.5682 - val_accuracy: 0.7500 - val_loss: 0.5372 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7177 - loss: 0.5419 - val_accuracy: 0.7738 - val_loss: 0.5152 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.4926 - val_accuracy: 0.7857 - val_loss: 0.4972 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7785 - loss: 0.4680 - val_accuracy: 0.7857 - val_loss: 0.4810 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7825 - loss: 0.4719 - val_accuracy: 0.7857 - val_loss: 0.4681 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7957 - loss: 0.4563 - val_accuracy: 0.7857 - val_loss: 0.4563 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8022 - loss: 0.4318 - val_accuracy: 0.8095 - val_loss: 0.4457 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.4453 - val_accuracy: 0.8095 - val_loss: 0.4368 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.4174 - val_accuracy: 0.7976 - val_loss: 0.4298 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3934 - val_accuracy: 0.7976 - val_loss: 0.4225 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3896 - val_accuracy: 0.7976 - val_loss: 0.4156 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.4000 - val_accuracy: 0.7976 - val_loss: 0.4111 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.3981 - val_accuracy: 0.7976 - val_loss: 0.4074 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8349 - loss: 0.3885 - val_accuracy: 0.7857 - val_loss: 0.4032 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8099 - loss: 0.4229 - val_accuracy: 0.7857 - val_loss: 0.3992 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.3769 - val_accuracy: 0.7857 - val_loss: 0.3960 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3959 - val_accuracy: 0.7857 - val_loss: 0.3936 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.3671 - val_accuracy: 0.7857 - val_loss: 0.3918 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.3547 - val_accuracy: 0.7976 - val_loss: 0.3891 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.3884 - val_accuracy: 0.8095 - val_loss: 0.3877 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3481 - val_accuracy: 0.8095 - val_loss: 0.3856 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.3617 - val_accuracy: 0.8095 - val_loss: 0.3839 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3550 - val_accuracy: 0.7976 - val_loss: 0.3824 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.3270 - val_accuracy: 0.7976 - val_loss: 0.3810 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3681 - val_accuracy: 0.8095 - val_loss: 0.3796 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3508 - val_accuracy: 0.8095 - val_loss: 0.3785 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.2983 - val_accuracy: 0.8214 - val_loss: 0.3768 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3445 - val_accuracy: 0.8333 - val_loss: 0.3753 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.2991 - val_accuracy: 0.8333 - val_loss: 0.3746 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.3283 - val_accuracy: 0.8333 - val_loss: 0.3741 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8662 - loss: 0.3332 - val_accuracy: 0.8333 - val_loss: 0.3744 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.3177 - val_accuracy: 0.8452 - val_loss: 0.3739 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2826 - val_accuracy: 0.8452 - val_loss: 0.3733 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3511 - val_accuracy: 0.8452 - val_loss: 0.3727 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3030 - val_accuracy: 0.8452 - val_loss: 0.3716 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.3195 - val_accuracy: 0.8452 - val_loss: 0.3711 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8428 - loss: 0.3255 - val_accuracy: 0.8452 - val_loss: 0.3702 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3200 - val_accuracy: 0.8452 - val_loss: 0.3695 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.3082 - val_accuracy: 0.8452 - val_loss: 0.3696 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8515 - loss: 0.3202 - val_accuracy: 0.8452 - val_loss: 0.3680 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.2875 - val_accuracy: 0.8452 - val_loss: 0.3688 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.3128 - val_accuracy: 0.8333 - val_loss: 0.3690 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8761 - loss: 0.2973 - val_accuracy: 0.8333 - val_loss: 0.3693 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3159 - val_accuracy: 0.8333 - val_loss: 0.3695 - learning_rate: 2.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8620 - loss: 0.2795 - val_accuracy: 0.8333 - val_loss: 0.3692 - learning_rate: 2.0000e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d9ca86b9da0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d9ca86b9da0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Fold 3 - Val Accuracy: 0.8452, Val Log Loss: 0.3680, Val F1: 0.8395, Val Precision: 0.8293, Val Recall: 0.8500, Val Specificity: 0.8409, Val AUROC: 0.9159\n",
            "\n",
            "Training fold 4...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6166 - loss: 0.6807 - val_accuracy: 0.5833 - val_loss: 0.6689 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6539 - loss: 0.6497 - val_accuracy: 0.6190 - val_loss: 0.6313 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.5510 - val_accuracy: 0.6667 - val_loss: 0.5995 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.5404 - val_accuracy: 0.6905 - val_loss: 0.5692 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7627 - loss: 0.4738 - val_accuracy: 0.7262 - val_loss: 0.5445 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.4811 - val_accuracy: 0.7381 - val_loss: 0.5202 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.4407 - val_accuracy: 0.7500 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4363 - val_accuracy: 0.7500 - val_loss: 0.4826 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4174 - val_accuracy: 0.7738 - val_loss: 0.4667 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4338 - val_accuracy: 0.7857 - val_loss: 0.4546 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.4130 - val_accuracy: 0.7857 - val_loss: 0.4442 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.4310 - val_accuracy: 0.7976 - val_loss: 0.4333 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.4023 - val_accuracy: 0.7976 - val_loss: 0.4246 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.4150 - val_accuracy: 0.8095 - val_loss: 0.4164 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.3755 - val_accuracy: 0.8095 - val_loss: 0.4086 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.3587 - val_accuracy: 0.8095 - val_loss: 0.4019 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3616 - val_accuracy: 0.8214 - val_loss: 0.3959 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8609 - loss: 0.3472 - val_accuracy: 0.8214 - val_loss: 0.3917 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8265 - loss: 0.3681 - val_accuracy: 0.8333 - val_loss: 0.3875 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.3635 - val_accuracy: 0.8214 - val_loss: 0.3839 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.3610 - val_accuracy: 0.8214 - val_loss: 0.3802 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: 0.3479 - val_accuracy: 0.8214 - val_loss: 0.3750 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.3366 - val_accuracy: 0.8214 - val_loss: 0.3734 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8653 - loss: 0.3224 - val_accuracy: 0.8214 - val_loss: 0.3712 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.3429 - val_accuracy: 0.8214 - val_loss: 0.3670 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.3415 - val_accuracy: 0.8214 - val_loss: 0.3654 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3270 - val_accuracy: 0.8214 - val_loss: 0.3620 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8480 - loss: 0.3282 - val_accuracy: 0.8333 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.3286 - val_accuracy: 0.8333 - val_loss: 0.3577 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.3037 - val_accuracy: 0.8333 - val_loss: 0.3561 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8900 - loss: 0.2972 - val_accuracy: 0.8333 - val_loss: 0.3534 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8321 - loss: 0.3625 - val_accuracy: 0.8333 - val_loss: 0.3522 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8614 - loss: 0.3266 - val_accuracy: 0.8333 - val_loss: 0.3496 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8488 - loss: 0.3320 - val_accuracy: 0.8333 - val_loss: 0.3476 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8438 - loss: 0.3183 - val_accuracy: 0.8333 - val_loss: 0.3462 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8714 - loss: 0.3073 - val_accuracy: 0.8333 - val_loss: 0.3441 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.3234 - val_accuracy: 0.8333 - val_loss: 0.3435 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.2705 - val_accuracy: 0.8333 - val_loss: 0.3408 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 0.3048 - val_accuracy: 0.8333 - val_loss: 0.3403 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.3047 - val_accuracy: 0.8333 - val_loss: 0.3383 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 0.2925 - val_accuracy: 0.8333 - val_loss: 0.3361 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.2966 - val_accuracy: 0.8333 - val_loss: 0.3347 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.3059 - val_accuracy: 0.8333 - val_loss: 0.3339 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.3121 - val_accuracy: 0.8333 - val_loss: 0.3309 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.2990 - val_accuracy: 0.8333 - val_loss: 0.3295 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2918 - val_accuracy: 0.8333 - val_loss: 0.3288 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.3035 - val_accuracy: 0.8452 - val_loss: 0.3291 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.2891 - val_accuracy: 0.8452 - val_loss: 0.3277 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8705 - loss: 0.2961 - val_accuracy: 0.8452 - val_loss: 0.3263 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.2811 - val_accuracy: 0.8452 - val_loss: 0.3248 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.2879 - val_accuracy: 0.8452 - val_loss: 0.3231 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 0.2975 - val_accuracy: 0.8452 - val_loss: 0.3220 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.3047 - val_accuracy: 0.8452 - val_loss: 0.3223 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.2970 - val_accuracy: 0.8452 - val_loss: 0.3217 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.2730 - val_accuracy: 0.8452 - val_loss: 0.3205 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8982 - loss: 0.2594 - val_accuracy: 0.8452 - val_loss: 0.3183 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.2680 - val_accuracy: 0.8452 - val_loss: 0.3181 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 0.2915 - val_accuracy: 0.8452 - val_loss: 0.3172 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2870 - val_accuracy: 0.8452 - val_loss: 0.3155 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2607 - val_accuracy: 0.8452 - val_loss: 0.3170 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.2844 - val_accuracy: 0.8571 - val_loss: 0.3143 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.2589 - val_accuracy: 0.8452 - val_loss: 0.3191 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.2645 - val_accuracy: 0.8452 - val_loss: 0.3168 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.2747 - val_accuracy: 0.8571 - val_loss: 0.3153 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2452 - val_accuracy: 0.8571 - val_loss: 0.3143 - learning_rate: 2.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8511 - loss: 0.2952 - val_accuracy: 0.8571 - val_loss: 0.3145 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Fold 4 - Val Accuracy: 0.8571, Val Log Loss: 0.3143, Val F1: 0.8571, Val Precision: 0.8182, Val Recall: 0.9000, Val Specificity: 0.8182, Val AUROC: 0.9449\n",
            "\n",
            "Training fold 5...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6097 - loss: 0.7509 - val_accuracy: 0.6071 - val_loss: 0.6623 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 0.6654 - val_accuracy: 0.6548 - val_loss: 0.6200 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7041 - loss: 0.5890 - val_accuracy: 0.7024 - val_loss: 0.5826 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 0.5731 - val_accuracy: 0.7381 - val_loss: 0.5514 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6632 - loss: 0.5731 - val_accuracy: 0.7500 - val_loss: 0.5234 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.5200 - val_accuracy: 0.7619 - val_loss: 0.5013 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.4784 - val_accuracy: 0.7500 - val_loss: 0.4814 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4537 - val_accuracy: 0.7738 - val_loss: 0.4641 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4394 - val_accuracy: 0.7738 - val_loss: 0.4485 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7891 - loss: 0.4642 - val_accuracy: 0.7857 - val_loss: 0.4342 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8176 - loss: 0.4237 - val_accuracy: 0.7976 - val_loss: 0.4216 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 0.3739 - val_accuracy: 0.7976 - val_loss: 0.4096 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.4440 - val_accuracy: 0.7976 - val_loss: 0.4006 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.3919 - val_accuracy: 0.7976 - val_loss: 0.3929 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3509 - val_accuracy: 0.8095 - val_loss: 0.3861 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.3870 - val_accuracy: 0.8095 - val_loss: 0.3803 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8635 - loss: 0.3330 - val_accuracy: 0.8214 - val_loss: 0.3746 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.3845 - val_accuracy: 0.8214 - val_loss: 0.3696 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.3230 - val_accuracy: 0.8214 - val_loss: 0.3645 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.3711 - val_accuracy: 0.8333 - val_loss: 0.3601 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.3711 - val_accuracy: 0.8214 - val_loss: 0.3567 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8443 - loss: 0.3271 - val_accuracy: 0.8333 - val_loss: 0.3529 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.3233 - val_accuracy: 0.8333 - val_loss: 0.3502 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.3724 - val_accuracy: 0.8333 - val_loss: 0.3479 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.4092 - val_accuracy: 0.8214 - val_loss: 0.3460 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.3246 - val_accuracy: 0.8333 - val_loss: 0.3434 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - loss: 0.3261 - val_accuracy: 0.8333 - val_loss: 0.3419 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.3296 - val_accuracy: 0.8333 - val_loss: 0.3397 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8790 - loss: 0.3137 - val_accuracy: 0.8333 - val_loss: 0.3377 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.3022 - val_accuracy: 0.8333 - val_loss: 0.3359 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.3200 - val_accuracy: 0.8214 - val_loss: 0.3342 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3171 - val_accuracy: 0.8214 - val_loss: 0.3341 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8245 - loss: 0.3364 - val_accuracy: 0.8214 - val_loss: 0.3331 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8683 - loss: 0.2946 - val_accuracy: 0.8214 - val_loss: 0.3323 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.2999 - val_accuracy: 0.8214 - val_loss: 0.3308 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8701 - loss: 0.3165 - val_accuracy: 0.8214 - val_loss: 0.3303 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8713 - loss: 0.2907 - val_accuracy: 0.8214 - val_loss: 0.3300 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8658 - loss: 0.3047 - val_accuracy: 0.8214 - val_loss: 0.3294 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8671 - loss: 0.2915 - val_accuracy: 0.8214 - val_loss: 0.3288 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8936 - loss: 0.2825 - val_accuracy: 0.8214 - val_loss: 0.3280 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8763 - loss: 0.2791 - val_accuracy: 0.8214 - val_loss: 0.3277 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8821 - loss: 0.3092 - val_accuracy: 0.8214 - val_loss: 0.3277 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.3211 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 0.2898 - val_accuracy: 0.8214 - val_loss: 0.3278 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.2779 - val_accuracy: 0.8214 - val_loss: 0.3284 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.2807 - val_accuracy: 0.8214 - val_loss: 0.3278 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.2887 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 2.0000e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9034 - loss: 0.2663 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 2.0000e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.2640 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 2.0000e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.2901 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 1.0000e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.2778 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 1.0000e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.2505 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 1.0000e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.2899 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 1.0000e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3078 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 1.0000e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.3378 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 1.0000e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3141 - val_accuracy: 0.8214 - val_loss: 0.3275 - learning_rate: 1.0000e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3179 - val_accuracy: 0.8214 - val_loss: 0.3273 - learning_rate: 1.0000e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.2752 - val_accuracy: 0.8214 - val_loss: 0.3273 - learning_rate: 1.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.2693 - val_accuracy: 0.8214 - val_loss: 0.3273 - learning_rate: 1.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.2709 - val_accuracy: 0.8214 - val_loss: 0.3273 - learning_rate: 1.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.2927 - val_accuracy: 0.8214 - val_loss: 0.3273 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2293 - val_accuracy: 0.8214 - val_loss: 0.3274 - learning_rate: 1.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2701 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 1.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.2891 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 1.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.2715 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 1.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.2608 - val_accuracy: 0.8214 - val_loss: 0.3276 - learning_rate: 1.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Fold 5 - Val Accuracy: 0.8214, Val Log Loss: 0.3273, Val F1: 0.8193, Val Precision: 0.8095, Val Recall: 0.8293, Val Specificity: 0.8140, Val AUROC: 0.9274\n",
            "\n",
            "Training fold 6...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5719 - loss: 0.7162 - val_accuracy: 0.6548 - val_loss: 0.6275 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.6616 - val_accuracy: 0.7381 - val_loss: 0.5941 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 0.6129 - val_accuracy: 0.7500 - val_loss: 0.5626 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7251 - loss: 0.5720 - val_accuracy: 0.7381 - val_loss: 0.5343 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7100 - loss: 0.5747 - val_accuracy: 0.7738 - val_loss: 0.5091 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5475 - val_accuracy: 0.7976 - val_loss: 0.4863 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7640 - loss: 0.5002 - val_accuracy: 0.7976 - val_loss: 0.4676 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7530 - loss: 0.4866 - val_accuracy: 0.7976 - val_loss: 0.4515 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4538 - val_accuracy: 0.7976 - val_loss: 0.4401 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4446 - val_accuracy: 0.7976 - val_loss: 0.4304 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.4459 - val_accuracy: 0.7976 - val_loss: 0.4219 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.4461 - val_accuracy: 0.8095 - val_loss: 0.4163 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4390 - val_accuracy: 0.8095 - val_loss: 0.4107 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4355 - val_accuracy: 0.8214 - val_loss: 0.4058 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.3862 - val_accuracy: 0.8214 - val_loss: 0.4014 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.3875 - val_accuracy: 0.8214 - val_loss: 0.3965 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8459 - loss: 0.3872 - val_accuracy: 0.8214 - val_loss: 0.3927 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8052 - loss: 0.4506 - val_accuracy: 0.8214 - val_loss: 0.3898 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.3627 - val_accuracy: 0.8214 - val_loss: 0.3865 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.3785 - val_accuracy: 0.8214 - val_loss: 0.3844 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.4035 - val_accuracy: 0.8214 - val_loss: 0.3816 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.3701 - val_accuracy: 0.8214 - val_loss: 0.3792 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3575 - val_accuracy: 0.8095 - val_loss: 0.3780 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8516 - loss: 0.3387 - val_accuracy: 0.8214 - val_loss: 0.3758 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.3744 - val_accuracy: 0.8214 - val_loss: 0.3731 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3503 - val_accuracy: 0.8214 - val_loss: 0.3714 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8380 - loss: 0.3695 - val_accuracy: 0.8333 - val_loss: 0.3693 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.3460 - val_accuracy: 0.8333 - val_loss: 0.3676 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 0.3453 - val_accuracy: 0.8333 - val_loss: 0.3669 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.3512 - val_accuracy: 0.8333 - val_loss: 0.3656 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.3514 - val_accuracy: 0.8333 - val_loss: 0.3629 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.3557 - val_accuracy: 0.8333 - val_loss: 0.3617 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8666 - loss: 0.3069 - val_accuracy: 0.8333 - val_loss: 0.3593 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8378 - loss: 0.3348 - val_accuracy: 0.8333 - val_loss: 0.3567 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8471 - loss: 0.3197 - val_accuracy: 0.8333 - val_loss: 0.3551 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 0.3494 - val_accuracy: 0.8333 - val_loss: 0.3538 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.3032 - val_accuracy: 0.8333 - val_loss: 0.3532 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8745 - loss: 0.2888 - val_accuracy: 0.8452 - val_loss: 0.3522 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8842 - loss: 0.2935 - val_accuracy: 0.8452 - val_loss: 0.3501 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8506 - loss: 0.3188 - val_accuracy: 0.8452 - val_loss: 0.3487 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8796 - loss: 0.2812 - val_accuracy: 0.8452 - val_loss: 0.3477 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8528 - loss: 0.3089 - val_accuracy: 0.8452 - val_loss: 0.3452 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8807 - loss: 0.2764 - val_accuracy: 0.8452 - val_loss: 0.3439 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.3196 - val_accuracy: 0.8452 - val_loss: 0.3436 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8613 - loss: 0.3134 - val_accuracy: 0.8571 - val_loss: 0.3432 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.2953 - val_accuracy: 0.8571 - val_loss: 0.3437 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8710 - loss: 0.2883 - val_accuracy: 0.8690 - val_loss: 0.3434 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.2723 - val_accuracy: 0.8690 - val_loss: 0.3430 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.2803 - val_accuracy: 0.8690 - val_loss: 0.3422 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.2796 - val_accuracy: 0.8690 - val_loss: 0.3416 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3025 - val_accuracy: 0.8690 - val_loss: 0.3407 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3060 - val_accuracy: 0.8690 - val_loss: 0.3384 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.2920 - val_accuracy: 0.8690 - val_loss: 0.3374 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3035 - val_accuracy: 0.8690 - val_loss: 0.3380 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8708 - loss: 0.2837 - val_accuracy: 0.8690 - val_loss: 0.3378 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.2833 - val_accuracy: 0.8690 - val_loss: 0.3372 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.2891 - val_accuracy: 0.8690 - val_loss: 0.3361 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.2668 - val_accuracy: 0.8690 - val_loss: 0.3355 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.2785 - val_accuracy: 0.8690 - val_loss: 0.3335 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.2891 - val_accuracy: 0.8690 - val_loss: 0.3324 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.2856 - val_accuracy: 0.8690 - val_loss: 0.3313 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.2664 - val_accuracy: 0.8810 - val_loss: 0.3307 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8709 - loss: 0.2884 - val_accuracy: 0.8810 - val_loss: 0.3309 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.2705 - val_accuracy: 0.8810 - val_loss: 0.3305 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.2616 - val_accuracy: 0.8690 - val_loss: 0.3309 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8727 - loss: 0.2690 - val_accuracy: 0.8810 - val_loss: 0.3301 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.3110 - val_accuracy: 0.8810 - val_loss: 0.3296 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.2469 - val_accuracy: 0.8810 - val_loss: 0.3296 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2550 - val_accuracy: 0.8810 - val_loss: 0.3292 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.2738 - val_accuracy: 0.8690 - val_loss: 0.3297 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.2536 - val_accuracy: 0.8810 - val_loss: 0.3293 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.2462 - val_accuracy: 0.8810 - val_loss: 0.3300 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 0.2379 - val_accuracy: 0.8810 - val_loss: 0.3300 - learning_rate: 2.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2641 - val_accuracy: 0.8690 - val_loss: 0.3301 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Fold 6 - Val Accuracy: 0.8810, Val Log Loss: 0.3292, Val F1: 0.8864, Val Precision: 0.8298, Val Recall: 0.9512, Val Specificity: 0.8140, Val AUROC: 0.9353\n",
            "\n",
            "Training fold 7...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5660 - loss: 0.7261 - val_accuracy: 0.5119 - val_loss: 0.6401 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5814 - loss: 0.6871 - val_accuracy: 0.6310 - val_loss: 0.6038 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6666 - loss: 0.6269 - val_accuracy: 0.7262 - val_loss: 0.5746 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6907 - loss: 0.5667 - val_accuracy: 0.7381 - val_loss: 0.5512 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7202 - loss: 0.5543 - val_accuracy: 0.7500 - val_loss: 0.5310 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7040 - loss: 0.5320 - val_accuracy: 0.7619 - val_loss: 0.5130 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7582 - loss: 0.4976 - val_accuracy: 0.7619 - val_loss: 0.4972 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.4439 - val_accuracy: 0.7857 - val_loss: 0.4852 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7859 - loss: 0.4554 - val_accuracy: 0.7738 - val_loss: 0.4749 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4347 - val_accuracy: 0.7738 - val_loss: 0.4665 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.4411 - val_accuracy: 0.7738 - val_loss: 0.4601 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.4121 - val_accuracy: 0.7738 - val_loss: 0.4559 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.3947 - val_accuracy: 0.7738 - val_loss: 0.4514 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4070 - val_accuracy: 0.7738 - val_loss: 0.4489 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8030 - loss: 0.4037 - val_accuracy: 0.7738 - val_loss: 0.4461 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8201 - loss: 0.3995 - val_accuracy: 0.7738 - val_loss: 0.4433 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8477 - loss: 0.3724 - val_accuracy: 0.7738 - val_loss: 0.4408 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8216 - loss: 0.3801 - val_accuracy: 0.7857 - val_loss: 0.4384 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8226 - loss: 0.3593 - val_accuracy: 0.7857 - val_loss: 0.4363 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8206 - loss: 0.3875 - val_accuracy: 0.7857 - val_loss: 0.4331 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8341 - loss: 0.3452 - val_accuracy: 0.7857 - val_loss: 0.4300 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8345 - loss: 0.3473 - val_accuracy: 0.7857 - val_loss: 0.4293 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8279 - loss: 0.3578 - val_accuracy: 0.7857 - val_loss: 0.4278 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8321 - loss: 0.3598 - val_accuracy: 0.7857 - val_loss: 0.4274 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 0.3331 - val_accuracy: 0.7857 - val_loss: 0.4270 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8401 - loss: 0.3421 - val_accuracy: 0.7857 - val_loss: 0.4248 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8588 - loss: 0.3239 - val_accuracy: 0.7857 - val_loss: 0.4227 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8531 - loss: 0.3069 - val_accuracy: 0.7857 - val_loss: 0.4216 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8430 - loss: 0.3388 - val_accuracy: 0.8095 - val_loss: 0.4210 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8625 - loss: 0.3300 - val_accuracy: 0.8095 - val_loss: 0.4171 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8493 - loss: 0.3327 - val_accuracy: 0.8214 - val_loss: 0.4160 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8763 - loss: 0.3021 - val_accuracy: 0.8095 - val_loss: 0.4148 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8847 - loss: 0.2767 - val_accuracy: 0.8095 - val_loss: 0.4143 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8661 - loss: 0.3198 - val_accuracy: 0.8214 - val_loss: 0.4138 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8792 - loss: 0.2790 - val_accuracy: 0.8095 - val_loss: 0.4141 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - loss: 0.3055 - val_accuracy: 0.8214 - val_loss: 0.4121 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8794 - loss: 0.2759 - val_accuracy: 0.8214 - val_loss: 0.4109 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8459 - loss: 0.3224 - val_accuracy: 0.8214 - val_loss: 0.4119 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3319 - val_accuracy: 0.8214 - val_loss: 0.4105 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.2996 - val_accuracy: 0.8214 - val_loss: 0.4085 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3181 - val_accuracy: 0.8214 - val_loss: 0.4075 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.2742 - val_accuracy: 0.8214 - val_loss: 0.4059 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.2865 - val_accuracy: 0.8214 - val_loss: 0.4035 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.2936 - val_accuracy: 0.8333 - val_loss: 0.4012 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.2840 - val_accuracy: 0.8333 - val_loss: 0.3996 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.3173 - val_accuracy: 0.8333 - val_loss: 0.3974 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.2931 - val_accuracy: 0.8333 - val_loss: 0.3972 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2633 - val_accuracy: 0.8333 - val_loss: 0.3971 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.2789 - val_accuracy: 0.8333 - val_loss: 0.3965 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.2796 - val_accuracy: 0.8452 - val_loss: 0.3970 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.2885 - val_accuracy: 0.8452 - val_loss: 0.3936 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8651 - loss: 0.2805 - val_accuracy: 0.8452 - val_loss: 0.3923 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2574 - val_accuracy: 0.8452 - val_loss: 0.3910 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.2761 - val_accuracy: 0.8452 - val_loss: 0.3889 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2597 - val_accuracy: 0.8452 - val_loss: 0.3885 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.2835 - val_accuracy: 0.8452 - val_loss: 0.3877 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.2769 - val_accuracy: 0.8452 - val_loss: 0.3879 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8785 - loss: 0.2790 - val_accuracy: 0.8452 - val_loss: 0.3878 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.2797 - val_accuracy: 0.8452 - val_loss: 0.3902 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8854 - loss: 0.2632 - val_accuracy: 0.8452 - val_loss: 0.3900 - learning_rate: 2.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.2966 - val_accuracy: 0.8452 - val_loss: 0.3897 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Fold 7 - Val Accuracy: 0.8452, Val Log Loss: 0.3877, Val F1: 0.8471, Val Precision: 0.8182, Val Recall: 0.8780, Val Specificity: 0.8140, Val AUROC: 0.9166\n",
            "\n",
            "Training fold 8...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5366 - loss: 0.7487 - val_accuracy: 0.5595 - val_loss: 0.6944 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6019 - loss: 0.6710 - val_accuracy: 0.6548 - val_loss: 0.6420 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6749 - loss: 0.6105 - val_accuracy: 0.7143 - val_loss: 0.5920 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.5590 - val_accuracy: 0.8214 - val_loss: 0.5524 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.5268 - val_accuracy: 0.8333 - val_loss: 0.5167 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7483 - loss: 0.5026 - val_accuracy: 0.8333 - val_loss: 0.4899 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7512 - loss: 0.4868 - val_accuracy: 0.8333 - val_loss: 0.4685 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4910 - val_accuracy: 0.8333 - val_loss: 0.4485 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7784 - loss: 0.4642 - val_accuracy: 0.8333 - val_loss: 0.4311 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7599 - loss: 0.4619 - val_accuracy: 0.8571 - val_loss: 0.4145 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.4094 - val_accuracy: 0.8571 - val_loss: 0.4024 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.4447 - val_accuracy: 0.8690 - val_loss: 0.3921 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4279 - val_accuracy: 0.8690 - val_loss: 0.3823 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7772 - loss: 0.4269 - val_accuracy: 0.8571 - val_loss: 0.3755 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8302 - loss: 0.3880 - val_accuracy: 0.8690 - val_loss: 0.3681 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.3863 - val_accuracy: 0.8690 - val_loss: 0.3622 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4143 - val_accuracy: 0.8690 - val_loss: 0.3570 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.3968 - val_accuracy: 0.8690 - val_loss: 0.3525 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.3757 - val_accuracy: 0.8690 - val_loss: 0.3487 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.3506 - val_accuracy: 0.8690 - val_loss: 0.3451 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.3679 - val_accuracy: 0.8690 - val_loss: 0.3411 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8280 - loss: 0.3600 - val_accuracy: 0.8690 - val_loss: 0.3376 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8442 - loss: 0.3489 - val_accuracy: 0.8690 - val_loss: 0.3334 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8449 - loss: 0.3572 - val_accuracy: 0.8690 - val_loss: 0.3315 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8413 - loss: 0.3572 - val_accuracy: 0.8690 - val_loss: 0.3286 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8238 - loss: 0.3732 - val_accuracy: 0.8810 - val_loss: 0.3266 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8829 - loss: 0.3045 - val_accuracy: 0.8690 - val_loss: 0.3236 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.3606 - val_accuracy: 0.8690 - val_loss: 0.3221 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8438 - loss: 0.3321 - val_accuracy: 0.8690 - val_loss: 0.3201 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.3649 - val_accuracy: 0.8690 - val_loss: 0.3185 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.3250 - val_accuracy: 0.8690 - val_loss: 0.3176 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8532 - loss: 0.3183 - val_accuracy: 0.8690 - val_loss: 0.3162 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8614 - loss: 0.3060 - val_accuracy: 0.8690 - val_loss: 0.3143 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8621 - loss: 0.2984 - val_accuracy: 0.8810 - val_loss: 0.3132 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8137 - loss: 0.3588 - val_accuracy: 0.8690 - val_loss: 0.3130 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8567 - loss: 0.3246 - val_accuracy: 0.8690 - val_loss: 0.3119 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 0.3225 - val_accuracy: 0.8690 - val_loss: 0.3106 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8553 - loss: 0.3124 - val_accuracy: 0.8571 - val_loss: 0.3094 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.2695 - val_accuracy: 0.8571 - val_loss: 0.3071 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.2690 - val_accuracy: 0.8571 - val_loss: 0.3059 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3378 - val_accuracy: 0.8571 - val_loss: 0.3036 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3053 - val_accuracy: 0.8571 - val_loss: 0.3034 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.2853 - val_accuracy: 0.8571 - val_loss: 0.3018 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.2547 - val_accuracy: 0.8571 - val_loss: 0.3010 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8788 - loss: 0.2955 - val_accuracy: 0.8571 - val_loss: 0.3009 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8541 - loss: 0.2915 - val_accuracy: 0.8571 - val_loss: 0.2998 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.2968 - val_accuracy: 0.8571 - val_loss: 0.2977 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.2853 - val_accuracy: 0.8571 - val_loss: 0.2980 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.2768 - val_accuracy: 0.8571 - val_loss: 0.2983 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8811 - loss: 0.2767 - val_accuracy: 0.8571 - val_loss: 0.2975 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.2600 - val_accuracy: 0.8571 - val_loss: 0.2971 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.2741 - val_accuracy: 0.8571 - val_loss: 0.2961 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8783 - loss: 0.2902 - val_accuracy: 0.8690 - val_loss: 0.2938 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.2780 - val_accuracy: 0.8571 - val_loss: 0.2937 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.2521 - val_accuracy: 0.8690 - val_loss: 0.2927 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.2937 - val_accuracy: 0.8571 - val_loss: 0.2935 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.2916 - val_accuracy: 0.8571 - val_loss: 0.2934 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.2531 - val_accuracy: 0.8452 - val_loss: 0.2933 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8832 - loss: 0.2749 - val_accuracy: 0.8571 - val_loss: 0.2928 - learning_rate: 2.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9066 - loss: 0.2580 - val_accuracy: 0.8452 - val_loss: 0.2929 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Fold 8 - Val Accuracy: 0.8690, Val Log Loss: 0.2927, Val F1: 0.8706, Val Precision: 0.8409, Val Recall: 0.9024, Val Specificity: 0.8372, Val AUROC: 0.9490\n",
            "\n",
            "Training fold 9...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5145 - loss: 0.8724 - val_accuracy: 0.7143 - val_loss: 0.6167 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5515 - loss: 0.7740 - val_accuracy: 0.7381 - val_loss: 0.5879 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 0.6410 - val_accuracy: 0.7619 - val_loss: 0.5608 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6365 - loss: 0.6849 - val_accuracy: 0.7738 - val_loss: 0.5359 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.6082 - val_accuracy: 0.7738 - val_loss: 0.5162 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.5701 - val_accuracy: 0.7619 - val_loss: 0.4986 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7751 - loss: 0.4903 - val_accuracy: 0.7738 - val_loss: 0.4825 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.5326 - val_accuracy: 0.7738 - val_loss: 0.4704 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5068 - val_accuracy: 0.7738 - val_loss: 0.4598 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4853 - val_accuracy: 0.7857 - val_loss: 0.4500 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4662 - val_accuracy: 0.7857 - val_loss: 0.4427 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.4647 - val_accuracy: 0.7857 - val_loss: 0.4374 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4348 - val_accuracy: 0.7976 - val_loss: 0.4322 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4476 - val_accuracy: 0.7976 - val_loss: 0.4291 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7660 - loss: 0.4916 - val_accuracy: 0.7976 - val_loss: 0.4253 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.4384 - val_accuracy: 0.8095 - val_loss: 0.4222 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4390 - val_accuracy: 0.8095 - val_loss: 0.4191 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.3989 - val_accuracy: 0.8095 - val_loss: 0.4166 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.3823 - val_accuracy: 0.8095 - val_loss: 0.4148 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.3977 - val_accuracy: 0.7976 - val_loss: 0.4140 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.4014 - val_accuracy: 0.7976 - val_loss: 0.4123 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.4156 - val_accuracy: 0.7976 - val_loss: 0.4106 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.3864 - val_accuracy: 0.7976 - val_loss: 0.4096 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3558 - val_accuracy: 0.7976 - val_loss: 0.4096 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.3867 - val_accuracy: 0.7976 - val_loss: 0.4098 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.3518 - val_accuracy: 0.7976 - val_loss: 0.4074 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3680 - val_accuracy: 0.7976 - val_loss: 0.4076 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.3528 - val_accuracy: 0.7976 - val_loss: 0.4077 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8442 - loss: 0.3475 - val_accuracy: 0.7976 - val_loss: 0.4069 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8466 - loss: 0.3334 - val_accuracy: 0.7976 - val_loss: 0.4064 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8466 - loss: 0.3633 - val_accuracy: 0.7976 - val_loss: 0.4058 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8679 - loss: 0.3303 - val_accuracy: 0.7976 - val_loss: 0.4065 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8008 - loss: 0.3704 - val_accuracy: 0.7976 - val_loss: 0.4067 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8224 - loss: 0.3934 - val_accuracy: 0.7976 - val_loss: 0.4068 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8205 - loss: 0.3891 - val_accuracy: 0.7976 - val_loss: 0.4067 - learning_rate: 2.0000e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - loss: 0.3171 - val_accuracy: 0.7976 - val_loss: 0.4065 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Fold 9 - Val Accuracy: 0.7976, Val Log Loss: 0.4058, Val F1: 0.8000, Val Precision: 0.7727, Val Recall: 0.8293, Val Specificity: 0.7674, Val AUROC: 0.8956\n",
            "\n",
            "Training fold 10...\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4295 - loss: 1.0675 - val_accuracy: 0.3810 - val_loss: 0.7620 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5138 - loss: 0.8959 - val_accuracy: 0.4643 - val_loss: 0.7166 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5498 - loss: 0.8132 - val_accuracy: 0.6310 - val_loss: 0.6685 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5656 - loss: 0.7798 - val_accuracy: 0.6786 - val_loss: 0.6246 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6404 - loss: 0.6716 - val_accuracy: 0.7262 - val_loss: 0.5845 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.6162 - val_accuracy: 0.7738 - val_loss: 0.5494 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6813 - loss: 0.6297 - val_accuracy: 0.7500 - val_loss: 0.5165 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5735 - val_accuracy: 0.7857 - val_loss: 0.4869 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 0.5765 - val_accuracy: 0.7857 - val_loss: 0.4627 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7536 - loss: 0.5094 - val_accuracy: 0.7976 - val_loss: 0.4422 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.4955 - val_accuracy: 0.7976 - val_loss: 0.4228 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.5172 - val_accuracy: 0.8452 - val_loss: 0.4066 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.4678 - val_accuracy: 0.8452 - val_loss: 0.3933 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.4522 - val_accuracy: 0.8452 - val_loss: 0.3803 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4401 - val_accuracy: 0.8452 - val_loss: 0.3693 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.4709 - val_accuracy: 0.8571 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.4420 - val_accuracy: 0.8690 - val_loss: 0.3506 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.4216 - val_accuracy: 0.8690 - val_loss: 0.3431 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7885 - loss: 0.4249 - val_accuracy: 0.8571 - val_loss: 0.3371 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4280 - val_accuracy: 0.8571 - val_loss: 0.3308 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.4088 - val_accuracy: 0.8571 - val_loss: 0.3267 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.3972 - val_accuracy: 0.8690 - val_loss: 0.3220 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.4097 - val_accuracy: 0.8690 - val_loss: 0.3170 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4043 - val_accuracy: 0.8810 - val_loss: 0.3122 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8393 - loss: 0.3620 - val_accuracy: 0.8810 - val_loss: 0.3080 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.3537 - val_accuracy: 0.8810 - val_loss: 0.3054 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.3976 - val_accuracy: 0.8810 - val_loss: 0.3024 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8137 - loss: 0.3562 - val_accuracy: 0.8810 - val_loss: 0.2989 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.4177 - val_accuracy: 0.8810 - val_loss: 0.2963 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.3658 - val_accuracy: 0.8810 - val_loss: 0.2936 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.3774 - val_accuracy: 0.8929 - val_loss: 0.2915 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.3697 - val_accuracy: 0.9048 - val_loss: 0.2891 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8484 - loss: 0.3398 - val_accuracy: 0.9048 - val_loss: 0.2882 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.3625 - val_accuracy: 0.9048 - val_loss: 0.2860 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3767 - val_accuracy: 0.9048 - val_loss: 0.2837 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3357 - val_accuracy: 0.9048 - val_loss: 0.2812 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.3711 - val_accuracy: 0.9048 - val_loss: 0.2796 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8400 - loss: 0.3534 - val_accuracy: 0.9048 - val_loss: 0.2782 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.3660 - val_accuracy: 0.9048 - val_loss: 0.2763 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8612 - loss: 0.3389 - val_accuracy: 0.9048 - val_loss: 0.2744 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3336 - val_accuracy: 0.9048 - val_loss: 0.2716 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3584 - val_accuracy: 0.9048 - val_loss: 0.2708 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.3423 - val_accuracy: 0.9048 - val_loss: 0.2699 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.3215 - val_accuracy: 0.9048 - val_loss: 0.2688 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.3275 - val_accuracy: 0.9048 - val_loss: 0.2665 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3321 - val_accuracy: 0.9048 - val_loss: 0.2659 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.3411 - val_accuracy: 0.9048 - val_loss: 0.2645 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3210 - val_accuracy: 0.9048 - val_loss: 0.2627 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3216 - val_accuracy: 0.9048 - val_loss: 0.2608 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8657 - loss: 0.3045 - val_accuracy: 0.8929 - val_loss: 0.2593 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3439 - val_accuracy: 0.9048 - val_loss: 0.2577 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.3226 - val_accuracy: 0.8929 - val_loss: 0.2575 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3195 - val_accuracy: 0.8929 - val_loss: 0.2577 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3058 - val_accuracy: 0.8929 - val_loss: 0.2560 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.3463 - val_accuracy: 0.9048 - val_loss: 0.2545 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8346 - loss: 0.3290 - val_accuracy: 0.8929 - val_loss: 0.2534 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8459 - loss: 0.3329 - val_accuracy: 0.9048 - val_loss: 0.2514 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8455 - loss: 0.3332 - val_accuracy: 0.9048 - val_loss: 0.2498 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 0.3381 - val_accuracy: 0.9048 - val_loss: 0.2484 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8827 - loss: 0.2756 - val_accuracy: 0.9048 - val_loss: 0.2474 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.2967 - val_accuracy: 0.9048 - val_loss: 0.2461 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8617 - loss: 0.3162 - val_accuracy: 0.9048 - val_loss: 0.2453 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.3102 - val_accuracy: 0.9048 - val_loss: 0.2443 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8241 - loss: 0.3475 - val_accuracy: 0.9048 - val_loss: 0.2443 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.2931 - val_accuracy: 0.8929 - val_loss: 0.2441 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.3141 - val_accuracy: 0.8929 - val_loss: 0.2426 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8816 - loss: 0.2901 - val_accuracy: 0.8929 - val_loss: 0.2424 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8502 - loss: 0.3155 - val_accuracy: 0.8929 - val_loss: 0.2432 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8758 - loss: 0.2804 - val_accuracy: 0.8929 - val_loss: 0.2424 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8658 - loss: 0.2962 - val_accuracy: 0.8929 - val_loss: 0.2417 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - loss: 0.3066 - val_accuracy: 0.8929 - val_loss: 0.2416 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8830 - loss: 0.2997 - val_accuracy: 0.8929 - val_loss: 0.2410 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8837 - loss: 0.2725 - val_accuracy: 0.9048 - val_loss: 0.2394 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8669 - loss: 0.2787 - val_accuracy: 0.9048 - val_loss: 0.2386 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.3108 - val_accuracy: 0.9048 - val_loss: 0.2379 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.2897 - val_accuracy: 0.9048 - val_loss: 0.2375 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2691 - val_accuracy: 0.9048 - val_loss: 0.2359 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2716 - val_accuracy: 0.9048 - val_loss: 0.2357 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.2711 - val_accuracy: 0.9048 - val_loss: 0.2354 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.2780 - val_accuracy: 0.9048 - val_loss: 0.2352 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8848 - loss: 0.2579 - val_accuracy: 0.9167 - val_loss: 0.2350 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8659 - loss: 0.2924 - val_accuracy: 0.9167 - val_loss: 0.2341 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.2549 - val_accuracy: 0.9167 - val_loss: 0.2337 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8822 - loss: 0.2758 - val_accuracy: 0.9167 - val_loss: 0.2341 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.2873 - val_accuracy: 0.9167 - val_loss: 0.2330 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.2943 - val_accuracy: 0.9167 - val_loss: 0.2335 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.3011 - val_accuracy: 0.9167 - val_loss: 0.2333 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8583 - loss: 0.2967 - val_accuracy: 0.9167 - val_loss: 0.2325 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.2782 - val_accuracy: 0.9167 - val_loss: 0.2326 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.2484 - val_accuracy: 0.9167 - val_loss: 0.2313 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2573 - val_accuracy: 0.9167 - val_loss: 0.2299 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.2778 - val_accuracy: 0.9167 - val_loss: 0.2296 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.2832 - val_accuracy: 0.9167 - val_loss: 0.2305 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8942 - loss: 0.2514 - val_accuracy: 0.9167 - val_loss: 0.2300 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.2612 - val_accuracy: 0.9167 - val_loss: 0.2307 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.2853 - val_accuracy: 0.9167 - val_loss: 0.2307 - learning_rate: 2.0000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2806 - val_accuracy: 0.9167 - val_loss: 0.2308 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Fold 10 - Val Accuracy: 0.9167, Val Log Loss: 0.2296, Val F1: 0.9157, Val Precision: 0.9048, Val Recall: 0.9268, Val Specificity: 0.9070, Val AUROC: 0.9682\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Val Accuracy: 0.8619\n",
            "Average Val Log Loss: 0.3185\n",
            "Average Val F1 Score: 0.8592\n",
            "Average Val Precision: 0.8508\n",
            "Average Val Recall: 0.8717\n",
            "Average Val Specificity: 0.8522\n",
            "Average Val AUROC: 0.9371\n",
            "\n",
            "Final Test Evaluation...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Test Accuracy: 0.8898\n",
            "Test Log Loss: 0.4173\n",
            "Test F1 Score: 0.9297\n",
            "Test Precision: 0.9773\n",
            "Test Recall: 0.8866\n",
            "Test Specificity: 0.9048\n",
            "Test AUROC: 0.9460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoostClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, log_loss, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
        ")\n",
        "\n",
        "# Scale the data for improved stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the AdaBoost model\n",
        "model = AdaBoostClassifier(n_estimators=25, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "# Metrics containers\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "specificities = []\n",
        "aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "for train_index, val_index in kf.split(X_train, y_train):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split training data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train the AdaBoost classifier\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "    y_val_pred_classes = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    log_loss_value = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    accuracies.append(accuracy)\n",
        "    log_losses.append(log_loss_value)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    specificities.append(specificity)\n",
        "    aurocs.append(auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Log Loss: {log_loss_value:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, AUROC: {auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final aggregated cross-validation results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average Specificity: {np.mean(specificities):.4f}\")\n",
        "print(f\"Average AUROC: {np.mean(aurocs):.4f}\")\n",
        "\n",
        "# Final evaluation on the test set\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "model.fit(X_train, y_train)  # Train the model on the full training data\n",
        "\n",
        "# Test set predictions\n",
        "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred_classes = model.predict(X_test)\n",
        "\n",
        "# Calculate test set metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
        "test_log_loss = log_loss(y_test, y_test_pred_proba)\n",
        "test_f1 = f1_score(y_test, y_test_pred_classes)\n",
        "test_precision = precision_score(y_test, y_test_pred_classes)\n",
        "test_recall = recall_score(y_test, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "# Specificity calculation\n",
        "cm_test = confusion_matrix(y_test, y_test_pred_classes)\n",
        "tn, fp, fn, tp = cm_test.ravel()\n",
        "test_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print test results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDSHwu6Qvwlj",
        "outputId": "938dd181-f3db-4282-e61a-96112f45f767"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "Fold 1 - Accuracy: 0.7976, Log Loss: 0.4603, F1: 0.7848, Precision: 0.7949, Recall: 0.7750, Specificity: 0.8182, AUROC: 0.8778\n",
            "\n",
            "Training fold 2...\n",
            "Fold 2 - Accuracy: 0.7738, Log Loss: 0.4452, F1: 0.7865, Precision: 0.7143, Recall: 0.8750, Specificity: 0.6818, AUROC: 0.9168\n",
            "\n",
            "Training fold 3...\n",
            "Fold 3 - Accuracy: 0.8095, Log Loss: 0.4611, F1: 0.8049, Precision: 0.7857, Recall: 0.8250, Specificity: 0.7955, AUROC: 0.8847\n",
            "\n",
            "Training fold 4...\n",
            "Fold 4 - Accuracy: 0.7738, Log Loss: 0.4492, F1: 0.7912, Precision: 0.7059, Recall: 0.9000, Specificity: 0.6591, AUROC: 0.9159\n",
            "\n",
            "Training fold 5...\n",
            "Fold 5 - Accuracy: 0.7976, Log Loss: 0.4350, F1: 0.7952, Precision: 0.7857, Recall: 0.8049, Specificity: 0.7907, AUROC: 0.9010\n",
            "\n",
            "Training fold 6...\n",
            "Fold 6 - Accuracy: 0.8452, Log Loss: 0.4124, F1: 0.8539, Precision: 0.7917, Recall: 0.9268, Specificity: 0.7674, AUROC: 0.9308\n",
            "\n",
            "Training fold 7...\n",
            "Fold 7 - Accuracy: 0.7857, Log Loss: 0.4591, F1: 0.7955, Precision: 0.7447, Recall: 0.8537, Specificity: 0.7209, AUROC: 0.8968\n",
            "\n",
            "Training fold 8...\n",
            "Fold 8 - Accuracy: 0.8333, Log Loss: 0.4363, F1: 0.8372, Precision: 0.8000, Recall: 0.8780, Specificity: 0.7907, AUROC: 0.9121\n",
            "\n",
            "Training fold 9...\n",
            "Fold 9 - Accuracy: 0.7976, Log Loss: 0.4714, F1: 0.8090, Precision: 0.7500, Recall: 0.8780, Specificity: 0.7209, AUROC: 0.8681\n",
            "\n",
            "Training fold 10...\n",
            "Fold 10 - Accuracy: 0.8333, Log Loss: 0.4116, F1: 0.8293, Precision: 0.8293, Recall: 0.8293, Specificity: 0.8372, AUROC: 0.9189\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8048\n",
            "Average Log Loss: 0.4441\n",
            "Average F1 Score: 0.8087\n",
            "Average Precision: 0.7702\n",
            "Average Recall: 0.8546\n",
            "Average Specificity: 0.7582\n",
            "Average AUROC: 0.9023\n",
            "\n",
            "Final Test Evaluation...\n",
            "Test Accuracy: 0.9492\n",
            "Test Log Loss: 0.2860\n",
            "Test F1 Score: 0.9694\n",
            "Test Precision: 0.9596\n",
            "Test Recall: 0.9794\n",
            "Test Specificity: 0.8095\n",
            "Test AUROC: 0.9904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LGBMClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, log_loss, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        ")\n",
        "\n",
        "# Define model parameters\n",
        "model = LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics containers\n",
        "cv_accuracies = []\n",
        "cv_log_losses = []\n",
        "cv_f1_scores = []\n",
        "cv_precisions = []\n",
        "cv_recalls = []\n",
        "cv_specificities = []\n",
        "cv_aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "fold = 1\n",
        "for train_index, val_index in kf.split(X_train, y_train):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Scale the data within the fold\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold = scaler.transform(X_val_fold)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "    y_val_pred_classes = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    log_loss_value = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    cv_accuracies.append(accuracy)\n",
        "    cv_log_losses.append(log_loss_value)\n",
        "    cv_f1_scores.append(f1)\n",
        "    cv_precisions.append(precision)\n",
        "    cv_recalls.append(recall)\n",
        "    cv_specificities.append(specificity)\n",
        "    cv_aurocs.append(auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Log Loss: {log_loss_value:.4f}, F1: {f1:.4f}, \"\n",
        "          f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, AUROC: {auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final Cross-Validation Results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(cv_accuracies):.4f}\")\n",
        "print(f\"Average Log Loss: {np.mean(cv_log_losses):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(cv_f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(cv_precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(cv_recalls):.4f}\")\n",
        "print(f\"Average Specificity: {np.mean(cv_specificities):.4f}\")\n",
        "print(f\"Average AUROC: {np.mean(cv_aurocs):.4f}\")\n",
        "\n",
        "# Final Test Evaluation\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "\n",
        "# Scale the test set using the entire training set\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model on the entire training set\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_test_pred_classes = model.predict(X_test_scaled)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
        "test_log_loss = log_loss(y_test, y_test_pred_proba)\n",
        "test_f1 = f1_score(y_test, y_test_pred_classes)\n",
        "test_precision = precision_score(y_test, y_test_pred_classes)\n",
        "test_recall = recall_score(y_test, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(y_test, y_test_pred_proba)\n",
        "\n",
        "cm_test = confusion_matrix(y_test, y_test_pred_classes)\n",
        "tn, fp, fn, tp = cm_test.ravel()\n",
        "test_specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzF8aROdg1lx",
        "outputId": "df0c8c6a-1220-4357-9f64-32eaf26af78f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "[LightGBM] [Info] Number of positive: 366, number of negative: 390\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8576\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484127 -> initscore=-0.063513\n",
            "[LightGBM] [Info] Start training from score -0.063513\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 1 - Accuracy: 0.8929, Log Loss: 0.3893, F1: 0.8767, Precision: 0.9697, Recall: 0.8000, Specificity: 0.9773, AUROC: 0.9364\n",
            "\n",
            "Training fold 2...\n",
            "[LightGBM] [Info] Number of positive: 366, number of negative: 390\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8578\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484127 -> initscore=-0.063513\n",
            "[LightGBM] [Info] Start training from score -0.063513\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 2 - Accuracy: 0.8929, Log Loss: 0.1586, F1: 0.8831, Precision: 0.9189, Recall: 0.8500, Specificity: 0.9318, AUROC: 0.9807\n",
            "\n",
            "Training fold 3...\n",
            "[LightGBM] [Info] Number of positive: 366, number of negative: 390\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8581\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484127 -> initscore=-0.063513\n",
            "[LightGBM] [Info] Start training from score -0.063513\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 3 - Accuracy: 0.9048, Log Loss: 0.4070, F1: 0.9000, Precision: 0.9000, Recall: 0.9000, Specificity: 0.9091, AUROC: 0.9375\n",
            "\n",
            "Training fold 4...\n",
            "[LightGBM] [Info] Number of positive: 366, number of negative: 390\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8581\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.484127 -> initscore=-0.063513\n",
            "[LightGBM] [Info] Start training from score -0.063513\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 4 - Accuracy: 0.8095, Log Loss: 0.4100, F1: 0.8182, Precision: 0.7500, Recall: 0.9000, Specificity: 0.7273, AUROC: 0.9324\n",
            "\n",
            "Training fold 5...\n",
            "[LightGBM] [Info] Number of positive: 365, number of negative: 391\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8582\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482804 -> initscore=-0.068810\n",
            "[LightGBM] [Info] Start training from score -0.068810\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 5 - Accuracy: 0.8214, Log Loss: 0.3930, F1: 0.8193, Precision: 0.8095, Recall: 0.8293, Specificity: 0.8140, AUROC: 0.9342\n",
            "\n",
            "Training fold 6...\n",
            "[LightGBM] [Info] Number of positive: 365, number of negative: 391\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8577\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482804 -> initscore=-0.068810\n",
            "[LightGBM] [Info] Start training from score -0.068810\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 6 - Accuracy: 0.8571, Log Loss: 0.3104, F1: 0.8571, Precision: 0.8372, Recall: 0.8780, Specificity: 0.8372, AUROC: 0.9490\n",
            "\n",
            "Training fold 7...\n",
            "[LightGBM] [Info] Number of positive: 365, number of negative: 391\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8576\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482804 -> initscore=-0.068810\n",
            "[LightGBM] [Info] Start training from score -0.068810\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 7 - Accuracy: 0.7976, Log Loss: 0.4568, F1: 0.7848, Precision: 0.8158, Recall: 0.7561, Specificity: 0.8372, AUROC: 0.9172\n",
            "\n",
            "Training fold 8...\n",
            "[LightGBM] [Info] Number of positive: 365, number of negative: 391\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8576\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482804 -> initscore=-0.068810\n",
            "[LightGBM] [Info] Start training from score -0.068810\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 8 - Accuracy: 0.8214, Log Loss: 0.3623, F1: 0.8276, Precision: 0.7826, Recall: 0.8780, Specificity: 0.7674, AUROC: 0.9558\n",
            "\n",
            "Training fold 9...\n",
            "[LightGBM] [Info] Number of positive: 365, number of negative: 391\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8584\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482804 -> initscore=-0.068810\n",
            "[LightGBM] [Info] Start training from score -0.068810\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 9 - Accuracy: 0.8214, Log Loss: 0.4292, F1: 0.8193, Precision: 0.8095, Recall: 0.8293, Specificity: 0.8140, AUROC: 0.9206\n",
            "\n",
            "Training fold 10...\n",
            "[LightGBM] [Info] Number of positive: 365, number of negative: 391\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8578\n",
            "[LightGBM] [Info] Number of data points in the train set: 756, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.482804 -> initscore=-0.068810\n",
            "[LightGBM] [Info] Start training from score -0.068810\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 10 - Accuracy: 0.8690, Log Loss: 0.3896, F1: 0.8642, Precision: 0.8750, Recall: 0.8537, Specificity: 0.8837, AUROC: 0.9444\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8488\n",
            "Average Log Loss: 0.3706\n",
            "Average F1 Score: 0.8450\n",
            "Average Precision: 0.8468\n",
            "Average Recall: 0.8474\n",
            "Average Specificity: 0.8499\n",
            "Average AUROC: 0.9408\n",
            "\n",
            "Final Test Evaluation...\n",
            "[LightGBM] [Info] Number of positive: 406, number of negative: 434\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8670\n",
            "[LightGBM] [Info] Number of data points in the train set: 840, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.483333 -> initscore=-0.066691\n",
            "[LightGBM] [Info] Start training from score -0.066691\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Test Accuracy: 0.9831\n",
            "Test Log Loss: 0.0585\n",
            "Test F1 Score: 0.9896\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 0.9794\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 0.9980\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}