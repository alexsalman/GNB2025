{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iOMBeyVyQ-7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b04ca6-7f08-43bc-f0f3-4075b07cc712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sdv in /usr/local/lib/python3.11/dist-packages (1.20.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.28 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.37.36)\n",
            "Requirement already satisfied: botocore<2.0.0,>=1.31 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.37.36)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (3.1.1)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.67.1)\n",
            "Requirement already satisfied: copulas>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.12.2)\n",
            "Requirement already satisfied: ctgan>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.11.0)\n",
            "Requirement already satisfied: deepecho>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.7.0)\n",
            "Requirement already satisfied: rdt>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (1.16.0)\n",
            "Requirement already satisfied: sdmetrics>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.20.1)\n",
            "Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.3.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (6.0.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2.0.0,>=1.28->sdv) (0.11.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.3.0)\n",
            "Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (1.14.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ctgan>=0.11.0->sdv) (2.6.0+cu124)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.16.0->sdv) (1.6.1)\n",
            "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.16.0->sdv) (37.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.16.0->sdv) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.16.0->sdv) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->ctgan>=0.11.0->sdv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan>=0.11.0->sdv) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# install singular value decomposition\n",
        "!pip install sdv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h1sinr-sIkou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca16731b-8349-44cb-dd6d-257f186077c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# import tools\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "from sdv.evaluation.single_table import evaluate_quality\n",
        "from google.colab import drive\n",
        "import logging\n",
        "import warnings\n",
        "drive.mount('/content/gdrive')\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, log_loss, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U2q--EUBQcy",
        "outputId": "4bcfd2e6-ae58-42d1-c429-f12b6885c25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe dimensions: (134, 38)\n",
            "Processed dataframe dimensions: (118, 37)\n",
            "Number of ALS: 97\n",
            "Number of HC: 21\n",
            "--------------------------------------------------\n",
            "Index(['Sesso', 'Disease', 'Età', 'GCSF', 'IFNgamma', 'IL10', 'IL15', 'IL17A',\n",
            "       'IL1beta', 'IL2', 'IL4', 'IL6', 'IL8', 'MCP1', 'MIP1alfa', 'TNFalfa',\n",
            "       'VEGF', 'TTVlog', 'TTVcopies', 'acetic', 'Propionic', 'Butyric',\n",
            "       'isoButyric', 'isoValeric', '@MethylButyric', 'valeric', 'Hexanoic',\n",
            "       'Heptanoic', 'Nonanoic', '@EthylHexanoic', 'Octanoic', 'Decanoic',\n",
            "       'Benzoic', 'Dodecanoic', 'Tetradecanoic', 'Hexadecanoic',\n",
            "       'Octadecanoic'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# data processing\n",
        "df = pd.read_excel('/content/gdrive/MyDrive/Colab Notebooks/Database_Features_ML.xlsx')\n",
        "print(f\"Original dataframe dimensions: {df.shape}\")\n",
        "df[df.columns[4:]] = df[df.columns[4:]].apply(pd.to_numeric, errors='coerce')\n",
        "df.replace([\"#!NULL\", \"\"], np.nan, inplace=True)\n",
        "df.drop(columns=['ID Paziente'], inplace=True)\n",
        "df = df.dropna()\n",
        "print(f\"Processed dataframe dimensions: {df.shape}\")\n",
        "\n",
        "# encoding sex column\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sesso'] = label_encoder.fit_transform(df['Sesso'])\n",
        "# encoding disease column\n",
        "df['Disease'] = df['Disease'].replace({'ALS': 1, 'HEALTHY': 0})\n",
        "df_als = df[df['Disease'] == 1]\n",
        "df_hc = df[df['Disease'] == 0]\n",
        "\n",
        "print(f\"Number of ALS: {len(df_als)}\")\n",
        "print(f\"Number of HC: {len(df_hc)}\")\n",
        "print('-'*50)\n",
        "print(df.columns)\n",
        "feature_names = df.columns.tolist()  # Store feature names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6MvADyQwFGqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e257e3cb-da7a-4c0b-9528-336e3224265d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (20, 37)\n",
            "Test set shape: (22, 37)\n"
          ]
        }
      ],
      "source": [
        "# subsampling the majority class, ALS\n",
        "df_als_downsized = df_als.sample(n=21, random_state=42)\n",
        "df_downsized = pd.concat([df_als_downsized, df_hc], ignore_index=True)\n",
        "# spliting data into training 50% and testing 50%\n",
        "class_a = df_downsized[df_downsized['Disease'] == 1]\n",
        "class_b = df_downsized[df_downsized['Disease'] == 0]\n",
        "half_class_a = class_a.sample(frac=0.5, random_state=42)\n",
        "half_class_b = class_b.sample(frac=0.5, random_state=42)\n",
        "train_df = pd.concat([half_class_a, half_class_b], axis=0).reset_index(drop=True)\n",
        "test_df = pd.concat([class_a.drop(half_class_a.index), class_b.drop(half_class_b.index)], axis=0).reset_index(drop=True)\n",
        "print(\"Train set shape:\", train_df.shape)\n",
        "print(\"Test set shape:\", test_df.shape)\n",
        "\n",
        "# Save to CSV\n",
        "test_df.to_csv(\"/content/gdrive/MyDrive/ALS/realx20.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KLeeRhFqIu7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed13851-291b-42fb-8177-ba3a32768e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 37)\n"
          ]
        }
      ],
      "source": [
        "# Detect metadata and ensure 'Disease' is categorical\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(train_df)\n",
        "metadata.update_column('Disease', sdtype='categorical')\n",
        "\n",
        "# validate\n",
        "metadata.validate()\n",
        "metadata.validate_data(data=train_df)\n",
        "\n",
        "# Initialize and fit the synthesizer\n",
        "synthesizer_GC = GaussianCopulaSynthesizer(\n",
        "        metadata,  # required\n",
        "        enforce_min_max_values=True,\n",
        "        enforce_rounding=False,\n",
        "        default_distribution='gaussian_kde'\n",
        "        )\n",
        "synthesizer_GC.fit(train_df)\n",
        "\n",
        "# Generate synthetic data\n",
        "# Sample 1 (10xTrainingSet)\n",
        "synthetic_data = synthesizer_GC.sample(num_rows=20*len(train_df))\n",
        "print(synthetic_data.shape)\n",
        "# Save to CSV\n",
        "synthetic_data.to_csv(\"/content/gdrive/MyDrive/ALS/syntheticx20.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8MqNwWBnJHYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ad1fca-48c5-49d2-d042-4ac866a5e0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 37/37 [00:00<00:00, 836.69it/s]|\n",
            "Column Shapes Score: 80.4%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 666/666 [00:15<00:00, 44.28it/s]|\n",
            "Column Pair Trends Score: 93.0%\n",
            "\n",
            "Overall Score (Average): 86.7%\n",
            "\n",
            "<sdmetrics.reports.single_table.quality_report.QualityReport object at 0x7dc8c3381d10>\n"
          ]
        }
      ],
      "source": [
        "quality_report = evaluate_quality(train_df, synthetic_data, metadata)\n",
        "print(quality_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting features and labels\n",
        "\n",
        "Xtrain = synthetic_data.drop(columns=['Disease']).values  # Features\n",
        "ytrain = synthetic_data['Disease'].values  # Labels\n",
        "\n",
        "# Use the test set\n",
        "Xtest = test_df.drop(columns=['Disease']).values  # Features\n",
        "ytest = test_df['Disease'].values  # Labels\n",
        "\n",
        "print(Xtrain.shape)\n",
        "print(ytrain.shape)\n",
        "print(Xtest.shape)\n",
        "print(ytest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UDFEMil0FPj",
        "outputId": "3f969fbb-1441-498e-883d-8314d08e08d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 36)\n",
            "(400,)\n",
            "(22, 36)\n",
            "(22,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras\n",
        "\n",
        "# Scale the data for improved training stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_test = scaler.transform(Xtest)\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(ytrain), y=ytrain)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Define the deep learning model\n",
        "def create_model(input_dim):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(96, activation='relu', input_shape=(input_dim,)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "# Metrics containers\n",
        "val_accuracies = []\n",
        "val_log_losses = []\n",
        "val_f1_scores = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_specificities = []\n",
        "val_aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "for train_index, val_index in kf.split(X_train, ytrain):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split training data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = ytrain[train_index], ytrain[val_index]\n",
        "\n",
        "    # Create and train the model\n",
        "    model = create_model(X_train_fold.shape[1])\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_fold, y_train_fold,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, lr_scheduler],\n",
        "        class_weight=class_weight_dict\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    y_val_pred_proba = model.predict(X_val_fold)\n",
        "    y_val_pred_classes = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    val_log_loss = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    val_f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    val_precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    val_recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    val_auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    val_specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_log_losses.append(val_log_loss)\n",
        "    val_f1_scores.append(val_f1)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_specificities.append(val_specificity)\n",
        "    val_aurocs.append(val_auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Val Accuracy: {val_accuracy:.4f}, Val Log Loss: {val_log_loss:.4f}, \"\n",
        "          f\"Val F1: {val_f1:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, \"\n",
        "          f\"Val Specificity: {val_specificity:.4f}, Val AUROC: {val_auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final Cross-Validation Results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Val Accuracy: {np.mean(val_accuracies):.4f}\")\n",
        "print(f\"Average Val Log Loss: {np.mean(val_log_losses):.4f}\")\n",
        "print(f\"Average Val F1 Score: {np.mean(val_f1_scores):.4f}\")\n",
        "print(f\"Average Val Precision: {np.mean(val_precisions):.4f}\")\n",
        "print(f\"Average Val Recall: {np.mean(val_recalls):.4f}\")\n",
        "print(f\"Average Val Specificity: {np.mean(val_specificities):.4f}\")\n",
        "print(f\"Average Val AUROC: {np.mean(val_aurocs):.4f}\")\n",
        "\n",
        "# Save the modelprint()\n",
        "model.save(\"/content/gdrive/MyDrive/ALS/dlx20.keras\")\n",
        "\n",
        "y_test_pred_proba = model.predict(X_test)\n",
        "y_test_pred_classes = (y_test_pred_proba > 0.5).astype(int)\n",
        "\n",
        "test_accuracy = accuracy_score(ytest, y_test_pred_classes)\n",
        "test_log_loss = log_loss(ytest, y_test_pred_proba)\n",
        "test_f1 = f1_score(ytest, y_test_pred_classes)\n",
        "test_precision = precision_score(ytest, y_test_pred_classes)\n",
        "test_recall = recall_score(ytest, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(ytest, y_test_pred_proba)\n",
        "\n",
        "cm_test = confusion_matrix(ytest, y_test_pred_classes)\n",
        "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
        "test_specificity = tn_test / (tn_test + fp_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSZ_iQz4vnWE",
        "outputId": "13e14ccd-5795-4ce8-db6c-c4434f3e7be0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.4764 - loss: 0.8483 - val_accuracy: 0.5250 - val_loss: 0.7364 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4232 - loss: 0.8932 - val_accuracy: 0.5500 - val_loss: 0.7107 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5121 - loss: 0.8002 - val_accuracy: 0.5625 - val_loss: 0.6872 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5065 - loss: 0.7786 - val_accuracy: 0.5875 - val_loss: 0.6644 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5368 - loss: 0.7443 - val_accuracy: 0.5750 - val_loss: 0.6420 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6183 - loss: 0.6686 - val_accuracy: 0.6375 - val_loss: 0.6222 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6338 - loss: 0.6386 - val_accuracy: 0.6750 - val_loss: 0.6037 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5671 - loss: 0.7156 - val_accuracy: 0.6750 - val_loss: 0.5859 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7020 - loss: 0.6277 - val_accuracy: 0.6875 - val_loss: 0.5690 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6634 - loss: 0.6633 - val_accuracy: 0.7125 - val_loss: 0.5540 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6872 - loss: 0.5706 - val_accuracy: 0.7375 - val_loss: 0.5398 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7003 - loss: 0.5665 - val_accuracy: 0.7375 - val_loss: 0.5270 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7162 - loss: 0.5516 - val_accuracy: 0.7500 - val_loss: 0.5148 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6650 - loss: 0.5774 - val_accuracy: 0.7750 - val_loss: 0.5038 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.7288 - loss: 0.5076 - val_accuracy: 0.8000 - val_loss: 0.4931 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7243 - loss: 0.5472 - val_accuracy: 0.8000 - val_loss: 0.4830 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7540 - loss: 0.5021 - val_accuracy: 0.8125 - val_loss: 0.4741 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7699 - loss: 0.4787 - val_accuracy: 0.8125 - val_loss: 0.4662 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7179 - loss: 0.5108 - val_accuracy: 0.8125 - val_loss: 0.4591 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7337 - loss: 0.5258 - val_accuracy: 0.8125 - val_loss: 0.4515 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8207 - loss: 0.4336 - val_accuracy: 0.8125 - val_loss: 0.4448 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8114 - loss: 0.4059 - val_accuracy: 0.8125 - val_loss: 0.4395 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7826 - loss: 0.4804 - val_accuracy: 0.8125 - val_loss: 0.4345 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7935 - loss: 0.4500 - val_accuracy: 0.8125 - val_loss: 0.4304 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7993 - loss: 0.4292 - val_accuracy: 0.8125 - val_loss: 0.4265 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7924 - loss: 0.4088 - val_accuracy: 0.8125 - val_loss: 0.4235 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7877 - loss: 0.3925 - val_accuracy: 0.8125 - val_loss: 0.4202 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7914 - loss: 0.4430 - val_accuracy: 0.8125 - val_loss: 0.4171 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8449 - loss: 0.3547 - val_accuracy: 0.8250 - val_loss: 0.4147 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8222 - loss: 0.3629 - val_accuracy: 0.8250 - val_loss: 0.4126 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8735 - loss: 0.3423 - val_accuracy: 0.8250 - val_loss: 0.4108 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8122 - loss: 0.3876 - val_accuracy: 0.8250 - val_loss: 0.4088 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8422 - loss: 0.3614 - val_accuracy: 0.8250 - val_loss: 0.4072 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8383 - loss: 0.3899 - val_accuracy: 0.8250 - val_loss: 0.4064 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8544 - loss: 0.3415 - val_accuracy: 0.8250 - val_loss: 0.4049 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8581 - loss: 0.3133 - val_accuracy: 0.8250 - val_loss: 0.4036 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8614 - loss: 0.3304 - val_accuracy: 0.8250 - val_loss: 0.4018 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8715 - loss: 0.3342 - val_accuracy: 0.8250 - val_loss: 0.4007 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8425 - loss: 0.3246 - val_accuracy: 0.8250 - val_loss: 0.3996 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8475 - loss: 0.3394 - val_accuracy: 0.8250 - val_loss: 0.3986 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8367 - loss: 0.3944 - val_accuracy: 0.8250 - val_loss: 0.3972 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8929 - loss: 0.2807 - val_accuracy: 0.8250 - val_loss: 0.3964 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8803 - loss: 0.3068 - val_accuracy: 0.8250 - val_loss: 0.3960 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8796 - loss: 0.3092 - val_accuracy: 0.8250 - val_loss: 0.3954 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8917 - loss: 0.3023 - val_accuracy: 0.8250 - val_loss: 0.3951 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8988 - loss: 0.2933 - val_accuracy: 0.8250 - val_loss: 0.3950 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8292 - loss: 0.3654 - val_accuracy: 0.8250 - val_loss: 0.3951 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8941 - loss: 0.3093 - val_accuracy: 0.8250 - val_loss: 0.3948 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8908 - loss: 0.3049 - val_accuracy: 0.8250 - val_loss: 0.3946 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9069 - loss: 0.2552 - val_accuracy: 0.8250 - val_loss: 0.3943 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8807 - loss: 0.2878 - val_accuracy: 0.8250 - val_loss: 0.3940 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8943 - loss: 0.3152 - val_accuracy: 0.8250 - val_loss: 0.3934 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8625 - loss: 0.3280 - val_accuracy: 0.8250 - val_loss: 0.3925 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8913 - loss: 0.2857 - val_accuracy: 0.8250 - val_loss: 0.3920 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8671 - loss: 0.2789 - val_accuracy: 0.8250 - val_loss: 0.3912 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9136 - loss: 0.2771 - val_accuracy: 0.8250 - val_loss: 0.3908 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9019 - loss: 0.2474 - val_accuracy: 0.8250 - val_loss: 0.3907 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9217 - loss: 0.2559 - val_accuracy: 0.8250 - val_loss: 0.3909 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8589 - loss: 0.2880 - val_accuracy: 0.8250 - val_loss: 0.3907 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8798 - loss: 0.2866 - val_accuracy: 0.8250 - val_loss: 0.3903 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8445 - loss: 0.2819 - val_accuracy: 0.8250 - val_loss: 0.3901 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9389 - loss: 0.2367 - val_accuracy: 0.8250 - val_loss: 0.3900 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.2643 - val_accuracy: 0.8375 - val_loss: 0.3898 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9208 - loss: 0.2309 - val_accuracy: 0.8375 - val_loss: 0.3891 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2595 - val_accuracy: 0.8250 - val_loss: 0.3893 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8826 - loss: 0.2597 - val_accuracy: 0.8250 - val_loss: 0.3887 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8970 - loss: 0.2783 - val_accuracy: 0.8250 - val_loss: 0.3883 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8973 - loss: 0.2366 - val_accuracy: 0.8250 - val_loss: 0.3881 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.2519 - val_accuracy: 0.8250 - val_loss: 0.3878 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9089 - loss: 0.2670 - val_accuracy: 0.8250 - val_loss: 0.3880 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.2549 - val_accuracy: 0.8250 - val_loss: 0.3879 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9212 - loss: 0.2277 - val_accuracy: 0.8250 - val_loss: 0.3881 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8825 - loss: 0.2543 - val_accuracy: 0.8250 - val_loss: 0.3881 - learning_rate: 2.0000e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8879 - loss: 0.2499 - val_accuracy: 0.8250 - val_loss: 0.3880 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Fold 1 - Val Accuracy: 0.8250, Val Log Loss: 0.3878, Val F1: 0.8205, Val Precision: 0.8205, Val Recall: 0.8205, Val Specificity: 0.8293, Val AUROC: 0.9112\n",
            "\n",
            "Training fold 2...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5058 - loss: 0.8526 - val_accuracy: 0.5250 - val_loss: 0.6847 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5002 - loss: 0.7679 - val_accuracy: 0.5500 - val_loss: 0.6643 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5800 - loss: 0.7469 - val_accuracy: 0.6250 - val_loss: 0.6445 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5662 - loss: 0.7273 - val_accuracy: 0.6750 - val_loss: 0.6254 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6095 - loss: 0.6831 - val_accuracy: 0.6750 - val_loss: 0.6081 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6316 - loss: 0.6666 - val_accuracy: 0.6875 - val_loss: 0.5911 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6950 - loss: 0.6045 - val_accuracy: 0.7625 - val_loss: 0.5744 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6589 - loss: 0.6412 - val_accuracy: 0.7875 - val_loss: 0.5595 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7113 - loss: 0.5928 - val_accuracy: 0.8000 - val_loss: 0.5451 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7679 - loss: 0.5201 - val_accuracy: 0.8125 - val_loss: 0.5309 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7205 - loss: 0.5479 - val_accuracy: 0.8125 - val_loss: 0.5177 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7657 - loss: 0.5574 - val_accuracy: 0.8125 - val_loss: 0.5050 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7989 - loss: 0.4908 - val_accuracy: 0.8000 - val_loss: 0.4927 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7904 - loss: 0.4892 - val_accuracy: 0.8000 - val_loss: 0.4815 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7924 - loss: 0.4577 - val_accuracy: 0.8000 - val_loss: 0.4708 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7863 - loss: 0.5245 - val_accuracy: 0.8125 - val_loss: 0.4605 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7954 - loss: 0.4517 - val_accuracy: 0.8125 - val_loss: 0.4508 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8043 - loss: 0.4454 - val_accuracy: 0.8250 - val_loss: 0.4416 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8328 - loss: 0.4247 - val_accuracy: 0.8250 - val_loss: 0.4331 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8580 - loss: 0.4003 - val_accuracy: 0.8250 - val_loss: 0.4246 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8097 - loss: 0.4556 - val_accuracy: 0.8375 - val_loss: 0.4171 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8062 - loss: 0.3879 - val_accuracy: 0.8375 - val_loss: 0.4099 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8279 - loss: 0.4195 - val_accuracy: 0.8375 - val_loss: 0.4037 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8201 - loss: 0.4270 - val_accuracy: 0.8375 - val_loss: 0.3975 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8289 - loss: 0.4143 - val_accuracy: 0.8375 - val_loss: 0.3921 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8499 - loss: 0.4020 - val_accuracy: 0.8375 - val_loss: 0.3867 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8030 - loss: 0.4195 - val_accuracy: 0.8375 - val_loss: 0.3814 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8344 - loss: 0.4034 - val_accuracy: 0.8375 - val_loss: 0.3764 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8462 - loss: 0.3569 - val_accuracy: 0.8375 - val_loss: 0.3721 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8571 - loss: 0.3787 - val_accuracy: 0.8375 - val_loss: 0.3677 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8449 - loss: 0.3652 - val_accuracy: 0.8375 - val_loss: 0.3633 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8879 - loss: 0.3428 - val_accuracy: 0.8375 - val_loss: 0.3595 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8357 - loss: 0.3772 - val_accuracy: 0.8375 - val_loss: 0.3565 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8929 - loss: 0.3164 - val_accuracy: 0.8375 - val_loss: 0.3531 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8499 - loss: 0.3743 - val_accuracy: 0.8375 - val_loss: 0.3498 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8369 - loss: 0.3616 - val_accuracy: 0.8375 - val_loss: 0.3468 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8206 - loss: 0.3789 - val_accuracy: 0.8250 - val_loss: 0.3442 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8328 - loss: 0.3620 - val_accuracy: 0.8250 - val_loss: 0.3412 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8968 - loss: 0.3031 - val_accuracy: 0.8250 - val_loss: 0.3384 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8451 - loss: 0.3249 - val_accuracy: 0.8250 - val_loss: 0.3356 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8892 - loss: 0.3274 - val_accuracy: 0.8250 - val_loss: 0.3329 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3420 - val_accuracy: 0.8250 - val_loss: 0.3303 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8499 - loss: 0.3441 - val_accuracy: 0.8250 - val_loss: 0.3282 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8623 - loss: 0.3448 - val_accuracy: 0.8375 - val_loss: 0.3264 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8718 - loss: 0.3062 - val_accuracy: 0.8375 - val_loss: 0.3241 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8309 - loss: 0.3881 - val_accuracy: 0.8375 - val_loss: 0.3224 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8980 - loss: 0.2826 - val_accuracy: 0.8375 - val_loss: 0.3204 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8365 - loss: 0.3218 - val_accuracy: 0.8375 - val_loss: 0.3187 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8915 - loss: 0.2848 - val_accuracy: 0.8375 - val_loss: 0.3167 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8967 - loss: 0.2999 - val_accuracy: 0.8375 - val_loss: 0.3148 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8754 - loss: 0.3109 - val_accuracy: 0.8375 - val_loss: 0.3125 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8620 - loss: 0.3247 - val_accuracy: 0.8375 - val_loss: 0.3110 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8504 - loss: 0.3706 - val_accuracy: 0.8375 - val_loss: 0.3091 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8782 - loss: 0.3128 - val_accuracy: 0.8375 - val_loss: 0.3072 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8987 - loss: 0.2848 - val_accuracy: 0.8375 - val_loss: 0.3056 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8809 - loss: 0.2975 - val_accuracy: 0.8500 - val_loss: 0.3038 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9020 - loss: 0.2825 - val_accuracy: 0.8500 - val_loss: 0.3023 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8954 - loss: 0.2837 - val_accuracy: 0.8500 - val_loss: 0.3013 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8295 - loss: 0.3312 - val_accuracy: 0.8500 - val_loss: 0.3002 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8916 - loss: 0.2868 - val_accuracy: 0.8500 - val_loss: 0.2989 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8853 - loss: 0.3011 - val_accuracy: 0.8500 - val_loss: 0.2979 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8814 - loss: 0.2760 - val_accuracy: 0.8500 - val_loss: 0.2958 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9133 - loss: 0.2310 - val_accuracy: 0.8500 - val_loss: 0.2945 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8757 - loss: 0.3339 - val_accuracy: 0.8625 - val_loss: 0.2934 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8982 - loss: 0.2511 - val_accuracy: 0.8625 - val_loss: 0.2922 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8927 - loss: 0.2570 - val_accuracy: 0.8625 - val_loss: 0.2914 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8845 - loss: 0.2677 - val_accuracy: 0.8625 - val_loss: 0.2906 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9313 - loss: 0.2524 - val_accuracy: 0.8625 - val_loss: 0.2897 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8958 - loss: 0.2700 - val_accuracy: 0.8625 - val_loss: 0.2892 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8889 - loss: 0.2613 - val_accuracy: 0.8625 - val_loss: 0.2883 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9015 - loss: 0.2527 - val_accuracy: 0.8625 - val_loss: 0.2874 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9041 - loss: 0.2567 - val_accuracy: 0.8625 - val_loss: 0.2861 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9203 - loss: 0.2369 - val_accuracy: 0.8625 - val_loss: 0.2855 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9196 - loss: 0.2521 - val_accuracy: 0.8625 - val_loss: 0.2850 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9171 - loss: 0.2257 - val_accuracy: 0.8625 - val_loss: 0.2838 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8829 - loss: 0.2354 - val_accuracy: 0.8625 - val_loss: 0.2833 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9313 - loss: 0.2143 - val_accuracy: 0.8625 - val_loss: 0.2821 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8766 - loss: 0.2615 - val_accuracy: 0.8625 - val_loss: 0.2810 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8670 - loss: 0.2944 - val_accuracy: 0.8625 - val_loss: 0.2801 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.2253 - val_accuracy: 0.8625 - val_loss: 0.2794 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8984 - loss: 0.2280 - val_accuracy: 0.8625 - val_loss: 0.2784 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9180 - loss: 0.2464 - val_accuracy: 0.8625 - val_loss: 0.2774 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9292 - loss: 0.1942 - val_accuracy: 0.8625 - val_loss: 0.2765 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9013 - loss: 0.2282 - val_accuracy: 0.8625 - val_loss: 0.2760 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8964 - loss: 0.2547 - val_accuracy: 0.8625 - val_loss: 0.2750 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9260 - loss: 0.2329 - val_accuracy: 0.8625 - val_loss: 0.2749 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9163 - loss: 0.2354 - val_accuracy: 0.8625 - val_loss: 0.2746 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9038 - loss: 0.2534 - val_accuracy: 0.8625 - val_loss: 0.2748 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8879 - loss: 0.2179 - val_accuracy: 0.8750 - val_loss: 0.2738 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8994 - loss: 0.2343 - val_accuracy: 0.8750 - val_loss: 0.2723 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9232 - loss: 0.2203 - val_accuracy: 0.8750 - val_loss: 0.2717 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9084 - loss: 0.2313 - val_accuracy: 0.8750 - val_loss: 0.2699 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9225 - loss: 0.2123 - val_accuracy: 0.8750 - val_loss: 0.2690 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9120 - loss: 0.2084 - val_accuracy: 0.8750 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9262 - loss: 0.1950 - val_accuracy: 0.8750 - val_loss: 0.2692 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9402 - loss: 0.1857 - val_accuracy: 0.8750 - val_loss: 0.2696 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9088 - loss: 0.2174 - val_accuracy: 0.8750 - val_loss: 0.2697 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9060 - loss: 0.2048 - val_accuracy: 0.8750 - val_loss: 0.2698 - learning_rate: 2.0000e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9029 - loss: 0.2200 - val_accuracy: 0.8750 - val_loss: 0.2697 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Fold 2 - Val Accuracy: 0.8750, Val Log Loss: 0.2687, Val F1: 0.8649, Val Precision: 0.9143, Val Recall: 0.8205, Val Specificity: 0.9268, Val AUROC: 0.9619\n",
            "\n",
            "Training fold 3...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5791 - loss: 0.7342 - val_accuracy: 0.6125 - val_loss: 0.6661 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5983 - loss: 0.7197 - val_accuracy: 0.6375 - val_loss: 0.6492 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5879 - loss: 0.7017 - val_accuracy: 0.6250 - val_loss: 0.6333 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6570 - loss: 0.6673 - val_accuracy: 0.6875 - val_loss: 0.6178 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6560 - loss: 0.6400 - val_accuracy: 0.7125 - val_loss: 0.6037 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7006 - loss: 0.5799 - val_accuracy: 0.7125 - val_loss: 0.5901 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7053 - loss: 0.5618 - val_accuracy: 0.7125 - val_loss: 0.5770 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7161 - loss: 0.5775 - val_accuracy: 0.7375 - val_loss: 0.5641 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7543 - loss: 0.5632 - val_accuracy: 0.7375 - val_loss: 0.5515 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7636 - loss: 0.5043 - val_accuracy: 0.7500 - val_loss: 0.5395 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7439 - loss: 0.5535 - val_accuracy: 0.7750 - val_loss: 0.5290 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7306 - loss: 0.5238 - val_accuracy: 0.7875 - val_loss: 0.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7559 - loss: 0.5073 - val_accuracy: 0.8000 - val_loss: 0.5092 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7632 - loss: 0.4934 - val_accuracy: 0.8000 - val_loss: 0.4999 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7784 - loss: 0.4906 - val_accuracy: 0.8000 - val_loss: 0.4908 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7709 - loss: 0.4960 - val_accuracy: 0.8000 - val_loss: 0.4824 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7965 - loss: 0.4357 - val_accuracy: 0.8125 - val_loss: 0.4748 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7924 - loss: 0.4486 - val_accuracy: 0.8125 - val_loss: 0.4675 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8212 - loss: 0.4609 - val_accuracy: 0.8125 - val_loss: 0.4604 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8158 - loss: 0.4137 - val_accuracy: 0.8250 - val_loss: 0.4535 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8236 - loss: 0.3787 - val_accuracy: 0.8250 - val_loss: 0.4478 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7984 - loss: 0.3985 - val_accuracy: 0.8250 - val_loss: 0.4414 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8052 - loss: 0.4171 - val_accuracy: 0.8375 - val_loss: 0.4358 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7986 - loss: 0.4133 - val_accuracy: 0.8375 - val_loss: 0.4311 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8199 - loss: 0.3993 - val_accuracy: 0.8625 - val_loss: 0.4256 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8702 - loss: 0.3484 - val_accuracy: 0.8625 - val_loss: 0.4206 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8344 - loss: 0.3705 - val_accuracy: 0.8625 - val_loss: 0.4156 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8544 - loss: 0.3955 - val_accuracy: 0.8750 - val_loss: 0.4116 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8346 - loss: 0.3741 - val_accuracy: 0.8750 - val_loss: 0.4077 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8222 - loss: 0.3768 - val_accuracy: 0.8750 - val_loss: 0.4039 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8556 - loss: 0.3663 - val_accuracy: 0.8750 - val_loss: 0.4007 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8319 - loss: 0.3507 - val_accuracy: 0.8750 - val_loss: 0.3973 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8565 - loss: 0.3490 - val_accuracy: 0.8750 - val_loss: 0.3936 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8261 - loss: 0.3643 - val_accuracy: 0.8750 - val_loss: 0.3900 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8196 - loss: 0.3748 - val_accuracy: 0.8750 - val_loss: 0.3866 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8625 - loss: 0.3107 - val_accuracy: 0.8750 - val_loss: 0.3842 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8754 - loss: 0.3431 - val_accuracy: 0.8750 - val_loss: 0.3813 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8654 - loss: 0.3413 - val_accuracy: 0.8750 - val_loss: 0.3781 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8386 - loss: 0.3867 - val_accuracy: 0.8750 - val_loss: 0.3752 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8738 - loss: 0.3550 - val_accuracy: 0.8750 - val_loss: 0.3729 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8791 - loss: 0.3074 - val_accuracy: 0.8750 - val_loss: 0.3708 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8449 - loss: 0.3748 - val_accuracy: 0.8750 - val_loss: 0.3688 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8967 - loss: 0.2973 - val_accuracy: 0.8750 - val_loss: 0.3662 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8158 - loss: 0.3549 - val_accuracy: 0.8750 - val_loss: 0.3642 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8725 - loss: 0.3285 - val_accuracy: 0.8750 - val_loss: 0.3622 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8925 - loss: 0.3037 - val_accuracy: 0.8750 - val_loss: 0.3605 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8606 - loss: 0.3246 - val_accuracy: 0.8625 - val_loss: 0.3591 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8611 - loss: 0.3033 - val_accuracy: 0.8625 - val_loss: 0.3578 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8947 - loss: 0.3180 - val_accuracy: 0.8625 - val_loss: 0.3561 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8287 - loss: 0.3218 - val_accuracy: 0.8625 - val_loss: 0.3546 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8656 - loss: 0.3522 - val_accuracy: 0.8625 - val_loss: 0.3524 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8745 - loss: 0.3125 - val_accuracy: 0.8625 - val_loss: 0.3508 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9005 - loss: 0.2631 - val_accuracy: 0.8625 - val_loss: 0.3487 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8656 - loss: 0.2945 - val_accuracy: 0.8625 - val_loss: 0.3468 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8850 - loss: 0.2871 - val_accuracy: 0.8750 - val_loss: 0.3459 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8588 - loss: 0.2984 - val_accuracy: 0.8750 - val_loss: 0.3441 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9030 - loss: 0.2538 - val_accuracy: 0.8750 - val_loss: 0.3423 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8790 - loss: 0.2565 - val_accuracy: 0.8750 - val_loss: 0.3411 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8493 - loss: 0.3241 - val_accuracy: 0.8750 - val_loss: 0.3391 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9192 - loss: 0.2459 - val_accuracy: 0.8750 - val_loss: 0.3370 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9037 - loss: 0.2443 - val_accuracy: 0.8875 - val_loss: 0.3354 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8834 - loss: 0.2636 - val_accuracy: 0.8875 - val_loss: 0.3334 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8867 - loss: 0.2706 - val_accuracy: 0.8875 - val_loss: 0.3320 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8700 - loss: 0.2677 - val_accuracy: 0.8875 - val_loss: 0.3306 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8901 - loss: 0.2638 - val_accuracy: 0.8750 - val_loss: 0.3290 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8970 - loss: 0.2586 - val_accuracy: 0.8750 - val_loss: 0.3275 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8737 - loss: 0.2930 - val_accuracy: 0.8750 - val_loss: 0.3259 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8863 - loss: 0.2754 - val_accuracy: 0.8750 - val_loss: 0.3250 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8777 - loss: 0.2893 - val_accuracy: 0.8750 - val_loss: 0.3239 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9066 - loss: 0.2376 - val_accuracy: 0.8750 - val_loss: 0.3231 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8849 - loss: 0.2583 - val_accuracy: 0.8875 - val_loss: 0.3223 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9077 - loss: 0.2453 - val_accuracy: 0.8875 - val_loss: 0.3214 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8518 - loss: 0.2750 - val_accuracy: 0.8875 - val_loss: 0.3205 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8473 - loss: 0.2827 - val_accuracy: 0.8875 - val_loss: 0.3197 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9220 - loss: 0.2269 - val_accuracy: 0.8875 - val_loss: 0.3192 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9044 - loss: 0.2481 - val_accuracy: 0.8750 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8998 - loss: 0.2190 - val_accuracy: 0.8750 - val_loss: 0.3181 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8761 - loss: 0.2637 - val_accuracy: 0.8750 - val_loss: 0.3179 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9010 - loss: 0.2434 - val_accuracy: 0.8875 - val_loss: 0.3172 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9118 - loss: 0.2225 - val_accuracy: 0.8875 - val_loss: 0.3166 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8878 - loss: 0.2641 - val_accuracy: 0.8750 - val_loss: 0.3157 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8895 - loss: 0.2517 - val_accuracy: 0.8750 - val_loss: 0.3150 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8675 - loss: 0.2551 - val_accuracy: 0.8750 - val_loss: 0.3143 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9173 - loss: 0.2432 - val_accuracy: 0.8750 - val_loss: 0.3135 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8507 - loss: 0.3112 - val_accuracy: 0.8750 - val_loss: 0.3132 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8919 - loss: 0.2788 - val_accuracy: 0.8750 - val_loss: 0.3127 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8914 - loss: 0.2796 - val_accuracy: 0.8750 - val_loss: 0.3125 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8883 - loss: 0.2390 - val_accuracy: 0.8750 - val_loss: 0.3121 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1964 - val_accuracy: 0.8750 - val_loss: 0.3115 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9029 - loss: 0.2483 - val_accuracy: 0.8750 - val_loss: 0.3106 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9144 - loss: 0.2223 - val_accuracy: 0.8750 - val_loss: 0.3107 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9001 - loss: 0.2264 - val_accuracy: 0.8750 - val_loss: 0.3099 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9179 - loss: 0.2184 - val_accuracy: 0.8750 - val_loss: 0.3083 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9208 - loss: 0.2195 - val_accuracy: 0.8750 - val_loss: 0.3074 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8839 - loss: 0.2428 - val_accuracy: 0.8750 - val_loss: 0.3067 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9276 - loss: 0.1818 - val_accuracy: 0.8750 - val_loss: 0.3054 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.2054 - val_accuracy: 0.8875 - val_loss: 0.3050 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9272 - loss: 0.2062 - val_accuracy: 0.8875 - val_loss: 0.3045 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9162 - loss: 0.2241 - val_accuracy: 0.8875 - val_loss: 0.3040 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9457 - loss: 0.1791 - val_accuracy: 0.8875 - val_loss: 0.3031 - learning_rate: 1.0000e-04\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Fold 3 - Val Accuracy: 0.8875, Val Log Loss: 0.3031, Val F1: 0.8831, Val Precision: 0.8718, Val Recall: 0.8947, Val Specificity: 0.8810, Val AUROC: 0.9430\n",
            "\n",
            "Training fold 4...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.5835 - loss: 0.7203 - val_accuracy: 0.6500 - val_loss: 0.6612 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5780 - loss: 0.7731 - val_accuracy: 0.6750 - val_loss: 0.6438 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5953 - loss: 0.7241 - val_accuracy: 0.6875 - val_loss: 0.6261 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6108 - loss: 0.6541 - val_accuracy: 0.7375 - val_loss: 0.6093 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6323 - loss: 0.6615 - val_accuracy: 0.7375 - val_loss: 0.5934 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7102 - loss: 0.5997 - val_accuracy: 0.7500 - val_loss: 0.5785 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6705 - loss: 0.5979 - val_accuracy: 0.8000 - val_loss: 0.5627 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6493 - loss: 0.6049 - val_accuracy: 0.7875 - val_loss: 0.5475 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6627 - loss: 0.5836 - val_accuracy: 0.8000 - val_loss: 0.5334 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7630 - loss: 0.4985 - val_accuracy: 0.8125 - val_loss: 0.5196 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7181 - loss: 0.5347 - val_accuracy: 0.8500 - val_loss: 0.5068 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7444 - loss: 0.5059 - val_accuracy: 0.8625 - val_loss: 0.4943 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7512 - loss: 0.4878 - val_accuracy: 0.8500 - val_loss: 0.4823 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7824 - loss: 0.4634 - val_accuracy: 0.8500 - val_loss: 0.4705 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7849 - loss: 0.4307 - val_accuracy: 0.8500 - val_loss: 0.4591 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7458 - loss: 0.4680 - val_accuracy: 0.8500 - val_loss: 0.4490 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7684 - loss: 0.4728 - val_accuracy: 0.8625 - val_loss: 0.4391 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7979 - loss: 0.4166 - val_accuracy: 0.8625 - val_loss: 0.4297 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8245 - loss: 0.4426 - val_accuracy: 0.8500 - val_loss: 0.4205 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8002 - loss: 0.4353 - val_accuracy: 0.8625 - val_loss: 0.4114 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7884 - loss: 0.4678 - val_accuracy: 0.8750 - val_loss: 0.4031 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8418 - loss: 0.4057 - val_accuracy: 0.8750 - val_loss: 0.3952 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8104 - loss: 0.4111 - val_accuracy: 0.8750 - val_loss: 0.3877 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8297 - loss: 0.3827 - val_accuracy: 0.8875 - val_loss: 0.3807 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8360 - loss: 0.3719 - val_accuracy: 0.8875 - val_loss: 0.3740 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8552 - loss: 0.3669 - val_accuracy: 0.8875 - val_loss: 0.3674 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8429 - loss: 0.3825 - val_accuracy: 0.8875 - val_loss: 0.3608 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8537 - loss: 0.3532 - val_accuracy: 0.8875 - val_loss: 0.3546 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8524 - loss: 0.3430 - val_accuracy: 0.8750 - val_loss: 0.3497 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8268 - loss: 0.3804 - val_accuracy: 0.8750 - val_loss: 0.3454 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8263 - loss: 0.3532 - val_accuracy: 0.8750 - val_loss: 0.3410 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8561 - loss: 0.3507 - val_accuracy: 0.8750 - val_loss: 0.3360 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8679 - loss: 0.3323 - val_accuracy: 0.8750 - val_loss: 0.3313 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8634 - loss: 0.3412 - val_accuracy: 0.8750 - val_loss: 0.3273 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8271 - loss: 0.3852 - val_accuracy: 0.8750 - val_loss: 0.3240 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8525 - loss: 0.3555 - val_accuracy: 0.8750 - val_loss: 0.3210 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8785 - loss: 0.3178 - val_accuracy: 0.8750 - val_loss: 0.3179 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8425 - loss: 0.3531 - val_accuracy: 0.8875 - val_loss: 0.3147 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8496 - loss: 0.3433 - val_accuracy: 0.8875 - val_loss: 0.3114 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8580 - loss: 0.3340 - val_accuracy: 0.8875 - val_loss: 0.3086 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8919 - loss: 0.2893 - val_accuracy: 0.8875 - val_loss: 0.3056 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8793 - loss: 0.3022 - val_accuracy: 0.8875 - val_loss: 0.3032 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8569 - loss: 0.3329 - val_accuracy: 0.8875 - val_loss: 0.3008 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8944 - loss: 0.2957 - val_accuracy: 0.8875 - val_loss: 0.2990 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8516 - loss: 0.3276 - val_accuracy: 0.8875 - val_loss: 0.2965 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8470 - loss: 0.3078 - val_accuracy: 0.8875 - val_loss: 0.2947 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8791 - loss: 0.2783 - val_accuracy: 0.8875 - val_loss: 0.2925 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9127 - loss: 0.2683 - val_accuracy: 0.9000 - val_loss: 0.2909 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8879 - loss: 0.2803 - val_accuracy: 0.9000 - val_loss: 0.2891 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8652 - loss: 0.3025 - val_accuracy: 0.8875 - val_loss: 0.2871 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8699 - loss: 0.2968 - val_accuracy: 0.8875 - val_loss: 0.2858 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8676 - loss: 0.2927 - val_accuracy: 0.9000 - val_loss: 0.2845 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9140 - loss: 0.2603 - val_accuracy: 0.9000 - val_loss: 0.2834 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8729 - loss: 0.2806 - val_accuracy: 0.9125 - val_loss: 0.2821 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9006 - loss: 0.2838 - val_accuracy: 0.9125 - val_loss: 0.2809 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8815 - loss: 0.2820 - val_accuracy: 0.9250 - val_loss: 0.2796 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8565 - loss: 0.3194 - val_accuracy: 0.9250 - val_loss: 0.2779 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8823 - loss: 0.3099 - val_accuracy: 0.9250 - val_loss: 0.2765 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8763 - loss: 0.2807 - val_accuracy: 0.9250 - val_loss: 0.2751 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8816 - loss: 0.2888 - val_accuracy: 0.9250 - val_loss: 0.2745 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9145 - loss: 0.2368 - val_accuracy: 0.9250 - val_loss: 0.2736 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8972 - loss: 0.2762 - val_accuracy: 0.9250 - val_loss: 0.2732 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8939 - loss: 0.2594 - val_accuracy: 0.9125 - val_loss: 0.2724 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8800 - loss: 0.2838 - val_accuracy: 0.9125 - val_loss: 0.2713 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9087 - loss: 0.2485 - val_accuracy: 0.9125 - val_loss: 0.2709 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8896 - loss: 0.2712 - val_accuracy: 0.9125 - val_loss: 0.2693 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9169 - loss: 0.2509 - val_accuracy: 0.9000 - val_loss: 0.2685 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9025 - loss: 0.3196 - val_accuracy: 0.9000 - val_loss: 0.2678 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9065 - loss: 0.2786 - val_accuracy: 0.9000 - val_loss: 0.2670 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8946 - loss: 0.2600 - val_accuracy: 0.9000 - val_loss: 0.2665 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8907 - loss: 0.2604 - val_accuracy: 0.9000 - val_loss: 0.2656 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8954 - loss: 0.2574 - val_accuracy: 0.9000 - val_loss: 0.2648 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.2618 - val_accuracy: 0.9000 - val_loss: 0.2638 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8944 - loss: 0.2573 - val_accuracy: 0.9000 - val_loss: 0.2632 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9062 - loss: 0.2274 - val_accuracy: 0.9000 - val_loss: 0.2626 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9213 - loss: 0.2173 - val_accuracy: 0.8875 - val_loss: 0.2623 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9025 - loss: 0.2247 - val_accuracy: 0.9000 - val_loss: 0.2616 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9209 - loss: 0.2101 - val_accuracy: 0.9000 - val_loss: 0.2618 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9099 - loss: 0.2243 - val_accuracy: 0.9000 - val_loss: 0.2621 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9072 - loss: 0.2450 - val_accuracy: 0.9000 - val_loss: 0.2617 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8913 - loss: 0.2415 - val_accuracy: 0.9000 - val_loss: 0.2615 - learning_rate: 2.0000e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9097 - loss: 0.2033 - val_accuracy: 0.9000 - val_loss: 0.2613 - learning_rate: 2.0000e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.2375 - val_accuracy: 0.9000 - val_loss: 0.2611 - learning_rate: 2.0000e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8900 - loss: 0.2578 - val_accuracy: 0.9000 - val_loss: 0.2610 - learning_rate: 2.0000e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9214 - loss: 0.2139 - val_accuracy: 0.9000 - val_loss: 0.2609 - learning_rate: 2.0000e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9042 - loss: 0.2281 - val_accuracy: 0.9000 - val_loss: 0.2609 - learning_rate: 2.0000e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9093 - loss: 0.2526 - val_accuracy: 0.9000 - val_loss: 0.2609 - learning_rate: 2.0000e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.2265 - val_accuracy: 0.9000 - val_loss: 0.2609 - learning_rate: 2.0000e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9475 - loss: 0.2012 - val_accuracy: 0.9000 - val_loss: 0.2607 - learning_rate: 2.0000e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9344 - loss: 0.1911 - val_accuracy: 0.9000 - val_loss: 0.2606 - learning_rate: 2.0000e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9200 - loss: 0.2291 - val_accuracy: 0.9000 - val_loss: 0.2605 - learning_rate: 2.0000e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9098 - loss: 0.2172 - val_accuracy: 0.9000 - val_loss: 0.2604 - learning_rate: 2.0000e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9103 - loss: 0.2259 - val_accuracy: 0.9000 - val_loss: 0.2603 - learning_rate: 2.0000e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9104 - loss: 0.2083 - val_accuracy: 0.9000 - val_loss: 0.2602 - learning_rate: 2.0000e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9110 - loss: 0.2347 - val_accuracy: 0.9000 - val_loss: 0.2600 - learning_rate: 2.0000e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9123 - loss: 0.2302 - val_accuracy: 0.9000 - val_loss: 0.2599 - learning_rate: 2.0000e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9120 - loss: 0.2237 - val_accuracy: 0.9000 - val_loss: 0.2597 - learning_rate: 2.0000e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9191 - loss: 0.2135 - val_accuracy: 0.9000 - val_loss: 0.2595 - learning_rate: 2.0000e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9158 - loss: 0.2375 - val_accuracy: 0.9000 - val_loss: 0.2593 - learning_rate: 2.0000e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8993 - loss: 0.2197 - val_accuracy: 0.8875 - val_loss: 0.2592 - learning_rate: 2.0000e-05\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Fold 4 - Val Accuracy: 0.8875, Val Log Loss: 0.2592, Val F1: 0.8831, Val Precision: 0.8718, Val Recall: 0.8947, Val Specificity: 0.8810, Val AUROC: 0.9649\n",
            "\n",
            "Training fold 5...\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5869 - loss: 0.7661 - val_accuracy: 0.6750 - val_loss: 0.6228 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6023 - loss: 0.8083 - val_accuracy: 0.6875 - val_loss: 0.6073 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5777 - loss: 0.7853 - val_accuracy: 0.7000 - val_loss: 0.5925 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6298 - loss: 0.7462 - val_accuracy: 0.7250 - val_loss: 0.5783 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6006 - loss: 0.7160 - val_accuracy: 0.7250 - val_loss: 0.5647 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6545 - loss: 0.6823 - val_accuracy: 0.7500 - val_loss: 0.5523 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6180 - loss: 0.6956 - val_accuracy: 0.7500 - val_loss: 0.5399 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6897 - loss: 0.6502 - val_accuracy: 0.7500 - val_loss: 0.5290 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6708 - loss: 0.6194 - val_accuracy: 0.7750 - val_loss: 0.5184 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7353 - loss: 0.5510 - val_accuracy: 0.7750 - val_loss: 0.5083 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6764 - loss: 0.5885 - val_accuracy: 0.7750 - val_loss: 0.4988 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6901 - loss: 0.5659 - val_accuracy: 0.7750 - val_loss: 0.4900 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7094 - loss: 0.5594 - val_accuracy: 0.7625 - val_loss: 0.4819 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7612 - loss: 0.5397 - val_accuracy: 0.7750 - val_loss: 0.4747 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7794 - loss: 0.4824 - val_accuracy: 0.7625 - val_loss: 0.4673 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7443 - loss: 0.5629 - val_accuracy: 0.7750 - val_loss: 0.4610 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7505 - loss: 0.5733 - val_accuracy: 0.7750 - val_loss: 0.4556 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7927 - loss: 0.4765 - val_accuracy: 0.7750 - val_loss: 0.4505 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8200 - loss: 0.4453 - val_accuracy: 0.7875 - val_loss: 0.4454 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7877 - loss: 0.4407 - val_accuracy: 0.7875 - val_loss: 0.4404 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7932 - loss: 0.4765 - val_accuracy: 0.7875 - val_loss: 0.4356 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8161 - loss: 0.3967 - val_accuracy: 0.7875 - val_loss: 0.4323 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8611 - loss: 0.3614 - val_accuracy: 0.8000 - val_loss: 0.4289 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.4387 - val_accuracy: 0.8000 - val_loss: 0.4259 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8335 - loss: 0.4060 - val_accuracy: 0.8000 - val_loss: 0.4227 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8044 - loss: 0.4100 - val_accuracy: 0.8000 - val_loss: 0.4204 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8381 - loss: 0.4097 - val_accuracy: 0.7875 - val_loss: 0.4181 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8212 - loss: 0.3810 - val_accuracy: 0.8000 - val_loss: 0.4159 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8209 - loss: 0.3943 - val_accuracy: 0.8125 - val_loss: 0.4136 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8565 - loss: 0.3601 - val_accuracy: 0.8125 - val_loss: 0.4112 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8277 - loss: 0.3902 - val_accuracy: 0.8000 - val_loss: 0.4096 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8436 - loss: 0.3908 - val_accuracy: 0.8125 - val_loss: 0.4079 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8229 - loss: 0.4085 - val_accuracy: 0.8125 - val_loss: 0.4065 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8260 - loss: 0.3740 - val_accuracy: 0.8125 - val_loss: 0.4047 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8342 - loss: 0.3566 - val_accuracy: 0.8250 - val_loss: 0.4036 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8515 - loss: 0.3742 - val_accuracy: 0.8250 - val_loss: 0.4024 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8310 - loss: 0.3855 - val_accuracy: 0.8375 - val_loss: 0.4014 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8493 - loss: 0.3852 - val_accuracy: 0.8375 - val_loss: 0.4004 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8445 - loss: 0.3926 - val_accuracy: 0.8375 - val_loss: 0.3998 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8474 - loss: 0.3666 - val_accuracy: 0.8375 - val_loss: 0.3991 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8917 - loss: 0.3181 - val_accuracy: 0.8375 - val_loss: 0.3978 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9009 - loss: 0.3036 - val_accuracy: 0.8375 - val_loss: 0.3964 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8648 - loss: 0.3323 - val_accuracy: 0.8250 - val_loss: 0.3954 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8574 - loss: 0.3426 - val_accuracy: 0.8250 - val_loss: 0.3951 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8744 - loss: 0.3073 - val_accuracy: 0.8125 - val_loss: 0.3946 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8692 - loss: 0.3502 - val_accuracy: 0.8125 - val_loss: 0.3937 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8695 - loss: 0.3185 - val_accuracy: 0.8000 - val_loss: 0.3924 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8753 - loss: 0.2988 - val_accuracy: 0.8000 - val_loss: 0.3912 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8613 - loss: 0.3253 - val_accuracy: 0.8000 - val_loss: 0.3902 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8806 - loss: 0.3490 - val_accuracy: 0.8000 - val_loss: 0.3892 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8654 - loss: 0.3566 - val_accuracy: 0.8000 - val_loss: 0.3883 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8723 - loss: 0.3121 - val_accuracy: 0.8000 - val_loss: 0.3877 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8366 - loss: 0.3367 - val_accuracy: 0.8125 - val_loss: 0.3870 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8771 - loss: 0.3091 - val_accuracy: 0.8125 - val_loss: 0.3859 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8871 - loss: 0.2940 - val_accuracy: 0.8125 - val_loss: 0.3843 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8592 - loss: 0.3047 - val_accuracy: 0.8250 - val_loss: 0.3842 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9144 - loss: 0.2634 - val_accuracy: 0.8250 - val_loss: 0.3843 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8829 - loss: 0.2962 - val_accuracy: 0.8250 - val_loss: 0.3836 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8689 - loss: 0.3132 - val_accuracy: 0.8250 - val_loss: 0.3838 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8763 - loss: 0.3067 - val_accuracy: 0.8250 - val_loss: 0.3840 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8559 - loss: 0.3294 - val_accuracy: 0.8250 - val_loss: 0.3827 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8982 - loss: 0.2753 - val_accuracy: 0.8250 - val_loss: 0.3816 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8950 - loss: 0.2730 - val_accuracy: 0.8250 - val_loss: 0.3806 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8887 - loss: 0.2951 - val_accuracy: 0.8250 - val_loss: 0.3800 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8648 - loss: 0.3114 - val_accuracy: 0.8250 - val_loss: 0.3797 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8572 - loss: 0.2805 - val_accuracy: 0.8250 - val_loss: 0.3780 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8806 - loss: 0.2943 - val_accuracy: 0.8125 - val_loss: 0.3770 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8934 - loss: 0.2655 - val_accuracy: 0.8125 - val_loss: 0.3761 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8776 - loss: 0.2665 - val_accuracy: 0.8125 - val_loss: 0.3760 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8904 - loss: 0.2744 - val_accuracy: 0.8125 - val_loss: 0.3749 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8739 - loss: 0.2742 - val_accuracy: 0.8125 - val_loss: 0.3739 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8732 - loss: 0.2991 - val_accuracy: 0.8125 - val_loss: 0.3741 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8751 - loss: 0.2891 - val_accuracy: 0.8125 - val_loss: 0.3734 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9305 - loss: 0.2149 - val_accuracy: 0.8125 - val_loss: 0.3730 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.2456 - val_accuracy: 0.8250 - val_loss: 0.3723 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8987 - loss: 0.2524 - val_accuracy: 0.8250 - val_loss: 0.3712 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9133 - loss: 0.2862 - val_accuracy: 0.8250 - val_loss: 0.3705 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9067 - loss: 0.2782 - val_accuracy: 0.8250 - val_loss: 0.3695 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9047 - loss: 0.2639 - val_accuracy: 0.8250 - val_loss: 0.3686 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9105 - loss: 0.2547 - val_accuracy: 0.8250 - val_loss: 0.3677 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8979 - loss: 0.2495 - val_accuracy: 0.8250 - val_loss: 0.3674 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9090 - loss: 0.2270 - val_accuracy: 0.8250 - val_loss: 0.3671 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8841 - loss: 0.2506 - val_accuracy: 0.8250 - val_loss: 0.3665 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8996 - loss: 0.2457 - val_accuracy: 0.8250 - val_loss: 0.3654 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8921 - loss: 0.2604 - val_accuracy: 0.8250 - val_loss: 0.3647 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8725 - loss: 0.2693 - val_accuracy: 0.8250 - val_loss: 0.3638 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8717 - loss: 0.2820 - val_accuracy: 0.8375 - val_loss: 0.3637 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8910 - loss: 0.2513 - val_accuracy: 0.8375 - val_loss: 0.3626 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9097 - loss: 0.2346 - val_accuracy: 0.8375 - val_loss: 0.3617 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.1974 - val_accuracy: 0.8375 - val_loss: 0.3611 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8970 - loss: 0.2336 - val_accuracy: 0.8500 - val_loss: 0.3603 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8914 - loss: 0.2502 - val_accuracy: 0.8500 - val_loss: 0.3594 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9288 - loss: 0.2075 - val_accuracy: 0.8375 - val_loss: 0.3591 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9003 - loss: 0.2337 - val_accuracy: 0.8375 - val_loss: 0.3586 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9232 - loss: 0.1929 - val_accuracy: 0.8375 - val_loss: 0.3575 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9131 - loss: 0.2286 - val_accuracy: 0.8500 - val_loss: 0.3566 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9269 - loss: 0.1960 - val_accuracy: 0.8375 - val_loss: 0.3556 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9090 - loss: 0.2103 - val_accuracy: 0.8375 - val_loss: 0.3554 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9157 - loss: 0.2183 - val_accuracy: 0.8375 - val_loss: 0.3542 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9433 - loss: 0.1736 - val_accuracy: 0.8375 - val_loss: 0.3536 - learning_rate: 1.0000e-04\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Fold 5 - Val Accuracy: 0.8375, Val Log Loss: 0.3536, Val F1: 0.8434, Val Precision: 0.7778, Val Recall: 0.9211, Val Specificity: 0.7619, Val AUROC: 0.9273\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Val Accuracy: 0.8625\n",
            "Average Val Log Loss: 0.3145\n",
            "Average Val F1 Score: 0.8590\n",
            "Average Val Precision: 0.8512\n",
            "Average Val Recall: 0.8703\n",
            "Average Val Specificity: 0.8560\n",
            "Average Val AUROC: 0.9417\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Test Accuracy: 0.9545\n",
            "Test Log Loss: 0.3760\n",
            "Test F1 Score: 0.9524\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 0.9091\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 0.9256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoostClassifier\n",
        "\n",
        "# Scale the data for improved stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_test = scaler.transform(Xtest)\n",
        "\n",
        "# Define the AdaBoost model\n",
        "model = AdaBoostClassifier(n_estimators=25, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "# Metrics containers\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "specificities = []\n",
        "aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "for train_index, val_index in kf.split(X_train, ytrain):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split training data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = ytrain[train_index], ytrain[val_index]\n",
        "\n",
        "    # Train the AdaBoost classifier\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "    y_val_pred_classes = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    log_loss_value = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    accuracies.append(accuracy)\n",
        "    log_losses.append(log_loss_value)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    specificities.append(specificity)\n",
        "    aurocs.append(auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Log Loss: {log_loss_value:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, AUROC: {auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final aggregated cross-validation results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average Specificity: {np.mean(specificities):.4f}\")\n",
        "print(f\"Average AUROC: {np.mean(aurocs):.4f}\")\n",
        "\n",
        "# Final evaluation on the test set\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "model.fit(X_train, ytrain)  # Train the model on the full training data\n",
        "\n",
        "# Save the trained AdaBoost model before testing\n",
        "joblib.dump({\"model\": model, \"feature_names\": feature_names}, \"/content/gdrive/MyDrive/ALS/adaboostx20.pkl\")\n",
        "\n",
        "\n",
        "# Test set predictions\n",
        "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred_classes = model.predict(X_test)\n",
        "\n",
        "# Calculate test set metrics\n",
        "test_accuracy = accuracy_score(ytest, y_test_pred_classes)\n",
        "test_log_loss = log_loss(ytest, y_test_pred_proba)\n",
        "test_f1 = f1_score(ytest, y_test_pred_classes)\n",
        "test_precision = precision_score(ytest, y_test_pred_classes)\n",
        "test_recall = recall_score(ytest, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(ytest, y_test_pred_proba)\n",
        "\n",
        "# Specificity calculation\n",
        "cm_test = confusion_matrix(ytest, y_test_pred_classes)\n",
        "tn, fp, fn, tp = cm_test.ravel()\n",
        "test_specificity = tn / (tn + fp)\n",
        "\n",
        "# Print test results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDSHwu6Qvwlj",
        "outputId": "49d3d0f9-c81d-448b-aafd-1a7b0083e9d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "Fold 1 - Accuracy: 0.8000, Log Loss: 0.4157, F1: 0.8095, Precision: 0.7556, Recall: 0.8718, Specificity: 0.7317, AUROC: 0.9140\n",
            "\n",
            "Training fold 2...\n",
            "Fold 2 - Accuracy: 0.9000, Log Loss: 0.3819, F1: 0.8974, Precision: 0.8974, Recall: 0.8974, Specificity: 0.9024, AUROC: 0.9434\n",
            "\n",
            "Training fold 3...\n",
            "Fold 3 - Accuracy: 0.8375, Log Loss: 0.4345, F1: 0.8312, Precision: 0.8205, Recall: 0.8421, Specificity: 0.8333, AUROC: 0.9123\n",
            "\n",
            "Training fold 4...\n",
            "Fold 4 - Accuracy: 0.8875, Log Loss: 0.3742, F1: 0.8800, Precision: 0.8919, Recall: 0.8684, Specificity: 0.9048, AUROC: 0.9633\n",
            "\n",
            "Training fold 5...\n",
            "Fold 5 - Accuracy: 0.7875, Log Loss: 0.4412, F1: 0.7952, Precision: 0.7333, Recall: 0.8684, Specificity: 0.7143, AUROC: 0.8960\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8425\n",
            "Average Log Loss: 0.4095\n",
            "Average F1 Score: 0.8427\n",
            "Average Precision: 0.8197\n",
            "Average Recall: 0.8696\n",
            "Average Specificity: 0.8173\n",
            "Average AUROC: 0.9258\n",
            "\n",
            "Final Test Evaluation...\n",
            "Test Accuracy: 1.0000\n",
            "Test Log Loss: 0.3260\n",
            "Test F1 Score: 1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 1.0000\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LGBMClassifier\n",
        "\n",
        "# Scale the data for improved stability\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_test = scaler.transform(Xtest)\n",
        "\n",
        "# Define model parameters\n",
        "model = LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Metrics containers\n",
        "cv_accuracies = []\n",
        "cv_log_losses = []\n",
        "cv_f1_scores = []\n",
        "cv_precisions = []\n",
        "cv_recalls = []\n",
        "cv_specificities = []\n",
        "cv_aurocs = []\n",
        "\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "fold = 1\n",
        "for train_index, val_index in kf.split(X_train, ytrain):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = ytrain[train_index], ytrain[val_index]\n",
        "\n",
        "    # Scale the data within the fold\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold = scaler.transform(X_val_fold)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
        "    y_val_pred_classes = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred_classes)\n",
        "    log_loss_value = log_loss(y_val_fold, y_val_pred_proba)\n",
        "    f1 = f1_score(y_val_fold, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_fold, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_fold, y_val_pred_classes)\n",
        "    auroc = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
        "\n",
        "    # Specificity calculation\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_classes)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Append metrics\n",
        "    cv_accuracies.append(accuracy)\n",
        "    cv_log_losses.append(log_loss_value)\n",
        "    cv_f1_scores.append(f1)\n",
        "    cv_precisions.append(precision)\n",
        "    cv_recalls.append(recall)\n",
        "    cv_specificities.append(specificity)\n",
        "    cv_aurocs.append(auroc)\n",
        "\n",
        "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Log Loss: {log_loss_value:.4f}, F1: {f1:.4f}, \"\n",
        "          f\"Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, AUROC: {auroc:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# Final Cross-Validation Results\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(cv_accuracies):.4f}\")\n",
        "print(f\"Average Log Loss: {np.mean(cv_log_losses):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(cv_f1_scores):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(cv_precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(cv_recalls):.4f}\")\n",
        "print(f\"Average Specificity: {np.mean(cv_specificities):.4f}\")\n",
        "print(f\"Average AUROC: {np.mean(cv_aurocs):.4f}\")\n",
        "\n",
        "# Final Test Evaluation\n",
        "print(\"\\nFinal Test Evaluation...\")\n",
        "\n",
        "# Train model on the entire training set\n",
        "model.fit(X_train, ytrain)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump({\"model\": model, \"feature_names\": df}, \"/content/gdrive/MyDrive/ALS/lgbmx20.pkl\")\n",
        "\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred_classes = model.predict(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(ytest, y_test_pred_classes)\n",
        "test_log_loss = log_loss(ytest, y_test_pred_proba)\n",
        "test_f1 = f1_score(ytest, y_test_pred_classes)\n",
        "test_precision = precision_score(ytest, y_test_pred_classes)\n",
        "test_recall = recall_score(ytest, y_test_pred_classes)\n",
        "test_auroc = roc_auc_score(ytest, y_test_pred_proba)\n",
        "\n",
        "cm_test = confusion_matrix(ytest, y_test_pred_classes)\n",
        "tn, fp, fn, tp = cm_test.ravel()\n",
        "test_specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Log Loss: {test_log_loss:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUROC: {test_auroc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzF8aROdg1lx",
        "outputId": "e0cb07e7-fd1f-4aa0-a067-80f6e6bdb32e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation...\n",
            "\n",
            "Training fold 1...\n",
            "[LightGBM] [Info] Number of positive: 153, number of negative: 167\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2881\n",
            "[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478125 -> initscore=-0.087556\n",
            "[LightGBM] [Info] Start training from score -0.087556\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 1 - Accuracy: 0.8250, Log Loss: 0.5459, F1: 0.8250, Precision: 0.8049, Recall: 0.8462, Specificity: 0.8049, AUROC: 0.9199\n",
            "\n",
            "Training fold 2...\n",
            "[LightGBM] [Info] Number of positive: 153, number of negative: 167\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.478125 -> initscore=-0.087556\n",
            "[LightGBM] [Info] Start training from score -0.087556\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 2 - Accuracy: 0.8250, Log Loss: 0.4446, F1: 0.8000, Precision: 0.9032, Recall: 0.7179, Specificity: 0.9268, AUROC: 0.9306\n",
            "\n",
            "Training fold 3...\n",
            "[LightGBM] [Info] Number of positive: 154, number of negative: 166\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2840\n",
            "[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481250 -> initscore=-0.075035\n",
            "[LightGBM] [Info] Start training from score -0.075035\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 3 - Accuracy: 0.9375, Log Loss: 0.2839, F1: 0.9333, Precision: 0.9459, Recall: 0.9211, Specificity: 0.9524, AUROC: 0.9561\n",
            "\n",
            "Training fold 4...\n",
            "[LightGBM] [Info] Number of positive: 154, number of negative: 166\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2830\n",
            "[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481250 -> initscore=-0.075035\n",
            "[LightGBM] [Info] Start training from score -0.075035\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 4 - Accuracy: 0.8750, Log Loss: 0.3169, F1: 0.8649, Precision: 0.8889, Recall: 0.8421, Specificity: 0.9048, AUROC: 0.9499\n",
            "\n",
            "Training fold 5...\n",
            "[LightGBM] [Info] Number of positive: 154, number of negative: 166\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2854\n",
            "[LightGBM] [Info] Number of data points in the train set: 320, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481250 -> initscore=-0.075035\n",
            "[LightGBM] [Info] Start training from score -0.075035\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Fold 5 - Accuracy: 0.8625, Log Loss: 0.4897, F1: 0.8642, Precision: 0.8140, Recall: 0.9211, Specificity: 0.8095, AUROC: 0.9185\n",
            "\n",
            "Cross-Validation Results:\n",
            "Average Accuracy: 0.8650\n",
            "Average Log Loss: 0.4162\n",
            "Average F1 Score: 0.8575\n",
            "Average Precision: 0.8714\n",
            "Average Recall: 0.8497\n",
            "Average Specificity: 0.8797\n",
            "Average AUROC: 0.9350\n",
            "\n",
            "Final Test Evaluation...\n",
            "[LightGBM] [Info] Number of positive: 192, number of negative: 208\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3787\n",
            "[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 36\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.480000 -> initscore=-0.080043\n",
            "[LightGBM] [Info] Start training from score -0.080043\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Test Accuracy: 1.0000\n",
            "Test Log Loss: 0.0761\n",
            "Test F1 Score: 1.0000\n",
            "Test Precision: 1.0000\n",
            "Test Recall: 1.0000\n",
            "Test Specificity: 1.0000\n",
            "Test AUROC: 1.0000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}